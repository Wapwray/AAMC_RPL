<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Vocal Test — Realtime Voice</title>
  <style>
    :root {
      /* Primary palette */
      --brand-blue: #0b4a7a;
      --brand-blue-accent: #1e73be;
      --panel-blue-bg: #eaf5ff;
      --panel-blue-border: #d6ecff;

      /* Accent / gold */
      --gold: #f5d07a;
      --gold-dark: #d2a63a;
      --contact-bg: #fff5df;

      /* Neutrals */
      --text: #0c2740;
      --muted: #7d8b95;
      --card-bg: #ffffff;
      --card-border: #efe9df;
      --shadow-soft: 0 8px 20px rgba(13, 30, 41, 0.06);

      /* Sizing */
      --radius-lg: 12px;
      --radius-md: 8px;
      --gap: 12px;

      /* Legacy tokens mapped to new palette */
      --bg: var(--panel-blue-bg);
      --fg: var(--text);
      --accent: var(--gold);
      --accent-strong: var(--gold-dark);
      --border: var(--card-border);
      --border-soft: rgba(12, 39, 64, 0.08);
      --card: var(--card-bg);
      --card-strong: #f7fbff;
      --shadow: var(--shadow-soft);
      --danger: #c75f52;
      --success: #4c9b79;
    }
    * { box-sizing: border-box; }
    body {
      margin: 0;
      min-height: 100vh;
      background: linear-gradient(180deg, #f6fbff 0%, var(--panel-blue-bg) 100%);
      color: var(--fg);
      font-family: "Inter", system-ui, -apple-system, "Segoe UI", Roboto, Ubuntu, sans-serif;
    }
    main {
      max-width: none;
      margin: 0;
      /* Reduce top gap above titles on subsequent screens */
      padding: 12px clamp(16px, 4vw, 52px) 72px;
      display: flex;
      flex-direction: column;
      gap: 28px;
    }
    .info-card {
      background: var(--panel-blue-bg);
      border: 1px solid var(--panel-blue-border);
      border-radius: var(--radius-lg);
      box-shadow: var(--shadow-soft);
      padding: 18px 22px;
      color: var(--text);
      position: relative;
      line-height: 1.5;
    }
    .info-card::before {
      content: "";
      position: absolute;
      left: 10px;
      top: 10px;
      bottom: 10px;
      width: 6px;
      background: var(--brand-blue-accent);
      border-radius: 6px;
    }
    .contact-panel {
      background: var(--contact-bg);
      border: 1px solid rgba(210, 166, 58, 0.14);
      border-radius: var(--radius-lg);
      padding: 14px;
      display: flex;
      justify-content: space-between;
      align-items: center;
      box-shadow: var(--shadow-soft);
      gap: var(--gap);
    }
    .student-context {
      display: flex;
      flex-wrap: wrap;
      align-items: baseline;
      justify-content: space-between;
      gap: 8px 16px;
      padding: 14px 18px;
      border: 1px solid var(--panel-blue-border);
      border-radius: var(--radius-lg);
      background: rgba(234, 245, 255, 0.65);
      box-shadow: var(--shadow-soft);
      font-size: 16px;
      color: var(--text);
    }
    .student-context__name {
      font-size: 18px;
      font-weight: 600;
      letter-spacing: 0.02em;
    }
    .student-context__meta {
      font-size: 14px;
      color: var(--muted);
    }
    .muted { color: var(--muted); font-size: 13px; }
    nav[data-shared-nav] {
      margin-bottom: 12px;
    }
    header h1 {
      margin: 0 0 8px;
      font-size: clamp(28px, 5vw, 40px);
      display: flex;
      flex-wrap: wrap;
      gap: 12px;
      align-items: baseline;
    }
    .badge {
      font-size: 14px;
      font-weight: 600;
      padding: 4px 12px;
      border-radius: 999px;
      background: rgba(11, 74, 122, 0.12);
      border: 1px solid rgba(30, 115, 190, 0.25);
      color: var(--brand-blue);
    }
    header p {
      margin: 0;
      color: var(--muted);
      font-size: 16px;
      max-width: 720px;
    }
    .settings-toggle {
      position: fixed;
      bottom: 20px;
      left: 20px;
      z-index: 10001;
      text-transform: uppercase;
      letter-spacing: 0.05em;
      font-size: 12px;
      box-shadow: 0 6px 18px rgba(13, 30, 41, 0.16);
    }
    /* Ensure step cards can anchor absolutely positioned elements */
    .card.step {
      position: relative;
      background: transparent;
      border: none;
      border-radius: 0;
      padding: 0;
      box-shadow: none;
    }
    /* Reposition Settings button within the Step 1 (baseline) card */
    .step[data-step="baseline"] .settings-toggle {
      position: absolute;
      top: 12px;
      right: 12px;
      left: auto;
      bottom: auto;
      z-index: 2;
      box-shadow: none;
    }
    /* Scenario view button placed at the far right of header */
    .scenario-view-btn {
      padding: 8px 14px;
      border-radius: 10px;
      border: 1px solid var(--panel-blue-border);
      background: var(--panel-blue-bg);
      color: var(--brand-blue);
      font-weight: 600;
    }
    /* Scenario slot header row: title left, scenario button right (inside the white slot box) */
    .scenario-instructions-header {
      display: flex;
      align-items: flex-start;
      justify-content: space-between;
      gap: 12px;
    }
    .scenario-view-btn-host {
      flex: 0 0 auto;
    }
    /* Move the scenario "white question box" up within the Scenario step */
    .card.step[data-step="scenario"] {
      padding-top: 12px;
      gap: 12px;
    }
    .settings-modal {
      position: fixed;
      inset: 0;
      display: grid;
      place-items: center;
      background: rgba(12, 39, 64, 0.35);
      backdrop-filter: blur(2px);
      z-index: 10000;
      padding: 24px;
    }
    .settings-modal[hidden] {
      display: none !important;
    }
    .settings-modal .card.settings {
      position: relative;
      width: min(640px, 100%);
      max-height: min(90vh, 640px);
      overflow-y: auto;
      outline: none;
      box-shadow: 0 24px 48px rgba(12, 39, 64, 0.24);
    }
    .settings-close {
      position: absolute;
      top: 14px;
      right: 14px;
      background: transparent;
      border: none;
      color: var(--muted);
      font-size: 18px;
      line-height: 1;
      padding: 6px;
      cursor: pointer;
      box-shadow: none;
      border-radius: 50%;
    }
    .settings-close:hover {
      color: var(--brand-blue);
    }
    .info-card p { margin: 0; }
    .card {
      background: var(--card-bg);
      border: 1px solid var(--card-border);
      border-radius: var(--radius-lg);
      padding: clamp(18px, 4vw, 28px);
      box-shadow: none;
      display: flex;
      flex-direction: column;
      gap: 18px;
    }
    .card h2 {
      margin: 0 0 6px;
      font-size: 20px;
      letter-spacing: 0.03em;
      text-transform: uppercase;
      color: var(--brand-blue);
    }
    /* Match Scenario overlay title to scenario section heading style */
    #scenarioOverviewTitle {
      margin: 0 0 6px;
      font-size: 20px;
      letter-spacing: 0.03em;
      text-transform: uppercase;
      color: var(--brand-blue);
    }
      /* Force instructional text to solid black across baseline/scenario */
      .step[data-step="baseline"],
      .step[data-step="scenario"] {
        color: #000;
      }
      /* Override any muted or secondary styles inside baseline/scenario */
      .step[data-step="baseline"] .muted,
      .step[data-step="scenario"] .muted,
      .step[data-step="baseline"] p,
      .step[data-step="scenario"] p,
      .step[data-step="baseline"] span,
      .step[data-step="scenario"] span,
      .step[data-step="baseline"] .subtle,
      .step[data-step="scenario"] .subtle {
        color: #000 !important;
      }
      /* Ensure links in instructions render black, not theme-muted */
      .step[data-step="baseline"] a,
      .step[data-step="scenario"] a {
        color: #000 !important;
      }
      /* In case cards or containers set a gray color, override deeply */
      .card.step[data-step="baseline"] *,
      .card.step[data-step="scenario"] * {
        color: inherit;
      }
    .subtle {
      font-size: 14px;
      color: var(--muted);
      margin: 0;
    }
    .controls {
      display: flex;
      flex-wrap: wrap;
      gap: 12px;
      align-items: center;
    }
    .controls label {
      font-weight: 600;
      letter-spacing: 0.02em;
      text-transform: uppercase;
      font-size: 12px;
      color: var(--muted);
    }
    select {
      appearance: none;
      background: #ffffff;
      color: var(--fg);
      border: 1px solid var(--panel-blue-border);
      border-radius: 10px;
      padding: 10px 12px;
      min-width: 220px;
      font: inherit;
      box-shadow: inset 0 1px 2px rgba(13, 30, 41, 0.06);
    }
    select:disabled {
      opacity: 0.55;
    }
    button {
      appearance: none;
      border: 1px solid rgba(11, 74, 122, 0.18);
      background: #ffffff;
      color: var(--brand-blue);
      padding: 11px 18px;
      border-radius: 12px;
      font-weight: 600;
      letter-spacing: 0.01em;
      cursor: pointer;
      transition: transform 120ms ease, box-shadow 120ms ease, opacity 120ms ease;
      box-shadow: 0 6px 18px rgba(13, 30, 41, 0.08);
    }
    button:hover:not(:disabled) {
      transform: translateY(-1px);
      box-shadow: 0 10px 24px rgba(13, 30, 41, 0.12);
    }
    button:disabled {
      opacity: 0.55;
      cursor: not-allowed;
      box-shadow: none;
    }
    .btn-primary {
      background: linear-gradient(180deg, var(--gold) 0%, #f0c85f 100%);
      border: 1px solid var(--gold-dark);
      color: #2b2b2b;
      border-radius: 24px;
      box-shadow: 0 6px 18px rgba(210, 166, 58, 0.12);
    }
    .secondary {
      background: var(--panel-blue-bg);
      border: 1px solid var(--panel-blue-border);
      color: var(--brand-blue);
      box-shadow: none;
    }
    .danger {
      border-color: rgba(199, 95, 82, 0.7);
      background: rgba(216, 118, 106, 0.85);
      color: #fffaf6;
      box-shadow: 0 12px 20px rgba(199, 95, 82, 0.22);
    }
    .pill {
      display: inline-flex;
      align-items: center;
      gap: 6px;
      padding: 6px 12px;
      border-radius: 999px;
      border: 1px solid rgba(210, 166, 58, 0.35);
      background: rgba(245, 208, 122, 0.18);
      color: var(--gold-dark);
      font-size: 13px;
      font-weight: 600;
    }
    .pill .dot {
      width: 8px;
      height: 8px;
      border-radius: 50%;
      background: currentColor;
      box-shadow: 0 0 0 0 rgba(210, 166, 58, 0.4);
      animation: pulse 2s infinite;
    }
    @keyframes pulse {
      0% { box-shadow: 0 0 0 0 rgba(210, 166, 58, 0.3); }
      50% { box-shadow: 0 0 0 12px rgba(210, 166, 58, 0); }
      100% { box-shadow: 0 0 0 0 rgba(210, 166, 58, 0); }
    }
    /* Version badge (top-right) */
    .version-badge {
      position: fixed;
      top: 12px;
      right: 12px;
      background: var(--brand-blue);
      color: #fff;
      padding: 6px 10px;
      border-radius: 14px;
      font-size: 12px;
      font-weight: 600;
      box-shadow: 0 4px 12px rgba(11, 74, 122, 0.12);
      border: none;
      z-index: 9999;
      pointer-events: auto;
    }
    .version-badge:focus {
      outline: 3px solid rgba(30, 115, 190, 0.24);
      outline-offset: 2px;
    }
    .assessment-status {
      display: flex;
      align-items: center;
      gap: 12px;
      padding: 14px 18px;
      border: 1px solid var(--panel-blue-border);
      border-radius: var(--radius-lg);
      background: var(--card-bg);
      box-shadow: var(--shadow-soft);
      flex-wrap: wrap;
    }
    .assessment-status__label {
      font-size: 14px;
      font-weight: 600;
      letter-spacing: 0.03em;
      text-transform: uppercase;
      color: var(--muted);
    }
    .assessment-status__badge {
      display: inline-flex;
      align-items: center;
      padding: 6px 16px;
      border-radius: 999px;
      font-weight: 600;
      letter-spacing: 0.02em;
      text-transform: uppercase;
      border: 1px solid transparent;
    }
    .assessment-status__badge.is-inprogress {
      background: rgba(245, 208, 122, 0.18);
      color: var(--gold-dark);
      border-color: rgba(210, 166, 58, 0.35);
    }
    .assessment-status__badge.is-met {
      background: rgba(76, 155, 121, 0.16);
      color: var(--success);
      border-color: rgba(76, 155, 121, 0.32);
    }
    .assessment-status__badge.is-not-met {
      background: rgba(199, 95, 82, 0.16);
      color: var(--danger);
      border-color: rgba(199, 95, 82, 0.32);
    }
    .assessment-status__timestamp {
      margin-left: 12px;
      font-size: 13px;
      color: var(--muted);
    }
    .assessment-status__controls {
      display: inline-flex;
      align-items: center;
      gap: 8px;
    }
    .assessment-status__controls button {
      border-radius: 16px;
      padding: 6px 12px;
      font-size: 12px;
      text-transform: uppercase;
      box-shadow: none;
    }
    .assessment-status__snapshot {
      flex-basis: 100%;
      margin: 0;
      padding: 10px 14px;
      border-radius: 10px;
      background: rgba(234, 245, 255, 0.65);
      font-family: "JetBrains Mono", "SFMono-Regular", Consolas, monospace;
      font-size: 12px;
      line-height: 1.6;
      color: var(--fg);
      white-space: pre-wrap;
      word-break: break-word;
    }
    .assessment-status__debug {
      flex-basis: 100%;
      border-radius: 10px;
      border: 1px solid var(--panel-blue-border);
      background: rgba(234, 245, 255, 0.65);
      display: grid;
      grid-template-rows: auto 1fr;
      max-height: 220px;
      overflow: hidden;
    }
    .assessment-status__debug[hidden] {
      display: none !important;
    }
    .assessment-status__debug-header {
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 8px 12px;
      background: rgba(30, 115, 190, 0.12);
      font-size: 11px;
      letter-spacing: 0.08em;
      text-transform: uppercase;
      color: var(--brand-blue);
      gap: 8px;
    }
    .assessment-status__debug-header button {
      font-size: 11px;
      padding: 4px 10px;
      border-radius: 12px;
      box-shadow: none;
    }
    .assessment-status__debug-output {
      margin: 0;
      padding: 10px 12px;
      font-family: "JetBrains Mono", "SFMono-Regular", Consolas, monospace;
      font-size: 12px;
      line-height: 1.6;
      color: var(--fg);
      background: rgba(234, 245, 255, 0.4);
      overflow: auto;
      white-space: pre;
    }
    .meter {
      position: relative;
      height: 12px;
      border-radius: 999px;
      background: rgba(30, 115, 190, 0.12);
      border: 1px solid var(--border-soft);
      overflow: hidden;
      flex: 1 0 180px;
    }
    .meter i {
      display: block;
      height: 100%;
      width: 4%;
      background: linear-gradient(90deg, rgba(11, 74, 122, 0.3), rgba(30, 115, 190, 0.8));
      transition: width 120ms linear;
    }
    .step {
      position: relative;
      gap: 24px;
    }
    .step[hidden] {
      display: none !important;
    }
    .step > p {
      margin: 0;
      color: var(--muted);
    }
    .script {
      padding: 14px 18px;
      border-radius: 14px;
      border: 1px solid var(--card-border);
      background: var(--contact-bg);
      font-size: 16px;
      line-height: 1.6;
      color: var(--fg);
      max-width: 720px;
      box-shadow: inset 0 1px 1px rgba(210, 166, 58, 0.12);
    }
    .scenario-text {
      padding: 18px;
      border-radius: 14px;
      border: none;
      background: var(--panel-blue-bg);
      color: var(--fg);
      line-height: 1.65;
      box-shadow: none;
    }
    .slot {
      border: none;
      border-radius: 16px;
      padding: 16px 18px;
      background: #ffffff;
      display: grid;
      gap: 12px;
      box-shadow: var(--shadow-soft);
    }
    .slot[hidden] {
      display: none !important;
    }
    .slot h3 {
      margin: 0;
      font-size: 18px;
      color: var(--fg);
    }
    .slot p {
      margin: 0;
      color: var(--muted);
      font-size: 15px;
    }
    .scenario-instructions p + p,
    .baseline-instructions p + p {
      margin-top: 16px;
    }
    /* Tighten spacing: remove extra gap above first instruction lines */
    .baseline-instructions p:first-child { margin-top: 0; }
    .scenario-instructions { margin-top: 0; }
    .scenario-instructions h3 { margin-top: 0; margin-bottom: 12px; }
    /* Ensure all instructional text is black */
    .scenario-instructions,
    .baseline-instructions,
    .next-hint,
    .startup-modal { color: #000 !important; }

    /* Startup / Scenario overlays: ensure modal layout is always styled (even if JS fails) */
    .startup-overlay {
      position: fixed;
      inset: 0;
      background: rgba(7, 21, 30, 0.6);
      backdrop-filter: blur(2px);
      display: grid;
      place-items: center;
      z-index: 10000;
    }
    .startup-overlay[hidden] { display: none !important; }

    /* Startup instructions modal sizing (video-focused) */
    #startupOverlay .startup-modal {
      width: min(1100px, 96vw);
      /* Adaptive height: shrink-wrap content, cap to viewport */
      height: auto;
      max-height: 92vh;
      background: #fff;
      border-radius: 16px;
      border: 1px solid var(--panel-blue-border);
      box-shadow: 0 10px 30px rgba(7, 21, 30, 0.25);
      padding: 20px 22px;
      display: grid;
      grid-template-rows: auto auto auto;
      gap: 12px;
      overflow: auto;
    }
    #startupOverlay .startup-modal h2 { margin: 0 0 10px; font-size: 22px; }
    #startupOverlay .startup-modal p { margin: 10px 0; }
    #startupOverlay .startup-modal ul { margin: 10px 0 0; padding-left: 22px; }
    #startupOverlay .startup-modal li { margin: 6px 0; }
    #startupOverlay .startup-content .watch-row { display: flex; align-items: center; gap: 12px; }
    #startupOverlay .startup-modal .actions { display: flex; justify-content: flex-end; align-items: center; gap: 10px; margin-top: 0; }
    #startupOverlay .startup-modal .actions .btn-primary { min-width: 140px; }
    #startupOverlay .startup-modal .highlight { font-weight: 600; }
    /* Video frame: match the displayed video (960x540 => 16:9) and avoid extra whitespace */
    #startupOverlay .startup-video {
      width: min(960px, 100%);
      aspect-ratio: 16 / 9;
      background: #000;
      border-radius: 8px;
      overflow: hidden;
    }
    #startupOverlay .startup-video iframe {
      width: 100%;
      height: 100%;
      display: block;
      border: 0;
    }
    #startupOverlay .startup-video-header h2 { margin: 0; color: var(--brand-blue); font-size: 22px; }

    /* Startup video header: align title and action buttons on one row */
    #startupVideoHeader {
      display: flex;
      align-items: center;
      justify-content: space-between;
      gap: 12px;
      margin-bottom: 8px; /* tighten space above video */
    }
    #startupVideoHeader h2 {
      margin: 0;
      line-height: 1.2;
    }
    /* Ensure header never shows until video is displayed */
    #startupVideoHeader[hidden] { display: none !important; }
    /* Header-aligned actions group */
    #startupHeaderActions {
      display: inline-flex;
      align-items: center;
      gap: 8px;
    }
    /* Reduce vertical gap between header and video container */
    #startupVideoContainer {
      margin-top: 0;
      padding-top: 0;
    }
    /* Ensure video container never shows until explicitly unhidden */
    #startupVideoContainer[hidden] { display: none !important; }
      /* Scenario overlay visual refresh to match provided design */
      #scenarioOverviewOverlay .startup-modal {
        background: #ffffff;
        border: 1px solid rgba(0,0,0,0.12);
        border-radius: 14px;
        box-shadow: 0 8px 24px rgba(0,0,0,0.12);
        max-width: 920px;
        padding: 24px 28px 24px;
      }
      #scenarioOverviewOverlay #scenarioOverviewTitle {
        font-size: 28px;
        line-height: 1.2;
        color: var(--brand-blue);
        margin: 0 0 12px 0;
        letter-spacing: 0.2px;
      }
      /* Ensure consistent paragraph spacing without large gaps */
      #scenarioOverviewOverlay .scenario-text p {
        margin: 8px 0;
        line-height: 1.35;
        color: #000;
      }
      /* Remove accidental huge gaps introduced by inline or conflicting styles */
      #scenarioOverviewOverlay .scenario-text p:first-child { margin-top: 0; }
      #scenarioOverviewOverlay .scenario-text p:last-child {
        margin-top: 14px;
        font-weight: 700;
        text-decoration: underline;
      }
      /* Footer actions align right and sit close to content */
      #scenarioOverviewOverlay .actions {
        display: flex;
        gap: 8px;
        justify-content: flex-end;
        margin-top: 16px;
      }
    /* Underline entire "Sam Says" line for scenario 2 and 3 */
    .slot[data-slot="scenario2"] .scenario-instructions p:first-child,
    .slot[data-slot="scenario3"] .scenario-instructions p:first-child {
      text-decoration: underline !important;
    }
    .slot-controls {
      display: flex;
      flex-wrap: wrap;
      align-items: center;
      gap: 12px;
    }
    .slot-controls button {
      min-width: 132px;
    }
    .slot .status {
      font-size: 14px;
      color: var(--muted);
      min-width: 140px;
    }
    .slot-meter {
      display: flex;
      flex-direction: column;
      gap: 6px;
      margin-top: 8px;
    }
    .slot-meter__label {
      font-size: 12px;
      letter-spacing: 0.04em;
      text-transform: uppercase;
      color: var(--muted);
    }
    .slot-meter .meter {
      height: 10px;
      width: 100%;
      flex: 0 0 auto;
    }
    .slot .timer {
      font-size: 15px;
      font-weight: 600;
      padding: 6px 12px;
      border-radius: 10px;
      background: rgba(30, 115, 190, 0.08);
      border: 1px solid rgba(30, 115, 190, 0.18);
      color: var(--fg);
      min-width: 88px;
      text-align: center;
      box-shadow: inset 0 1px 1px rgba(13, 30, 41, 0.08);
    }
    .slot-footer {
      display: flex;
      justify-content: flex-end;
      gap: 12px;
    }
    .playback-tools {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      align-items: center;
    }
    .playback-tools[hidden] {
      display: none !important;
    }
    .playback-tools a {
      color: var(--brand-blue);
      text-decoration: none;
      font-weight: 600;
      border: 1px solid var(--panel-blue-border);
      border-radius: 10px;
      padding: 8px 14px;
      background: var(--panel-blue-bg);
    }
    .summary {
      border-top: 1px solid var(--border-soft);
      padding-top: 14px;
      display: grid;
      gap: 12px;
    }
    .summary[hidden] {
      display: none !important;
    }
    .baseline-checks {
      border: 1px solid rgba(199, 95, 82, 0.28);
      background: rgba(199, 95, 82, 0.08);
      border-radius: 12px;
      padding: 14px 16px;
      display: grid;
      gap: 10px;
    }
    .baseline-checks[hidden] {
      display: none !important;
    }
    .baseline-checks__title {
      color: var(--danger);
      font-size: 14px;
      letter-spacing: 0.05em;
      text-transform: uppercase;
    }
    .baseline-checks__list {
      margin: 0;
      padding-left: 18px;
      font-size: 14px;
      color: var(--fg);
    }
    .baseline-checks__list li {
      margin: 4px 0;
    }
    .baseline-checks__list li.warning {
      color: var(--gold-dark);
    }
    .baseline-checks__list li.error {
      color: var(--danger);
      font-weight: 600;
    }
    .keywords-list {
      margin: 6px 0 0;
      padding-left: 20px;
      color: var(--muted);
      font-size: 14px;
    }
    .keywords-list code {
      background: rgba(245, 208, 122, 0.18);
      border: 1px solid rgba(210, 166, 58, 0.35);
      border-radius: 6px;
      padding: 2px 6px;
      font-family: 'JetBrains Mono', 'SFMono-Regular', Consolas, monospace;
      font-size: 13px;
      color: var(--gold-dark);
    }
    .evaluation-transcript {
      margin: 8px 0 0;
      padding: 12px 14px;
      border-radius: 12px;
      border: 1px solid var(--panel-blue-border);
      background: rgba(234, 245, 255, 0.7);
      font-family: "JetBrains Mono", "SFMono-Regular", Consolas, monospace;
      font-size: 13px;
      line-height: 1.6;
      color: var(--fg);
      white-space: pre-wrap;
    }
    .summary-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
      gap: 14px;
    }
    .summary-item {
      background: rgba(234, 245, 255, 0.65);
      border: 1px solid var(--panel-blue-border);
      border-radius: var(--radius-md);
      padding: 12px 14px;
      display: flex;
      flex-direction: column;
      gap: 4px;
      box-shadow: none;
    }
    .summary-item span {
      font-size: 12px;
      letter-spacing: 0.05em;
      text-transform: uppercase;
      color: var(--muted);
    }
    .summary-item strong {
      font-size: 20px;
      color: var(--fg);
    }
    .transcript {
      border-radius: 14px;
      border: 1px solid var(--panel-blue-border);
      background: #ffffff;
      padding: 16px;
      font-family: "JetBrains Mono", "SFMono-Regular", Consolas, monospace;
      font-size: 13px;
      max-height: 260px;
      overflow: auto;
      box-shadow: inset 0 1px 1px rgba(13, 30, 41, 0.05);
      color: var(--fg);
    }
    .transcript h4 {
      margin: 0 0 10px;
      font-size: 14px;
      color: var(--muted);
      letter-spacing: 0.04em;
      text-transform: uppercase;
    }
    .transcript-header {
      display: flex;
      align-items: center;
      justify-content: space-between;
      gap: 12px;
      margin-bottom: 10px;
    }
    .btn-small {
      padding: 6px 12px;
      font-size: 12px;
      line-height: 1;
    }
    .transcript-editor {
      display: grid;
      gap: 8px;
      margin-top: 10px;
    }
    .transcript-editor[hidden] {
      display: none !important;
    }
    .transcript-editor textarea {
      width: 100%;
      min-height: 120px;
      padding: 10px 12px;
      border-radius: 10px;
      border: 1px solid var(--border);
      background: rgba(255, 252, 241, 0.96);
      font-family: "Inter", system-ui, -apple-system, "Segoe UI", Roboto, Ubuntu, sans-serif;
      font-size: 14px;
      line-height: 1.5;
      color: var(--fg);
      resize: vertical;
    }
    .line {
      margin: 4px 0;
      line-height: 1.5;
    }
    .line.partial {
      color: var(--accent-strong);
    }
    .line.final {
      color: var(--fg);
    }
    .line .ts {
      color: rgba(145, 128, 102, 0.7);
      margin-right: 6px;
    }
    .empty {
      color: rgba(145, 128, 102, 0.7);
      font-style: italic;
    }
    .step-footer {
      display: flex;
      justify-content: flex-end;
      gap: 12px;
    }
    .step-footer--with-hint {
      /* Ensure Next button sits on the right always */
      align-items: center;
      gap: 18px;
    }
    /* In hint footers, push the Next button to the far right */
    .step-footer--with-hint > .btn-primary,
    .step-footer--with-hint > button.btn-primary,
    .step-footer--with-hint > #baselineNext,
    .step-footer--with-hint > #scenarioNext {
      margin-left: auto;
    }
    .next-hint {
      display: none;
      padding: 10px 12px;
      border-radius: 10px;
      border: 1px solid var(--panel-blue-border);
      background: var(--panel-blue-bg);
      color: var(--text);
      font-size: 14px;
      line-height: 1.4;
      margin-right: auto;
    }
    .next-hint.visible {
      display: block;
      flex: 1;
    }
    .evaluation-summary p {
      margin: 0;
    }
    .evaluation-summary ul {
      margin: 12px 0 0;
      padding-left: 20px;
      color: var(--muted);
    }
    .evaluation-block {
      padding: 14px 0;
      border-bottom: 1px solid var(--border-soft);
      display: grid;
      gap: 10px;
    }
    .evaluation-block:last-of-type {
      border-bottom: none;
      padding-bottom: 0;
    }
    .downloads-list {
      margin: 12px 0 0;
      padding-left: 20px;
      color: var(--muted);
    }
    .downloads-list a {
      color: var(--accent-strong);
      font-weight: 600;
      text-decoration: none;
    }
    .tag {
      display: inline-flex;
      align-items: center;
      padding: 3px 8px;
      border-radius: 999px;
      font-size: 11px;
      letter-spacing: 0.04em;
      text-transform: uppercase;
      color: var(--accent-strong);
      background: rgba(241, 164, 58, 0.16);
      border: 1px solid rgba(241, 164, 58, 0.32);
    }
      .debug-toggle {
        position: fixed;
        bottom: 18px;
        right: 18px;
        padding: 8px 14px;
        border-radius: 999px;
        font-size: 12px;
        font-weight: 600;
        background: rgba(11, 74, 122, 0.9);
        color: #ffffff;
        border: none;
        box-shadow: 0 6px 18px rgba(13, 30, 41, 0.18);
        cursor: pointer;
        z-index: 9999;
      }
      .debug-toggle:focus {
        outline: 3px solid rgba(30, 115, 190, 0.4);
        outline-offset: 2px;
      }
      .debug-panel {
        position: fixed;
        bottom: 70px;
        right: 18px;
        width: min(420px, 90vw);
        max-height: 45vh;
        background: #0c2740;
        color: #f6fbff;
        border-radius: 16px;
        box-shadow: 0 20px 40px rgba(13, 30, 41, 0.35);
        display: flex;
        flex-direction: column;
        z-index: 9999;
        border: 1px solid rgba(30, 115, 190, 0.45);
      }
      .debug-panel[hidden] {
        display: none !important;
      }
      .debug-header {
        display: flex;
        align-items: center;
        justify-content: space-between;
        padding: 10px 14px;
        background: rgba(30, 115, 190, 0.18);
        border-bottom: 1px solid rgba(30, 115, 190, 0.32);
        font-size: 12px;
        letter-spacing: 0.08em;
        text-transform: uppercase;
      }
      .debug-header span {
        font-weight: 600;
      }
      .debug-header button {
        background: transparent;
        border: 1px solid rgba(246, 251, 255, 0.18);
        color: inherit;
        border-radius: 12px;
        padding: 6px 10px;
        font-size: 12px;
        cursor: pointer;
      }
      .debug-output {
        flex: 1;
        margin: 0;
        padding: 12px 14px;
        font-family: "JetBrains Mono", "SFMono-Regular", Consolas, monospace;
        font-size: 12px;
        white-space: pre-wrap;
        overflow: auto;
        background: rgba(12, 39, 64, 0.88);
      }
      .debug-actions {
        display: flex;
        align-items: center;
        gap: 6px;
      }
    @media (max-width: 720px) {
      .slot-controls {
        flex-direction: column;
        align-items: stretch;
      }
      .slot-controls button,
      .slot-controls .timer {
        width: 100%;
      }
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/microsoft-cognitiveservices-speech-sdk@1.41.0/distrib/browser/microsoft.cognitiveservices.speech.sdk.bundle-min.js"></script>
</head>
<body>
  <!-- Startup Instructions Overlay: blocks app until continued -->
  <div id="startupOverlay" class="startup-overlay" role="dialog" aria-modal="true" aria-labelledby="startupTitle">
    <section class="startup-modal">
      <div class="startup-content" id="startupContent">
        <h2 id="startupTitle">Instructions</h2>
        <p>This activity checks your ability to meet the speaking requirements for the LLND assessment. You will be given a case study and will role-play as the <u>Senior Finance Broker</u>.</p>
        <p>There are three separate recordings. For each recording, you will be given a starter sentence. You must complete the response using information from the case study.</p>
        <p>This is not timed — take your time to plan your response.</p>
        <h3 style="margin:14px 0 6px; font-size:18px;">Before You Start</h3>
        <p class="watch-row"><span>You must watch this video</span> <button id="startupPlayVideo" type="button" class="btn-primary">Play Video</button></p>
      </div>
      <div class="startup-video-header" id="startupVideoHeader" hidden>
        <h2>LLND Instructional Video</h2>
        <div class="actions" id="startupHeaderActions">
          <button id="startupSkip" type="button" class="secondary" hidden>Skip</button>
          <button id="startupPlayAgain" type="button" class="secondary" hidden>Play Again</button>
          <button id="startupContinue" type="button" class="btn-primary" hidden>Continue</button>
        </div>
      </div>
      <div class="startup-video" id="startupVideoContainer" hidden>
        <iframe
          id="startupVimeo"
          src="https://player.vimeo.com/video/1145641956?title=0&amp;byline=0&amp;portrait=0&amp;badge=0&amp;autopause=0&amp;controls=1&amp;muted=0&amp;api=1&amp;player_id=startupVimeoPlayer&amp;app_id=58479"
          width="960"
          height="540"
          frameborder="0"
          allow="autoplay; fullscreen; picture-in-picture; clipboard-write; encrypted-media; web-share"
          referrerpolicy="strict-origin-when-cross-origin"
          title="LLND Instructions"
        ></iframe>
      </div>
    </section>
  </div>
  
  <main>
    <!-- Student context banner now created dynamically only in Admin mode -->
    <section class="card step" data-step="baseline">
      <h2>Step 1 — Test Recording</h2>
      <button type="button" id="settingsToggle" class="settings-toggle secondary" aria-expanded="false" aria-controls="sessionSettings">SETTINGS</button>
      <div class="baseline-instructions">
        <p>Read the sentence below in a calm, professional tone.</p>

        <p>This recording is used to start the next part of your speaking test.</p>
        <p>Press the start button and after the tone, record the scripted line, and press stop. If you are happy with what you have said, continue to start the speaking test.</p>
      </div>
  <div class="script">Hello my name is [YOUR NAME] and I understand that I must speak in a clear and professional tone during this test</div>
      <div class="slot" data-slot="baseline" data-label="Baseline">
        <div class="slot-controls">
          <button type="button" data-action="start">Start</button>
          <button type="button" data-action="stop" disabled>Stop</button>
          <span class="pill" data-role="listen" hidden><span class="dot" aria-hidden="true"></span>Listening</span>
          <span class="timer" data-role="timer">00:00</span>
          <span class="status" data-role="status">Idle</span>
        </div>
        <div class="slot-meter" data-role="meter">
          <span class="slot-meter__label">Input level</span>
          <div class="meter" aria-label="Microphone input level"><i data-role="meter-bar" style="width: 4%;"></i></div>
        </div>
        <div class="playback-tools" data-role="playback" hidden>
          <button type="button" class="secondary" data-action="play" disabled aria-pressed="false">Play Recording</button>
        </div>
        <div class="summary" data-role="summary" hidden>
          <span class="tag">Recording details</span>
          <div class="summary-grid">
            <div class="summary-item"><span>Tempo</span><strong data-metric="tempo">0 wpm</strong></div>
            <div class="summary-item"><span>Speech ratio</span><strong data-metric="ratio">0%</strong></div>
            <div class="summary-item"><span>Mean loudness</span><strong data-metric="loudness">– dB</strong></div>
            <div class="summary-item"><span>Filler words</span><strong data-metric="filler">0</strong></div>
            <div class="summary-item"><span>Longest pause</span><strong data-metric="pause">0.0s</strong></div>
          </div>
        </div>
        <div class="baseline-checks" data-role="alerts" hidden>
          <strong class="baseline-checks__title">Please review before continuing</strong>
          <ul class="baseline-checks__list" data-role="alerts-list"></ul>
        </div>
        <div class="transcript" data-role="transcript">
          <div class="transcript-header">
            <h4>Transcript</h4>
          </div>
          <div data-role="transcript-body" class="empty" aria-live="polite">No transcript yet.</div>
          <div class="transcript-editor" data-role="transcript-editor" hidden>
            <textarea data-role="transcript-input" spellcheck="true"></textarea>
            <p class="subtle">Adjust wording if the transcription missed anything. This does not change the audio recording.</p>
          </div>
        </div>
      </div>
    <div class="step-footer step-footer--with-hint">
      <div id="baselineNextHint" class="next-hint" aria-live="polite" aria-hidden="true">
        <div>Check the transcription is correct before pressing the Next button. Press the 'Start' button to re-record.</div>
      </div>
  <button type="button" id="baselineNext" class="btn-primary" disabled>next</button>
      </div>
    </section>

    <!-- Scenario Overview Overlay shown after Step 1 Next (and when Recording 1 is visible) -->
    <div id="scenarioOverviewOverlay" class="startup-overlay" role="dialog" aria-modal="true" aria-labelledby="scenarioOverviewTitle" hidden>
      <section class="startup-modal">
        <h2 id="scenarioOverviewTitle">SCENARIO</h2>
        <p>In this role play you are playing the part of the Senior Finance Broker for Arora Finance Solutions. Your assistant, Sam, has missed two important deadlines.</p>
        <p>The missed deadlines have affected a client’s ability to settle their finance on time, which may result in penalties for the client.</p>
        <p>Sam has apologised and said he missed the deadlines because he was busy with other tasks.</p>
        <p>As a consequence, the client may consider lodging a formal complaint against Aurora Finance Solutions.</p>
        <p>Sam has asked what he can do to make sure it doesn’t happen again in the future.</p>
        <p>To avoid any future occurrences of this nature, you provide Sam with some strategies such as setting reminders, asking for help, prioritising tasks. At the end of your conversation, you will confirm with Sam what will happen next by mentioning a follow up time or date and that the strategy is working.</p>
        <p><strong><u>Limit your answers to around two sentences per section.</u></strong></p>
        <div class="actions" style="display:flex; justify-content:flex-end; gap:8px; margin-top:16px;">
          <button id="scenarioOverviewContinue" type="button" class="btn-primary">Continue</button>
          <button id="scenarioOverviewClose" type="button" class="secondary" hidden>Close</button>
        </div>
      </section>
    </div>

    <section class="card step" data-step="scenario" hidden>
      
      <div class="slot" data-slot="scenario1" data-label="Client impact">
        <div class="scenario-instructions" style="color: var(--fg);">
          <div class="scenario-instructions-header">
            <h3>Recording 1 — Impact on the client</h3>
            <div class="scenario-view-btn-host">
              <button type="button" id="scenarioViewBtn" class="scenario-view-btn" aria-haspopup="dialog" aria-controls="scenarioOverviewOverlay">Scenario</button>
            </div>
          </div>
          <p><strong><u>ONLY PROVIDE A RESPONSE TO THE FOLLOWING TASK. NOT THE WHOLE SCENARIO.</u></strong></p>
          <p><strong>Your Task :</strong> Greet Sam in a professional manner and explain to him what impact the missed deadlines has had on the client.</p>
          <p><strong>Example Starter:</strong> "Hi Sam, because you missed important deadlines the client…."</p>
          <p><u>You can remind yourself of the scenario by pressing the button at the top right of the screen.</u></p>
        </div>
        <div class="slot-controls">
          <button type="button" data-action="start">Start recording 1</button>
          <button type="button" data-action="stop" disabled>Stop</button>
          <span class="pill" data-role="listen" hidden><span class="dot" aria-hidden="true"></span>Listening</span>
          <span class="timer" data-role="timer">00:00</span>
          <span class="status" data-role="status">Idle</span>
        </div>
        <div class="slot-meter" data-role="meter">
          <span class="slot-meter__label">Input level</span>
          <div class="meter" aria-label="Microphone input level"><i data-role="meter-bar" style="width: 4%;"></i></div>
        </div>
        <div class="playback-tools" data-role="playback" hidden>
          <button type="button" class="secondary" data-action="play" disabled aria-pressed="false">Play Recording</button>
        </div>
        <div class="summary" data-role="summary" hidden>
          <span class="tag">Recording details</span>
          <div class="summary-grid">
            <div class="summary-item"><span>Tempo</span><strong data-metric="tempo">0 wpm</strong></div>
            <div class="summary-item"><span>Speech ratio</span><strong data-metric="ratio">0%</strong></div>
            <div class="summary-item"><span>Mean loudness</span><strong data-metric="loudness">– dB</strong></div>
            <div class="summary-item"><span>Filler words</span><strong data-metric="filler">0</strong></div>
            <div class="summary-item"><span>Longest pause</span><strong data-metric="pause">0.0s</strong></div>
          </div>
        </div>
        <div class="transcript" data-role="transcript">
          <div class="transcript-header">
            <h4>Transcript</h4>
          </div>
          <div data-role="transcript-body" class="empty" aria-live="polite">No transcript yet.</div>
          <div class="transcript-editor" data-role="transcript-editor" hidden>
            <textarea data-role="transcript-input" spellcheck="true"></textarea>
            <p class="subtle">Adjust wording if the transcription missed anything. This does not change the audio recording.</p>
          </div>
        </div>
        <div class="slot-footer">
          <div class="next-hint" data-role="next-hint" aria-live="polite" aria-hidden="true">
            <div>Check the transcription is correct before pressing the Next button.</div>
          </div>
          <button type="button" class="btn-primary" data-action="next-slot" hidden disabled>Next</button>
        </div>
      </div>
      <div class="slot" data-slot="scenario2" data-label="Company impact" hidden>
        <div class="scenario-instructions" style="color: var(--fg);">
          <div class="scenario-instructions-header">
            <h3>Recording 2 — Impact on the company</h3>
            <div class="scenario-view-btn-host"></div>
          </div>
          <p><strong><u>ONLY PROVIDE A RESPONSE TO THE FOLLOWING TASK. NOT THE WHOLE SCENARIO.</u></strong></p>
          <p><strong><u>Sam Says :</u></strong> “Sorry, I missed the deadlines because I was busy with other tasks.”</p>
          <p><strong>Your Task :</strong> Acknowledge Sam’s reason for missing the deadlines and explain the potential impact on the business.</p>
          <p><strong>Example Starter:</strong> " I understand you were busy with other tasks, however…"</p>
          <p><u>You can remind yourself of the scenario by pressing the button at the top right of the screen.</u></p>
        </div>
        <div class="slot-controls">
          <button type="button" data-action="start" disabled>Start recording 2</button>
          <button type="button" data-action="stop" disabled>Stop</button>
          <span class="pill" data-role="listen" hidden><span class="dot" aria-hidden="true"></span>Listening</span>
          <span class="timer" data-role="timer">00:00</span>
          <span class="status" data-role="status">Idle</span>
        </div>
        <div class="slot-meter" data-role="meter">
          <span class="slot-meter__label">Input level</span>
          <div class="meter" aria-label="Microphone input level"><i data-role="meter-bar" style="width: 4%;"></i></div>
        </div>
        <div class="playback-tools" data-role="playback" hidden>
          <button type="button" class="secondary" data-action="play" disabled aria-pressed="false">Play Recording</button>
        </div>
        <div class="summary" data-role="summary" hidden>
          <span class="tag">Recording details</span>
          <div class="summary-grid">
            <div class="summary-item"><span>Tempo</span><strong data-metric="tempo">0 wpm</strong></div>
            <div class="summary-item"><span>Speech ratio</span><strong data-metric="ratio">0%</strong></div>
            <div class="summary-item"><span>Mean loudness</span><strong data-metric="loudness">– dB</strong></div>
            <div class="summary-item"><span>Filler words</span><strong data-metric="filler">0</strong></div>
            <div class="summary-item"><span>Longest pause</span><strong data-metric="pause">0.0s</strong></div>
          </div>
        </div>
        <div class="transcript" data-role="transcript">
          <div class="transcript-header">
            <h4>Transcript</h4>
          </div>
          <div data-role="transcript-body" class="empty" aria-live="polite">No transcript yet.</div>
          <div class="transcript-editor" data-role="transcript-editor" hidden>
            <textarea data-role="transcript-input" spellcheck="true"></textarea>
            <p class="subtle">Adjust wording if the transcription missed anything. This does not change the audio recording.</p>
          </div>
        </div>
        <div class="slot-footer">
          <div class="next-hint" data-role="next-hint" aria-live="polite" aria-hidden="true">
            <div>Check the transcription is correct before pressing the Next button. Press the 'Start' button to re-record.</div>
          </div>
          <button type="button" class="btn-primary" data-action="next-slot" hidden disabled>Next</button>
        </div>
      </div>
      <div class="slot" data-slot="scenario3" data-label="Prevention strategy" hidden>
        <div class="scenario-instructions" style="color: var(--fg);">
          <div class="scenario-instructions-header">
            <h3>Recording 3 — Prevention strategy</h3>
            <div class="scenario-view-btn-host"></div>
          </div>
          <p><strong><u>ONLY PROVIDE A RESPONSE TO THE FOLLOWING TASK. NOT THE WHOLE SCENARIO.</u></strong></p>
          <p><strong><u>Sam Says :</u></strong> “What can I do to make sure it doesn’t happen again?”</p>
          <p><strong>Your Task :</strong> Provide a strategy to prevent this issue from happening again and explain how you will monitor Sam's progress.</p>
          <p><strong>Example Starter:</strong> "To avoid this happening again … and I will check with you…"</p>
          <p><u>You can remind yourself of the scenario by pressing the button at the top right of the screen.</u></p>
        </div>
        <div class="slot-controls">
          <button type="button" data-action="start" disabled>Start recording 3</button>
          <button type="button" data-action="stop" disabled>Stop</button>
          <span class="pill" data-role="listen" hidden><span class="dot" aria-hidden="true"></span>Listening</span>
          <span class="timer" data-role="timer">00:00</span>
          <span class="status" data-role="status">Idle</span>
        </div>
        <div class="slot-meter" data-role="meter">
          <span class="slot-meter__label">Input level</span>
          <div class="meter" aria-label="Microphone input level"><i data-role="meter-bar" style="width: 4%;"></i></div>
        </div>
        <div class="playback-tools" data-role="playback" hidden>
          <button type="button" class="secondary" data-action="play" disabled aria-pressed="false">Play Recording</button>
        </div>
        <div class="summary" data-role="summary" hidden>
          <span class="tag">Recording details</span>
          <div class="summary-grid">
            <div class="summary-item"><span>Tempo</span><strong data-metric="tempo">0 wpm</strong></div>
            <div class="summary-item"><span>Speech ratio</span><strong data-metric="ratio">0%</strong></div>
            <div class="summary-item"><span>Mean loudness</span><strong data-metric="loudness">– dB</strong></div>
            <div class="summary-item"><span>Filler words</span><strong data-metric="filler">0</strong></div>
            <div class="summary-item"><span>Longest pause</span><strong data-metric="pause">0.0s</strong></div>
          </div>
        </div>
        <div class="transcript" data-role="transcript">
          <div class="transcript-header">
            <h4>Transcript</h4>
          </div>
          <div data-role="transcript-body" class="empty" aria-live="polite">No transcript yet.</div>
          <div class="transcript-editor" data-role="transcript-editor" hidden>
            <textarea data-role="transcript-input" spellcheck="true"></textarea>
            <p class="subtle">Adjust wording if the transcription missed anything. This does not change the audio recording.</p>
          </div>
        </div>
      </div>
      <div class="step-footer step-footer--with-hint">
        <div id="scenarioNextHint" class="next-hint" aria-live="polite" aria-hidden="true">
          <div>Check the transcription is correct before pressing the Next button. Press the 'Start' button to re-record.</div>
        </div>
  <button type="button" id="scenarioNext" class="btn-primary" hidden disabled>next</button>
      </div>
    </section>

    <section class="card step" data-step="evaluation" hidden>
      <h2>Step 3 — Evaluation</h2>
      <div class="evaluation-summary" id="evaluationSummary">
        <p>You have now completed the LLND quiz. Please wait for your initial assessment.</p>
      </div>
      <div>
        <h3>Downloads</h3>
        <p class="subtle">Save the audio for your records. Each file uses the WebM format.</p>
        <ul class="downloads-list" id="downloadList"></ul>
      </div>
      <div class="step-footer">
        <button type="button" id="sendAssessmentInfo" class="btn-primary" disabled>Send BASIC</button>
        <button type="button" id="sendAssessmentHtml" class="secondary" disabled>Send HTML</button>
        <button type="button" id="saveAssessmentAudio" class="secondary" disabled>Save Audio</button>
      </div>
    </section>
  </main>
  <div id="settingsModal" class="settings-modal" hidden>
    <section id="sessionSettings" class="card settings" role="dialog" aria-modal="true" aria-labelledby="sessionSettingsTitle" hidden tabindex="-1">
      <button type="button" id="settingsClose" class="settings-close" aria-label="Close settings">
        <span aria-hidden="true">&times;</span>
      </button>
      <h2 id="sessionSettingsTitle">Session settings</h2>
      <div class="controls">
        <label for="language">Speech recognition language</label>
  <select id="language" data-autofocus>
          <option value="en-AU" selected>English (Australia)</option>
          <option value="en-US">English (United States)</option>
          <option value="en-GB">English (United Kingdom)</option>
          <option value="en-CA">English (Canada)</option>
          <option value="en-IN">English (India)</option>
          <option value="en-NZ">English (New Zealand)</option>
          <option value="en-ZA">English (South Africa)</option>
        </select>
        <label for="microphone">Microphone</label>
        <select id="microphone">
          <option value="">System default input</option>
        </select>
      </div>
      <div class="controls">
        <span class="subtle">Input level</span>
        <div class="meter" aria-label="Microphone level"><i id="level"></i></div>
      </div>
      <p class="subtle">Tip: record in a quiet space. You can re-record any step before progressing.</p>
    </section>
  </div>
  <button type="button" class="debug-toggle" id="debugToggle" aria-controls="debugPanel" aria-expanded="false" hidden>Debug</button>
  <section class="debug-panel" id="debugPanel" hidden>
    <div class="debug-header">
      <span>Debug console</span>
      <div class="debug-actions">
        <button type="button" id="debugClear">Clear</button>
        <button type="button" id="debugClose" aria-label="Hide debug console">Hide</button>
      </div>
    </div>
    <pre id="debugOutput" class="debug-output" role="log" aria-live="polite"></pre>
  </section>

  <script>
    // Block app interaction until user presses Continue
    const startupOverlayEl = document.getElementById('startupOverlay');
    const startupContinueBtn = document.getElementById('startupContinue');
    const startupPlayVideoBtn = document.getElementById('startupPlayVideo');
    const startupSkipBtn = document.getElementById('startupSkip');
    const startupPlayAgainBtn = document.getElementById('startupPlayAgain');
    const startupVideoHeader = document.getElementById('startupVideoHeader');
    const startupVideoContainer = document.getElementById('startupVideoContainer');
    const startupVimeoEl = document.getElementById('startupVimeo');
    // Helper to stop/pause the Vimeo player and optionally hide the UI
    function stopStartupVideo({ hide = false, unload = false } = {}) {
      try {
        if (unload) {
          startupVimeoEl?.contentWindow?.postMessage({ method: 'unload' }, '*');
        } else {
          startupVimeoEl?.contentWindow?.postMessage({ method: 'pause' }, '*');
        }
      } catch {}
      if (hide) {
        if (startupVideoContainer) startupVideoContainer.hidden = true;
        if (startupVideoHeader) startupVideoHeader.hidden = true;
      }
    }
    // Prevent scrolling the page while overlay is visible
    document.body.style.overflow = 'hidden';
    startupContinueBtn?.addEventListener('click', () => {
      // Ensure video audio stops when leaving overlay
      try { stopStartupVideo({ hide: true, unload: true }); } catch {}
      startupOverlayEl?.setAttribute('hidden', '');
      document.body.style.overflow = '';
      // Move focus to the first actionable control
      const firstButton = document.querySelector('button, [href], input, select, textarea');
      if (firstButton instanceof HTMLElement) firstButton.focus();
    });

    function setStartupButtons({ showPlay=false, showSkip=false, showContinue=false, showPlayAgain=false }) {
      if (startupPlayVideoBtn) startupPlayVideoBtn.hidden = !showPlay;
      if (startupSkipBtn) startupSkipBtn.hidden = !showSkip;
      if (startupContinueBtn) startupContinueBtn.hidden = !showContinue;
      if (startupPlayAgainBtn) startupPlayAgainBtn.hidden = !showPlayAgain;
    }

    function forceStartupVideoUnmuted() {
      try {
        // Vimeo sometimes starts muted even with volume set; explicitly unmute.
        startupVimeoEl?.contentWindow?.postMessage({ method: 'setMuted', value: false }, '*');
        startupVimeoEl?.contentWindow?.postMessage({ method: 'setVolume', value: 1 }, '*');
      } catch {}
    }

    // Play Video button: reveal iframe, unmute and request autoplay
    startupPlayVideoBtn?.addEventListener('click', () => {
      if (startupVideoContainer) startupVideoContainer.hidden = false;
      if (startupVideoHeader) startupVideoHeader.hidden = false;
      const contentBox = document.getElementById('startupContent');
      if (contentBox) contentBox.hidden = true;
      // Ask Vimeo to play (user gesture present); guard errors
      try {
        // Ensure audio is not muted when starting
        forceStartupVideoUnmuted();
        startupVimeoEl?.contentWindow?.postMessage({ method: 'play' }, '*');
      } catch {}
      // Belt-and-suspenders: repeat shortly after play in case Vimeo applies mute on start.
      window.setTimeout(forceStartupVideoUnmuted, 300);
      setStartupButtons({ showPlay:false, showSkip:true, showContinue:false, showPlayAgain:false });
      // Fallback: reveal Continue after 1m49s (109000 ms) if no ended event
      window.__startupVideoFallbackTimer = window.setTimeout(() => {
        if (startupContinueBtn) {
          setStartupButtons({ showPlay:false, showSkip:false, showContinue:true, showPlayAgain:true });
          startupContinueBtn.focus();
        }
      }, 109000);
    });

    // Skip behaves like Continue, but stop video first to prevent lingering audio
    startupSkipBtn?.addEventListener('click', () => {
      stopStartupVideo({ hide: true, unload: true });
      startupContinueBtn?.click();
    });

    // Play Again: restart video, re-show Skip, hide Continue until it ends again
    startupPlayAgainBtn?.addEventListener('click', () => {
      setStartupButtons({ showPlay:false, showSkip:true, showContinue:false, showPlayAgain:false });
      try {
        startupVimeoEl?.contentWindow?.postMessage({ method: 'setCurrentTime', value: 0 }, '*');
        forceStartupVideoUnmuted();
        startupVimeoEl?.contentWindow?.postMessage({ method: 'play' }, '*');
      } catch {}
      window.setTimeout(forceStartupVideoUnmuted, 300);
    });

    // Listen for Vimeo player events to detect end
    window.addEventListener('message', (event) => {
      const origin = event.origin || '';
      if (!origin.includes('vimeo.com')) return;
      let payload = event.data;
      if (typeof payload === 'string') {
        try { payload = JSON.parse(payload); } catch { payload = null; }
      }
      if (!payload) return;
      if (payload.event === 'ended' || payload.method === 'ended') {
        // Video finished: show Continue and Play Again, remove Skip
        setStartupButtons({ showPlay:false, showSkip:false, showContinue:true, showPlayAgain:true });
        startupContinueBtn.focus();
        // Clear fallback timer if set
        if (window.__startupVideoFallbackTimer) {
          window.clearTimeout(window.__startupVideoFallbackTimer);
          window.__startupVideoFallbackTimer = null;
        }
      }
    });
    const languageEl = document.getElementById('language');
    const micSelect = document.getElementById('microphone');
    const levelBar = document.getElementById('level');
    const baselineStepEl = document.querySelector('[data-step="baseline"]');
    const scenarioStepEl = document.querySelector('[data-step="scenario"]');
    const evaluationStepEl = document.querySelector('[data-step="evaluation"]');
    const baselineNextBtn = document.getElementById('baselineNext');
    const scenarioNextBtn = document.getElementById('scenarioNext');
    const scenarioViewBtn = document.getElementById('scenarioViewBtn');
    const evaluationSummaryEl = document.getElementById('evaluationSummary');
    const baselineNextHintEl = document.getElementById('baselineNextHint');
    const scenarioNextHintEl = document.getElementById('scenarioNextHint');
    let studentContextBannerEl = document.getElementById('studentContextBanner');
    let studentContextNameEl = document.getElementById('studentContextName');
    let studentContextContactIdEl = document.getElementById('studentContextContactId');
  const sendAssessmentInfoBtn = document.getElementById('sendAssessmentInfo');
  const sendAssessmentHtmlBtn = document.getElementById('sendAssessmentHtml');
    const saveAssessmentAudioBtn = document.getElementById('saveAssessmentAudio');
    const infoCardEl = document.querySelector('header .info-card');
    const settingsCardEl = document.getElementById('sessionSettings');
    const settingsToggleBtn = document.getElementById('settingsToggle');
    const settingsModalEl = document.getElementById('settingsModal');
    const settingsCloseBtn = document.getElementById('settingsClose');

    function mountScenarioViewButton() {
      if (!scenarioViewBtn || !scenarioStepEl) return;
      const host = scenarioStepEl.querySelector('.slot:not([hidden]) .scenario-view-btn-host');
      if (!(host instanceof HTMLElement)) return;
      if (scenarioViewBtn.parentElement !== host) host.appendChild(scenarioViewBtn);
    }

    // Ensure the Scenario button stays inside the visible "white question box" (slot)
    mountScenarioViewButton();
    if (scenarioStepEl) {
      const slotVisibilityObserver = new MutationObserver(() => mountScenarioViewButton());
      slotVisibilityObserver.observe(scenarioStepEl, { subtree: true, attributes: true, attributeFilter: ['hidden'] });
    }
    // Show instruction hint box when Next becomes active
    function attachNextHint(buttonEl, hintEl) {
      if (!buttonEl || !hintEl) return;
      const updateHint = () => {
        const visible = !buttonEl.disabled && !buttonEl.hasAttribute('hidden');
        hintEl.classList.toggle('visible', visible);
        hintEl.setAttribute('aria-hidden', String(!visible));
      };
      updateHint();
      const obs = new MutationObserver(updateHint);
      obs.observe(buttonEl, { attributes: true, attributeFilter: ['disabled', 'hidden'] });
    }

    attachNextHint(baselineNextBtn, baselineNextHintEl);
        // Show Scenario Overview modal when baseline Next is pressed
        const scenarioOverviewOverlayEl = document.getElementById('scenarioOverviewOverlay');
        const scenarioOverviewCloseBtn = document.getElementById('scenarioOverviewClose');
        const scenarioOverviewContinueBtn = document.getElementById('scenarioOverviewContinue');
        let scenarioOverviewShown = false;

        function showScenarioOverview({ focus = 'continue', force = false } = {}) {
          if (!scenarioOverviewOverlayEl) return;
          if (scenarioOverviewShown && !force) return;
          scenarioOverviewOverlayEl.removeAttribute('hidden');
          const prevOverflow = document.body.style.overflow;
          document.body.dataset.prevOverflow = prevOverflow;
          document.body.style.overflow = 'hidden';
          // Toggle buttons based on invocation mode
          if (scenarioOverviewCloseBtn) {
            if (focus === 'continue') {
              scenarioOverviewCloseBtn.setAttribute('hidden', '');
            } else {
              scenarioOverviewCloseBtn.removeAttribute('hidden');
            }
          }
          if (scenarioOverviewContinueBtn) {
            if (focus === 'close') {
              scenarioOverviewContinueBtn.setAttribute('hidden', '');
            } else {
              scenarioOverviewContinueBtn.removeAttribute('hidden');
            }
          }
          const focusSelector = focus === 'close' ? '#scenarioOverviewClose' : '#scenarioOverviewContinue';
          const focusEl = scenarioOverviewOverlayEl.querySelector(focusSelector) || scenarioOverviewOverlayEl;
          if (focusEl instanceof HTMLElement) {
            try { focusEl.focus({ preventScroll: true }); } catch { focusEl.focus(); }
          }
          scenarioOverviewShown = true;
        }
        baselineNextBtn?.addEventListener('click', (e) => {
          e.preventDefault();
          // Only if enabled (user completed baseline)
          if (baselineNextBtn.disabled) return;
          // First advance to scenario step
          if (baselineStepEl && scenarioStepEl) {
            baselineStepEl.hidden = true;
            scenarioStepEl.hidden = false;
          }
          // Then show overlay on top of Recording 1
          showScenarioOverview({ focus: 'continue' });
        });

        scenarioOverviewCloseBtn?.addEventListener('click', () => {
          // Just hide overlay and restore scroll; do not advance
          scenarioOverviewOverlayEl?.setAttribute('hidden', '');
          const prevOverflow = document.body.dataset.prevOverflow || '';
          document.body.style.overflow = prevOverflow;
        });
        scenarioOverviewContinueBtn?.addEventListener('click', () => {
          // Hide overlay and restore scroll, then advance to scenario
          scenarioOverviewOverlayEl?.setAttribute('hidden', '');
          const prevOverflow = document.body.dataset.prevOverflow || '';
          document.body.style.overflow = prevOverflow;
          if (baselineStepEl && scenarioStepEl) {
            baselineStepEl.hidden = true;
            scenarioStepEl.hidden = false;
            const firstAction = scenarioStepEl.querySelector('[data-slot="scenario1"] [data-action="start"]') || scenarioStepEl.querySelector('button');
            if (firstAction instanceof HTMLElement) firstAction.focus();
          }
        });
        // Allow reopening the scenario overview from the Scenario button
        scenarioViewBtn?.addEventListener('click', () => {
          showScenarioOverview({ focus: 'close', force: true });
        });

        // Auto-show the scenario overview whenever the Scenario step becomes visible
        if (scenarioStepEl) {
          const stepObserver = new MutationObserver(() => {
            if (!scenarioStepEl.hidden) {
              showScenarioOverview({ focus: 'continue' });
            }
          });
          stepObserver.observe(scenarioStepEl, { attributes: true, attributeFilter: ['hidden'] });
          // If already visible on load (e.g., direct navigation), show it too
          if (!scenarioStepEl.hidden) {
            showScenarioOverview({ focus: 'continue' });
          }
        }
    attachNextHint(scenarioNextBtn, scenarioNextHintEl);
        // Ensure Scenario button popup does not show specific instructional lines
        scenarioViewBtn?.addEventListener('click', (event) => {
          const overlay = document.getElementById('scenarioOverviewOverlay');
          if (overlay) {
            // Remove the two sentences if present
            const paragraphs = Array.from(overlay.querySelectorAll('p'));
            paragraphs.forEach((p) => {
              const text = (p.textContent || '').trim();
              if (
                text.startsWith('You will now be asked to respond to three specific parts of the following scenario.') ||
                text.startsWith('Press the Continue button to proceed.')
              ) {
                p.remove();
              }
            });
            // Hide the Continue button when opened via Scenario button
            const continueBtn = overlay.querySelector('#scenarioOverviewContinue');
            if (continueBtn instanceof HTMLElement) {
              continueBtn.setAttribute('hidden', '');
            }
            const closeBtn = overlay.querySelector('#scenarioOverviewClose');
            if (closeBtn instanceof HTMLElement) {
              closeBtn.removeAttribute('hidden');
            }
          }
        }, { once: true });
    const assessmentStatusEl = document.getElementById('assessmentStatus');
    const assessmentStatusBadgeEl = assessmentStatusEl?.querySelector('[data-role="assessment-status-badge"]');
    const assessmentStatusTimestampEl = assessmentStatusEl?.querySelector('[data-role="assessment-status-timestamp"]');
    const assessmentStatusSnapshotEl = assessmentStatusEl?.querySelector('[data-role="assessment-status-snapshot"]');
  const assessmentStatusDebugEl = assessmentStatusEl?.querySelector('[data-role="assessment-debug"]');
  const assessmentStatusDebugOutputEl = assessmentStatusEl?.querySelector('[data-role="assessment-debug-output"]');
  const assessmentStatusDebugClearEl = assessmentStatusEl?.querySelector('[data-role="assessment-debug-clear"]');
  const assessmentStatusVisibilityInput = document.getElementById('showAssessmentStatus');
  const assessmentStatusDebugInput = document.getElementById('showAssessmentStatusDebug');
    const assessmentStatusButtons = assessmentStatusEl ? Array.from(assessmentStatusEl.querySelectorAll('[data-role="assessment-status-trigger"]')) : [];
    const downloadListEl = document.getElementById('downloadList');
    const debugPanelEl = document.getElementById('debugPanel');
    const debugToggleBtn = document.getElementById('debugToggle');
    const debugOutputEl = document.getElementById('debugOutput');
    const debugClearBtn = document.getElementById('debugClear');
  const debugCloseBtn = document.getElementById('debugClose');
  const ZAPIER_BASIC_WEBHOOK_URL = 'https://hooks.zapier.com/hooks/catch/18802327/u8r4mhl/';
  const POWER_AUTOMATE_HTML_ENDPOINT = 'https://default63871d3cd05d49fa86b6420054699f.b4.environment.api.powerplatform.com:443/powerautomate/automations/direct/workflows/d1a82ecee7ea45e3bf547d95328bf608/triggers/manual/paths/invoke?api-version=1&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=EIK-0MTUNg1RNEpxdyoPkguCRP1glLWdi-UkNkAaP-0';
  const POWER_AUTOMATE_AUDIO_ENDPOINT = 'https://default63871d3cd05d49fa86b6420054699f.b4.environment.api.powerplatform.com:443/powerautomate/automations/direct/workflows/d196850c386f4beebb1d8df6315d394f/triggers/manual/paths/invoke?api-version=1&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=nIiqeRGhNNQXVjYyO4g0AnI0YdLMJzNG-93k4guOnnw';
  const REMOTE_RECORDING1_ENDPOINT = 'https://default4f0de57b35694b51b8c8b1dadd7ba8.19.environment.api.powerplatform.com:443/powerautomate/automations/direct/workflows/9056c26165dd47c98a33681cd5a81c16/triggers/manual/paths/invoke?api-version=1&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=6O8dX71eTLd0OCd43-cYGH2k9jW0eh1g3n77B60iVhw';
  const REMOTE_RECORDING2_ENDPOINT = 'https://default4f0de57b35694b51b8c8b1dadd7ba8.19.environment.api.powerplatform.com:443/powerautomate/automations/direct/workflows/ecf70a7119224828abb629c683da176a/triggers/manual/paths/invoke?api-version=1&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=dlKIYNaTm0zNAfOkIiykmUEyA6wCtp3zXE3ZShlFWiU';
  const REMOTE_RECORDING3_ENDPOINT = 'https://default4f0de57b35694b51b8c8b1dadd7ba8.19.environment.api.powerplatform.com:443/powerautomate/automations/direct/workflows/acb23dbb4eb643548465e37b1d053caa/triggers/manual/paths/invoke?api-version=1&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=ZLqcnTWxJTi1HFOkO1Rc37FiTIXyz1v_MReoGXjJdPc';
  const DEFAULT_STUDENT_NAME = 'Richard Wray';
  const DEFAULT_CONTACT_ID = '14801549';

    const vocalAssessmentResult = {
      overall: 'InProgress',
      timestamp: Date.now(),
      details: null
    };
    window.VocalAssessmentResult = vocalAssessmentResult;
    let autoDeliveryInFlight = false;
    if (!window.VocalStudentInfo || typeof window.VocalStudentInfo !== 'object') {
      window.VocalStudentInfo = { studentName: DEFAULT_STUDENT_NAME, contactId: DEFAULT_CONTACT_ID };
    }
    if (document.body?.dataset) {
      if (!document.body.dataset.studentName) {
        document.body.dataset.studentName = DEFAULT_STUDENT_NAME;
      }
      if (!document.body.dataset.contactId) {
        document.body.dataset.contactId = DEFAULT_CONTACT_ID;
      }
    }
    applyUrlStudentContext();
    updateStudentContextBanner();
    window.addEventListener('hashchange', () => updateStudentContextBanner());
    window.addEventListener('hashchange', () => updateAdminTranscriptEditing());

    function setDebugPanelVisible(visible) {
      if (!debugPanelEl || !debugToggleBtn) return;
      const nextVisible = Boolean(visible && assessmentStatusDebugVisible);
      debugPanelEl.hidden = !nextVisible;
      debugToggleBtn.setAttribute('aria-expanded', nextVisible ? 'true' : 'false');
    }

  let settingsVisible = false;
  let settingsReturnFocusEl = null;
  let settingsPreviousOverflow = '';
  let assessmentStatusVisible = false;
  let assessmentStatusDebugVisible = false;
  // Live mic preview for Settings modal (independent of recording)
  let settingsPreviewVisible = false;
  let settingsPreviewCtx = null;
  let settingsPreviewAnalyser = null;
  let settingsPreviewSource = null;
  let settingsPreviewStream = null;
  let settingsPreviewLoop = null;

  function stopSettingsLevelPreview() {
    settingsPreviewVisible = false;
    if (settingsPreviewLoop) {
      cancelAnimationFrame(settingsPreviewLoop);
      settingsPreviewLoop = null;
    }
    if (settingsPreviewSource) {
      try { settingsPreviewSource.disconnect(); } catch {}
      settingsPreviewSource = null;
    }
    if (settingsPreviewCtx) {
      try { settingsPreviewCtx.close(); } catch {}
      settingsPreviewCtx = null;
    }
    if (settingsPreviewStream) {
      try { settingsPreviewStream.getTracks().forEach((t) => t.stop()); } catch {}
      settingsPreviewStream = null;
    }
  }

  async function startSettingsLevelPreview() {
    // If already recording, the main monitor updates the bar; no separate preview needed
    if (isRecording || !settingsVisible) return;
    try {
      stopSettingsLevelPreview();
      settingsPreviewVisible = true;
      // Use currently selected mic
      const stream = await openMicrophone();
      settingsPreviewStream = stream;
      const AudioContextRef = window.AudioContext || window.webkitAudioContext;
      settingsPreviewCtx = new AudioContextRef({ latencyHint: 'interactive' });
      settingsPreviewAnalyser = settingsPreviewCtx.createAnalyser();
      settingsPreviewAnalyser.fftSize = 4096; // same resolution as main monitor
      settingsPreviewSource = settingsPreviewCtx.createMediaStreamSource(stream);
      settingsPreviewSource.connect(settingsPreviewAnalyser);

      const localBuffer = new Float32Array(2048);
      const tick = () => {
        if (!settingsPreviewVisible || !settingsPreviewAnalyser || !settingsVisible || isRecording) {
          // Stop if modal hidden or a recording begins
          stopSettingsLevelPreview();
          return;
        }
        try {
          settingsPreviewAnalyser.getFloatTimeDomainData(localBuffer);
          let sum = 0;
          for (let i = 0; i < localBuffer.length; i++) sum += localBuffer[i] * localBuffer[i];
          const rms = Math.sqrt(sum / localBuffer.length);
          const clamped = Math.max(0, Math.min(1, rms * 8));
          const meterWidth = Math.max(4, clamped * 100);
          if (levelBar) levelBar.style.width = `${meterWidth}%`;
        } catch {}
        settingsPreviewLoop = requestAnimationFrame(tick);
      };
      settingsPreviewLoop = requestAnimationFrame(tick);
    } catch (err) {
      // Silently ignore – level bar preview is non-critical
    }
  }

    function handleSettingsKeydown(event) {
      if (event.key === 'Escape') {
        event.stopPropagation();
        setSettingsVisible(false, { focusToggle: true });
      }
    }

    function setSettingsVisible(visible, { focusToggle = false } = {}) {
      if (!settingsCardEl || !settingsToggleBtn || !settingsModalEl) return;
      settingsVisible = visible;
      settingsToggleBtn.setAttribute('aria-expanded', visible ? 'true' : 'false');
      settingsToggleBtn.textContent = 'SETTINGS';

      if (visible) {
        settingsReturnFocusEl = document.activeElement instanceof HTMLElement ? document.activeElement : null;
        settingsModalEl.removeAttribute('hidden');
        settingsCardEl.removeAttribute('hidden');
        settingsPreviousOverflow = document.body.style.overflow;
        document.body.style.overflow = 'hidden';
        document.addEventListener('keydown', handleSettingsKeydown);
        // Kick off live level preview when modal opens
        startSettingsLevelPreview();

        const focusCandidate = settingsCardEl.querySelector('[data-autofocus],[autofocus], select, button, input, textarea') || settingsCloseBtn || settingsCardEl;
        const focusTarget = focusCandidate instanceof HTMLElement ? focusCandidate : settingsCardEl;
        window.requestAnimationFrame(() => {
          try {
            focusTarget.focus({ preventScroll: true });
          } catch (err) {
            focusTarget.focus();
          }
        });
      } else {
        settingsCardEl.setAttribute('hidden', '');
        settingsModalEl.setAttribute('hidden', '');
  document.body.style.overflow = settingsPreviousOverflow;
  settingsPreviousOverflow = '';
        document.removeEventListener('keydown', handleSettingsKeydown);
        // Stop preview when modal closes
        stopSettingsLevelPreview();

        if (focusToggle && settingsToggleBtn instanceof HTMLElement) {
          settingsToggleBtn.focus();
        } else if (!focusToggle && settingsReturnFocusEl && document.contains(settingsReturnFocusEl)) {
          settingsReturnFocusEl.focus();
        }
        settingsReturnFocusEl = null;
      }
    }

    function setAssessmentStatusVisible(visible) {
      assessmentStatusVisible = visible;
      if (assessmentStatusEl) {
        assessmentStatusEl.hidden = !visible;
        assessmentStatusEl.style.display = visible ? 'flex' : 'none';
      }
      if (assessmentStatusVisibilityInput) {
        assessmentStatusVisibilityInput.checked = visible;
        assessmentStatusVisibilityInput.setAttribute('aria-checked', visible ? 'true' : 'false');
      }
    }

    function setAssessmentStatusDebugVisible(visible) {
      assessmentStatusDebugVisible = visible;
      if (assessmentStatusDebugEl) {
        assessmentStatusDebugEl.hidden = !visible;
      }
      if (assessmentStatusDebugInput) {
        assessmentStatusDebugInput.checked = visible;
        assessmentStatusDebugInput.setAttribute('aria-checked', visible ? 'true' : 'false');
      }
      if (debugToggleBtn) {
        debugToggleBtn.hidden = !visible;
      }
      if (!visible) {
        setDebugPanelVisible(false);
      }
    }

    function debugStringify(detail) {
      if (detail === undefined || detail === null) return '';
      if (detail instanceof Error) return `${detail.name}: ${detail.message}`;
      if (typeof detail === 'string') return detail;
      if (typeof detail === 'number' || typeof detail === 'boolean') return String(detail);
      try {
        return JSON.stringify(detail);
      } catch (err) {
        return '[unserializable detail]';
      }
    }

    function debugLog(message, detail) {
      const ts = new Date().toISOString();
      const extra = debugStringify(detail);
      const line = extra ? `[${ts}] ${message} — ${extra}` : `[${ts}] ${message}`;
      if (debugOutputEl) {
        debugOutputEl.textContent += `${line}\n`;
        debugOutputEl.scrollTop = debugOutputEl.scrollHeight;
      }
      if (assessmentStatusDebugVisible && debugPanelEl && debugPanelEl.hidden) {
        const maybeError = /error|fail|denied/i.test(message) || (typeof extra === 'string' && /error|fail|denied/i.test(extra));
        if (maybeError) {
          setDebugPanelVisible(true);
        }
      }
      if (detail !== undefined) {
        console.log('[Vocal Test]', message, detail);
      } else {
        console.log('[Vocal Test]', message);
      }
    }

    function normaliseStatusText(status) {
      if (!status) return 'In progress';
      const trimmed = String(status).trim();
      const lower = trimmed.toLowerCase();
      if (lower === 'inprogress' || lower === 'in progress') return 'In progress';
      if (lower === 'met') return 'Met';
      if (lower === 'not met' || lower === 'unmet' || lower === 'un-met') return 'Not met';
      return trimmed;
    }

    function renderAssessmentStatusSnapshot(result) {
      if (!assessmentStatusSnapshotEl) return;
      const snapshot = {
        overall: result?.overall ?? null,
        timestamp: result?.timestamp ?? null,
        updatedAt: result?.timestamp ? new Date(result.timestamp).toLocaleString() : null,
        details: result?.details ?? null
      };
      let formatted = '';
      try {
        formatted = JSON.stringify(snapshot, (key, value) => {
          if (typeof value === 'function') return '[Function]';
          if (value instanceof Date) return value.toISOString();
          return value;
        }, 2);
      } catch (err) {
        formatted = debugStringify(snapshot);
      }
      assessmentStatusSnapshotEl.textContent = `window.VocalAssessmentResult = ${formatted}`;
    }

    const assessmentStatusDebugHistory = [];

    function renderAssessmentStatusDebug() {
      if (!assessmentStatusDebugOutputEl) return;
      if (!assessmentStatusDebugHistory.length) {
        assessmentStatusDebugOutputEl.textContent = '(No events yet)';
        return;
      }
      assessmentStatusDebugOutputEl.textContent = assessmentStatusDebugHistory.join('\n');
      assessmentStatusDebugOutputEl.scrollTop = assessmentStatusDebugOutputEl.scrollHeight;
    }

    function appendAssessmentStatusDebug(message, detail) {
      const ts = new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit', second: '2-digit' });
      let entry = `[${ts}] ${message}`;
      if (detail !== undefined) {
        entry = `${entry} — ${debugStringify(detail)}`;
      }
      assessmentStatusDebugHistory.push(entry);
      if (assessmentStatusDebugHistory.length > 200) {
        assessmentStatusDebugHistory.shift();
      }
      renderAssessmentStatusDebug();
    }

    renderAssessmentStatusDebug();

    function updateAssessmentStatus(result) {
      const statusText = normaliseStatusText(result?.overall);
      const lower = statusText.toLowerCase();
      if (assessmentStatusBadgeEl) {
        assessmentStatusBadgeEl.textContent = statusText;
        assessmentStatusBadgeEl.classList.remove('is-inprogress', 'is-met', 'is-not-met');
        if (lower === 'met') {
          assessmentStatusBadgeEl.classList.add('is-met');
        } else if (lower === 'not met') {
          assessmentStatusBadgeEl.classList.add('is-not-met');
        } else {
          assessmentStatusBadgeEl.classList.add('is-inprogress');
        }
      }
      if (assessmentStatusTimestampEl) {
        const timestamp = result?.timestamp ? new Date(result.timestamp) : new Date();
        assessmentStatusTimestampEl.textContent = `Updated ${timestamp.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' })}`;
      }
      renderAssessmentStatusSnapshot(result);
    }

    function emitAssessmentStatus(result = vocalAssessmentResult) {
      const payload = result || vocalAssessmentResult;
      if (typeof window.broadcastVocalAssessmentResult === 'function') {
        try {
          window.broadcastVocalAssessmentResult(payload);
          appendAssessmentStatusDebug('Broadcasted assessment status (parent postMessage)', payload);
        } catch (err) {
          appendAssessmentStatusDebug('Failed to emit assessment status', err);
          debugLog('Unable to emit assessment status', err);
        }
      } else {
        try {
          window.postMessage({ type: 'vocal-status', status: payload }, '*');
          appendAssessmentStatusDebug('Broadcasted assessment status (local postMessage)', payload);
        } catch (err) {
          appendAssessmentStatusDebug('Failed to emit assessment status', err);
          debugLog('Unable to emit assessment status', err);
        }
      }
    }

    function updateSendInfoAvailability(status) {
      const ready = status && status !== 'InProgress' && status !== 'In progress';
      if (sendAssessmentInfoBtn) {
        sendAssessmentInfoBtn.disabled = !ready;
        if (!ready) {
          sendAssessmentInfoBtn.textContent = 'Send BASIC';
        }
      }
      if (sendAssessmentHtmlBtn) {
        sendAssessmentHtmlBtn.disabled = !ready;
        if (!ready) {
          sendAssessmentHtmlBtn.textContent = 'Send HTML';
        }
      }
      if (saveAssessmentAudioBtn) {
        const audioReady = ready && ['scenario1', 'scenario2', 'scenario3'].every((slotId) => {
          const slot = slots?.[slotId];
          return slot?.blob instanceof Blob;
        });
        saveAssessmentAudioBtn.disabled = !audioReady;
        if (!audioReady) {
          saveAssessmentAudioBtn.textContent = 'Save Audio';
        }
      }
    }

    function pickFirstValue(...candidates) {
      for (const candidate of candidates) {
        if (candidate === undefined || candidate === null) continue;
        const text = typeof candidate === 'string' ? candidate : String(candidate);
        if (text && text.trim()) {
          return candidate;
        }
      }
      return '';
    }

    function ensureContactIdValue(value) {
      if (value === undefined || value === null) return 'xxxx';
      const text = String(value).trim();
      if (!text) return 'xxxx';
      const numeric = Number(text);
      return Number.isFinite(numeric) ? numeric : text;
    }

    function ensureTextValue(value) {
      if (value === undefined || value === null) return 'xxxx';
      const text = String(value).trim();
      return text || 'xxxx';
    }

    function blobToBase64(blob) {
      return new Promise((resolve, reject) => {
        if (!(blob instanceof Blob)) {
          reject(new TypeError('Expected Blob instance'));
          return;
        }
        const reader = new FileReader();
        reader.onerror = () => {
          reader.abort();
          reject(new Error('Failed to read blob data')); 
        };
        reader.onloadend = () => {
          const { result } = reader;
          if (typeof result !== 'string') {
            reject(new Error('Unexpected reader result'));
            return;
          }
          const commaIndex = result.indexOf(',');
          resolve(commaIndex >= 0 ? result.slice(commaIndex + 1) : result);
        };
        reader.readAsDataURL(blob);
      });
    }

    function getStudentContext() {
      const bodyDataset = document.body?.dataset || {};
      const studentInfo = window.VocalStudentInfo || window.vocalStudentInfo || window.studentInfo || {};
      const contactSource = pickFirstValue(
        vocalAssessmentResult?.details?.contactId,
        studentInfo?.contactId,
        window.VocalStudent?.contactId,
        window.VocalAssessmentContactId,
        bodyDataset.contactId
      );
      const nameSource = pickFirstValue(
        vocalAssessmentResult?.details?.studentName,
        studentInfo?.studentName,
        studentInfo?.name,
        window.VocalStudent?.studentName,
        window.VocalStudent?.name,
        bodyDataset.studentName
      );
      const emailSource = pickFirstValue(
        vocalAssessmentResult?.details?.studentEmail,
        studentInfo?.studentEmail,
        studentInfo?.email,
        window.VocalStudent?.studentEmail,
        window.VocalStudent?.email,
        bodyDataset.studentEmail
      );
      let contactIdValue = ensureContactIdValue(contactSource);
      let contactIdText = contactIdValue === 'xxxx' ? '' : String(contactIdValue).trim();
      if (!contactIdText) {
        contactIdValue = DEFAULT_CONTACT_ID;
        contactIdText = DEFAULT_CONTACT_ID;
      }
      let studentName = ensureTextValue(nameSource);
      if (!studentName || studentName.toLowerCase() === 'xxxx') {
        studentName = DEFAULT_STUDENT_NAME;
      }
      let studentEmail = ensureTextValue(emailSource);
      if (!studentEmail || studentEmail.toLowerCase() === 'xxxx') {
        studentEmail = '';
      }
      return { contactIdValue, contactIdText, studentName, studentEmail };
    }

    function updateStudentContextBanner() {
      const isAdmin = window.location.hash === '#/admin';
      const { studentName, contactIdText } = getStudentContext();
      const baseName = studentName || DEFAULT_STUDENT_NAME;
      const resolvedContactId = contactIdText || DEFAULT_CONTACT_ID;
      // Non-admin: remove banner if present.
      if (!isAdmin) {
        if (studentContextBannerEl && studentContextBannerEl.parentNode) {
          studentContextBannerEl.parentNode.removeChild(studentContextBannerEl);
        }
        studentContextBannerEl = null;
        studentContextNameEl = null;
        studentContextContactIdEl = null;
        return;
      }
      // Admin mode: create banner if missing.
      if (!studentContextBannerEl) {
        const mainEl = document.querySelector('main');
        if (!mainEl) return;
        studentContextBannerEl = document.createElement('div');
        studentContextBannerEl.className = 'student-context';
        studentContextBannerEl.id = 'studentContextBanner';
        studentContextBannerEl.setAttribute('aria-live', 'polite');
        studentContextNameEl = document.createElement('div');
        studentContextNameEl.className = 'student-context__name';
        studentContextNameEl.id = 'studentContextName';
        studentContextContactIdEl = document.createElement('span');
        studentContextContactIdEl.id = 'studentContextContactId';
        const metaDiv = document.createElement('div');
        metaDiv.className = 'student-context__meta';
        metaDiv.innerHTML = 'Contact ID: ';
        metaDiv.appendChild(studentContextContactIdEl);
        studentContextBannerEl.appendChild(studentContextNameEl);
        studentContextBannerEl.appendChild(metaDiv);
        mainEl.insertBefore(studentContextBannerEl, mainEl.firstChild.nextSibling);
      }
      const alreadyAdmin = / - Admin Mode$/i.test(studentContextNameEl?.textContent || '');
      if (studentContextNameEl) {
        studentContextNameEl.textContent = alreadyAdmin ? studentContextNameEl.textContent : `${baseName} - Admin Mode`;
      }
      if (studentContextContactIdEl) {
        studentContextContactIdEl.textContent = resolvedContactId;
      }
    }

    function ensureEditButton(slot) {
      if (!slot || !slot.transcriptPanel) return;
      const header = slot.transcriptPanel.querySelector('.transcript-header');
      if (!header) return;
      // If button already exists, nothing to do
      if (slot.editBtn && slot.editBtn instanceof HTMLElement) {
        return;
      }
      const btn = document.createElement('button');
      btn.type = 'button';
      btn.className = 'btn-small secondary';
      btn.setAttribute('data-action', 'toggle-edit');
      btn.textContent = 'Edit text';
      header.appendChild(btn);
      slot.editBtn = btn;
      btn.addEventListener('click', () => toggleTranscriptEditor(slot));
    }

    function updateAdminTranscriptEditing() {
      const isAdmin = window.location.hash === '#/admin';
      // Show edit controls only in Admin mode
      Object.values(slots).forEach((slot) => {
        if (!slot || !slot.transcriptPanel) return;
        if (isAdmin) {
          ensureEditButton(slot);
          ensurePlaybackEditButton(slot);
          if (slot.editBtn) slot.editBtn.hidden = false;
          if (slot.playbackEditBtn) slot.playbackEditBtn.hidden = false;
        } else {
          if (slot.editBtn) slot.editBtn.hidden = true;
          if (slot.playbackEditBtn) slot.playbackEditBtn.hidden = true;
          // If editor is open outside admin, close it
          if (slot.editorPanel && !slot.editorPanel.hidden) {
            slot.editorPanel.hidden = true;
            if (slot.transcriptBody) slot.transcriptBody.hidden = false;
            if (slot.editBtn) slot.editBtn.textContent = 'Edit text';
          }
        }
      });
    }

    function ensurePlaybackEditButton(slot) {
      if (!slot || !slot.playbackGroup) return;
      // Already created
      if (slot.playbackEditBtn && slot.playbackEditBtn instanceof HTMLElement) return;
      // Insert next to Play Recording button inside playback tools
      const btn = document.createElement('button');
      btn.type = 'button';
      btn.className = 'secondary';
      btn.setAttribute('data-action', 'toggle-edit');
      btn.textContent = 'Edit Transcription';
      // Place after play button when available
      if (slot.playBtn && slot.playBtn.parentNode === slot.playbackGroup) {
        slot.playBtn.insertAdjacentElement('afterend', btn);
      } else {
        slot.playbackGroup.appendChild(btn);
      }
      slot.playbackEditBtn = btn;
      btn.addEventListener('click', () => toggleTranscriptEditor(slot));
      // Respect current admin visibility state
      const isAdmin = window.location.hash === '#/admin';
      btn.hidden = !isAdmin;
    }

    function applyUrlStudentContext() {
      if (typeof window.URLSearchParams !== 'function') {
        return;
      }
      let params;
      try {
        params = new URLSearchParams(window.location?.search || '');
      } catch (err) {
        debugLog('Unable to parse URL parameters', err);
        return;
      }
      if (!params || (!params.has('studentName') && !params.has('StudentName') && !params.has('contactId') && !params.has('ContactID') && !params.has('ContactId'))) {
        return;
      }
      const nameCandidate = params.get('studentName') ?? params.get('StudentName');
      const contactCandidate = params.get('contactId') ?? params.get('ContactID') ?? params.get('ContactId');
      const emailCandidate = params.get('studentEmail') ?? params.get('StudentEmail');

      const nextInfo = {
        ...(typeof window.VocalStudentInfo === 'object' && window.VocalStudentInfo ? window.VocalStudentInfo : {})
      };
      let mutated = false;

      if (typeof nameCandidate === 'string' && nameCandidate.trim()) {
        nextInfo.studentName = nameCandidate.trim();
        mutated = true;
      }

      if (typeof contactCandidate === 'string' && contactCandidate.trim()) {
        nextInfo.contactId = contactCandidate.trim();
        mutated = true;
      }

      if (typeof emailCandidate === 'string' && emailCandidate.trim()) {
        nextInfo.studentEmail = emailCandidate.trim();
        mutated = true;
      }

      if (!mutated) {
        return;
      }

      window.VocalStudentInfo = nextInfo;
      if (nextInfo.contactId) {
        window.VocalAssessmentContactId = nextInfo.contactId;
      }

      if (document.body?.dataset) {
        if (nextInfo.studentName) {
          document.body.dataset.studentName = nextInfo.studentName;
        }
        if (nextInfo.contactId) {
          document.body.dataset.contactId = nextInfo.contactId;
        }
        if (nextInfo.studentEmail) {
          document.body.dataset.studentEmail = nextInfo.studentEmail;
        }
      }
    }

    function setAssessmentResult(overall, details = null) {
      vocalAssessmentResult.overall = overall;
      vocalAssessmentResult.timestamp = Date.now();
      vocalAssessmentResult.details = details ?? null;
      updateAssessmentStatus(vocalAssessmentResult);
      appendAssessmentStatusDebug(`Status set to ${normaliseStatusText(vocalAssessmentResult.overall)}`, vocalAssessmentResult.details ?? undefined);
      emitAssessmentStatus();
      updateSendInfoAvailability(vocalAssessmentResult.overall);
      return vocalAssessmentResult;
    }

    debugToggleBtn?.addEventListener('click', () => {
      const shouldShow = debugPanelEl?.hidden !== false;
      setDebugPanelVisible(shouldShow);
    });
    debugCloseBtn?.addEventListener('click', () => setDebugPanelVisible(false));
    debugClearBtn?.addEventListener('click', () => {
      if (debugOutputEl) {
        debugOutputEl.textContent = '';
      }
    });

    settingsToggleBtn?.addEventListener('click', () => {
      const nextVisible = !settingsVisible;
      setSettingsVisible(nextVisible, { focusToggle: !nextVisible });
    });

    async function deliverAssessmentInfo(button) {
      if (!button) return;
      const payload = window.VocalAssessmentResult;
      if (!payload || !payload.overall || payload.overall === 'InProgress') {
        debugLog('Send BASIC aborted — assessment not complete');
        return;
      }
  const originalText = button.textContent || 'Send BASIC';
      button.disabled = true;
  button.textContent = 'Sending...';
      try {
        const evaluationHtmlSource = payload?.details?.evaluationHtml
          || evaluationSummaryEl?.innerHTML
          || '';
        const { contactIdText, studentName } = getStudentContext();
        const evaluationEmailHtml = payload?.details?.evaluationEmailHtml
          || buildEvaluationEmailHtml(evaluationHtmlSource, { studentName, contactId: contactIdText });
        const evaluationText = payload?.details?.evaluationText || evaluationSummaryEl?.textContent || '';
        const requestBody = JSON.stringify({
          assessment: payload,
          evaluationEmailHtml,
          evaluationText
        });
  const response = await fetch(ZAPIER_BASIC_WEBHOOK_URL, {
          method: 'POST',
          headers: { 'Content-Type': 'text/plain;charset=UTF-8' },
          body: requestBody
        });
        if (!response.ok) {
          throw new Error(`Webhook responded with ${response.status}`);
        }
  debugLog('Zapier BASIC webhook delivered', { status: response.status, bytes: requestBody.length });
        button.textContent = 'Sent';
      } catch (err) {
        debugLog('Zapier webhook failed', err);
        button.textContent = originalText;
        button.disabled = false;
        return;
      }
      window.setTimeout(() => {
        button.textContent = originalText;
        button.disabled = false;
      }, 2000);
    }

    async function deliverAssessmentHtml(button, overridePayload = null) {
      if (!button) return;
      const payload = overridePayload ?? window.VocalAssessmentResult;
      const usingOverride = Boolean(overridePayload);
      if (!payload || !payload.overall || (!usingOverride && payload.overall === 'InProgress')) {
        debugLog('Send HTML aborted — assessment not complete');
        return;
      }
      const originalText = button.textContent || 'Send HTML';
      button.disabled = true;
      button.textContent = 'Sending...';
      try {
        const { contactIdText, studentName, studentEmail } = getStudentContext();
        const details = payload.details || (payload.details = {});
        const evaluationHtmlSource = details.evaluationHtml
          || evaluationSummaryEl?.innerHTML
          || '';
        const evaluationEmailHtml = details.evaluationEmailHtml
          || buildEvaluationEmailHtml(evaluationHtmlSource, {
            studentName,
            contactId: contactIdText
          });

        details.evaluationHtml = evaluationHtmlSource;
        details.evaluationEmailHtml = evaluationEmailHtml;
        details.studentName = studentName;
        details.contactId = contactIdText;
        details.studentEmail = studentEmail;

        const htmlPayload = {
          StudentName: studentName,
          ContactID: contactIdText,
          EvaluationHtml: evaluationEmailHtml
        };

        window.__LastAssessmentHtmlPayload = { ...htmlPayload, studentEmail };
        debugLog('Power Automate HTML payload prepared', {
          contactId: htmlPayload.ContactID,
          studentName: htmlPayload.StudentName,
          reportHtmlBytes: htmlPayload.EvaluationHtml?.length ?? 0
        });

        const requestBody = JSON.stringify(htmlPayload);

        const response = await fetch(POWER_AUTOMATE_HTML_ENDPOINT, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: requestBody
        });
        if (!response.ok) {
          const responseText = await response.text().catch(() => '(no response body)');
          throw new Error(`Power Automate endpoint responded with ${response.status}: ${responseText}`);
        }
        debugLog('Power Automate HTML payload delivered', { status: response.status, bytes: requestBody.length });
        button.textContent = 'Sent';
      } catch (err) {
        debugLog('Power Automate HTML payload failed', err);
        button.textContent = originalText;
        button.disabled = false;
        if (usingOverride) {
          throw err;
        }
        return;
      }
      window.setTimeout(() => {
        button.textContent = originalText;
        button.disabled = false;
      }, 2000);
      return payload;
    }

    async function deliverAssessmentAudio(button, overridePayload = null) {
      if (!button) return;
      const payload = overridePayload ?? window.VocalAssessmentResult;
      const usingOverride = Boolean(overridePayload);
      if (!payload || !payload.overall || (!usingOverride && payload.overall === 'InProgress')) {
        debugLog('Save Audio aborted — assessment not complete');
        return;
      }
      const scenarioIds = ['scenario1', 'scenario2', 'scenario3'];
      const missing = scenarioIds.filter((slotId) => !(slots?.[slotId]?.blob instanceof Blob));
      if (missing.length) {
        debugLog('Save Audio aborted — missing recordings', { missing });
        return;
      }

      const originalText = button.textContent || 'Save Audio';
      button.disabled = true;
      button.textContent = 'Saving...';

      try {
        const { studentName, contactIdText } = getStudentContext();
        const recordings = [];

        for (let index = 0; index < scenarioIds.length; index += 1) {
          const slotId = scenarioIds[index];
          const slot = slots[slotId];
          const base64Data = await blobToBase64(slot.blob);
          recordings.push({
            FileName: `recording-${index + 1}.webm`,
            Label: slot.label || `Recording ${index + 1}`,
            ContentType: slot.blob?.type || 'audio/webm',
            Base64Data: base64Data
          });
        }

        const audioPayload = {
          StudentName: studentName,
          ContactID: contactIdText,
          Recordings: recordings
        };

        window.__LastAssessmentAudioPayload = {
          StudentName: studentName,
          ContactID: contactIdText,
          Recordings: recordings.map((record) => ({
            FileName: record.FileName,
            Label: record.Label,
            ContentType: record.ContentType,
            Base64Length: record.Base64Data.length
          }))
        };

        const requestBody = JSON.stringify(audioPayload);

        const response = await fetch(POWER_AUTOMATE_AUDIO_ENDPOINT, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: requestBody
        });

        if (!response.ok) {
          const responseText = await response.text().catch(() => '(no response body)');
          throw new Error(`Power Automate audio endpoint responded with ${response.status}: ${responseText}`);
        }

        debugLog('Power Automate audio payload delivered', {
          status: response.status,
          recordings: recordings.length,
          bytes: requestBody.length
        });
        button.textContent = 'Saved';
      } catch (err) {
        debugLog('Power Automate audio payload failed', err);
        button.textContent = originalText;
        button.disabled = false;
        if (usingOverride) {
          throw err;
        }
        return;
      }

      window.setTimeout(() => {
        button.textContent = originalText;
        button.disabled = false;
      }, 2000);
      return payload;
    }

    async function runAutomaticDeliveries() {
      if (autoDeliveryInFlight) {
        debugLog('Automatic delivery skipped — already in progress');
        return;
      }
      if (!sendAssessmentHtmlBtn || !saveAssessmentAudioBtn) {
        debugLog('Automatic delivery skipped — required controls missing');
        return;
      }
      const status = window.VocalAssessmentResult?.overall;
      if (!status || status === 'InProgress') {
        debugLog('Automatic delivery skipped — assessment incomplete');
        return;
      }
      autoDeliveryInFlight = true;
      try {
        debugLog('Automatic delivery started');
        await deliverAssessmentHtml(sendAssessmentHtmlBtn);
        await deliverAssessmentAudio(saveAssessmentAudioBtn);
        debugLog('Automatic delivery completed');
      } catch (err) {
        debugLog('Automatic delivery failed', err);
      } finally {
        autoDeliveryInFlight = false;
      }
    }

    sendAssessmentInfoBtn?.addEventListener('click', () => {
      deliverAssessmentInfo(sendAssessmentInfoBtn);
    });

    sendAssessmentHtmlBtn?.addEventListener('click', () => {
      deliverAssessmentHtml(sendAssessmentHtmlBtn);
    });

    saveAssessmentAudioBtn?.addEventListener('click', () => {
      deliverAssessmentAudio(saveAssessmentAudioBtn);
    });

    settingsCloseBtn?.addEventListener('click', () => setSettingsVisible(false, { focusToggle: true }));
    settingsModalEl?.addEventListener('click', (event) => {
      if (event.target === settingsModalEl) {
        setSettingsVisible(false, { focusToggle: true });
      }
    });

    assessmentStatusButtons.forEach((btn) => {
      btn.addEventListener('click', () => {
        const targetStatus = btn.getAttribute('data-status') || 'InProgress';
        setAssessmentResult(targetStatus);
      });
    });

    assessmentStatusVisibilityInput?.addEventListener('change', (event) => {
      const nextVisible = Boolean(event.target?.checked);
      setAssessmentStatusVisible(nextVisible);
    });

    assessmentStatusDebugInput?.addEventListener('change', (event) => {
      const nextVisible = Boolean(event.target?.checked);
      setAssessmentStatusDebugVisible(nextVisible);
      if (nextVisible) {
        renderAssessmentStatusDebug();
      }
    });

    assessmentStatusDebugClearEl?.addEventListener('click', () => {
      assessmentStatusDebugHistory.length = 0;
      renderAssessmentStatusDebug();
    });

    setSettingsVisible(false);
    debugLog('Vocal Test page initialised');
    const themeTokens = Object.freeze({
      colors: {
        brandBlue: '#0b4a7a',
        brandAccentBlue: '#1e73be',
        panelBlueBg: '#eaf5ff',
        panelBlueBorder: '#d6ecff',
        gold: '#f5d07a',
        goldDark: '#d2a63a',
        contactBg: '#fff5df',
        text: '#0c2740',
        muted: '#7d8b95',
        cardBg: '#ffffff',
        cardBorder: '#efe9df'
      },
      radius: { lg: '12px', md: '8px' },
      shadow: { soft: '0 8px 20px rgba(13,30,41,0.06)' },
      spacing: { gap: '12px', cardPadding: '16px' },
      badge: { bg: '#0b4a7a', color: '#ffffff', radius: '14px' }
    });

    if (typeof window.SpeechSDK === 'undefined') {
      debugLog('Azure Speech SDK not loaded');
      alert('Azure Speech SDK failed to load. Check your connection and refresh.');
    }

  const slotIds = ['baseline', 'scenario1', 'scenario2', 'scenario3'];
  const scenarioOrder = ['scenario1', 'scenario2', 'scenario3'];
  const slots = {};
  const nextSlotMap = { scenario1: 'scenario2', scenario2: 'scenario3' };

    function initSlot(id) {
      const container = document.querySelector(`[data-slot="${id}"]`);
      if (!container) return null;
      // Previously inserted a guidance notice; removed per latest requirements
      const slot = {
        id,
        label: container.getAttribute('data-label') || id,
        container,
        recordBtn: container.querySelector('[data-action="start"]'),
        stopBtn: container.querySelector('[data-action="stop"]'),
        statusEl: container.querySelector('[data-role="status"]'),
        listenBadge: container.querySelector('[data-role="listen"]'),
        timerEl: container.querySelector('[data-role="timer"]'),
        playbackGroup: container.querySelector('[data-role="playback"]'),
        playBtn: container.querySelector('[data-action="play"]'),
  playbackAudio: null,
  playbackEndedHandler: null,
  playbackErrorHandler: null,
  isPlaying: false,
        redoBtn: container.querySelector('[data-action="redo"]'),
        downloadLink: container.querySelector('[data-action="download"]'),
        summaryPanel: container.querySelector('[data-role="summary"]'),
        summaryFields: {
          tempo: container.querySelector('[data-metric="tempo"]'),
          ratio: container.querySelector('[data-metric="ratio"]'),
          loudness: container.querySelector('[data-metric="loudness"]'),
          filler: container.querySelector('[data-metric="filler"]'),
          pause: container.querySelector('[data-metric="pause"]')
        },
        meterContainer: container.querySelector('[data-role="meter"]'),
        meterBar: container.querySelector('[data-role="meter-bar"]'),
        transcriptPanel: container.querySelector('[data-role="transcript"]'),
        transcriptBody: container.querySelector('[data-role="transcript-body"]'),
        editBtn: container.querySelector('[data-action="toggle-edit"]'),
        editorPanel: container.querySelector('[data-role="transcript-editor"]'),
    editorInput: container.querySelector('[data-role="transcript-input"]'),
    alertsPanel: container.querySelector('[data-role="alerts"]'),
    alertsList: container.querySelector('[data-role="alerts-list"]'),
    nextBtn: container.querySelector('[data-action="next-slot"]'),
    nextHint: container.querySelector('[data-role="next-hint"]'),
    nextSlotId: nextSlotMap[id] || null,
    revealed: !container.hasAttribute('hidden'),
        transcriptSegments: [],
        partialLine: null,
        blob: null,
        audioUrl: '',
        summary: null,
        transcriptText: '',
        recognitionDone: false,
        recorderDone: false,
        manualTranscript: false,
        manualTranscriptText: ''
      };

      slot.recordBtn?.addEventListener('click', () => beginRecording(slot));
      slot.stopBtn?.addEventListener('click', () => scheduleStopRecording(slot));
      slot.playBtn?.addEventListener('click', () => playSlot(slot));
      slot.redoBtn?.addEventListener('click', () => resetSlot(slot, true));
      slot.editBtn?.addEventListener('click', () => toggleTranscriptEditor(slot));
      slot.editorInput?.addEventListener('input', (event) => {
        handleManualTranscriptInput(slot, event.target.value);
      });
      slot.nextBtn?.addEventListener('click', () => advanceToNextSlot(slot));
      // Show slot-level hint when Next becomes enabled
      if (slot.nextBtn && slot.nextHint) {
        attachNextHint(slot.nextBtn, slot.nextHint);
      }

      return slot;
    }

    slotIds.forEach((id) => {
      slots[id] = initSlot(id);
    });

    // Ensure Admin mode shows Edit controls immediately on load
    try { updateAdminTranscriptEditing(); } catch {}

  setAssessmentStatusVisible(false);
  setAssessmentStatusDebugVisible(false);
    setAssessmentResult('InProgress');
    const assessmentStatusInterval = setInterval(() => emitAssessmentStatus(), 1000);

    window.onStatusChange = (next) => {
      if (!next) return;
      if (typeof next === 'string') {
        setAssessmentResult(next);
      } else if (typeof next === 'object') {
        const overall = next.overall ?? next.status ?? 'InProgress';
        const details = Object.prototype.hasOwnProperty.call(next, 'details') ? next.details : null;
        setAssessmentResult(overall, details);
      }
    };

    const fillers = [
      'um','uh','erm','ah','er','like','you know','kind of','sort of','actually','basically','literally','right','hmm','mm','okay','ok','well'
    ];

    const SHOUTING_THRESHOLD_DB = -12;
    const PROHIBITED_LANGUAGE_TERMS = [
      'damn','dammit','shit','fuck','fucking','bastard','bitch','crap','asshole','idiot','stupid','bloody','bollocks','hell','suck','sucks','sucked','sucking','stuffed','freaking','frickin','jerk','screw','screwed','screwing','screwup','knob head','knobhead'
    ];
    const CASUAL_LANGUAGE_PATTERNS = [
      { regex: /\b(gonna|wanna|ain't)\b/i, label: 'informal contractions (gonna/wanna/ain\'t)' },
      { regex: /\b(dude|buddy|pal|bro|mate)\b/i, label: 'casual address (dude/buddy/bro)' },
      { regex: /\b(chill out|calm down|shut up|get your act together)\b/i, label: 'confrontational phrasing' },
  { regex: /\b(we'?re|we are|were|they'?re|they are)?\s*stuffed\b/i, label: 'slang such as "we are stuffed"' },
  { regex: /\b(they|clients?|client is|client was|we)\b[^.]*\bsuck(s|ed|ing)?\b/i, label: 'slang criticism (suck/sucked)' }
    ];
    const UNPROFESSIONAL_BEHAVIOUR_PATTERNS = [
      { regex: /(\[laughs\]|\(laughs\)|\blaughs\b|\blaughing\b|\bhaha\b|\blol\b)/i, label: 'laughing during the response' },
      { regex: /\b(shut up|shut it|be quiet|stop talking)\b/i, label: 'aggressive command' },
      { regex: /\b(lazy|useless|incompetent|stupid|idiot|dumb)\b/i, label: 'insulting the listener' },
      { regex: /\b(whatever|don'?t care|not my problem|couldn'?t care less)\b/i, label: 'dismissive attitude' }
    ];
    const BASELINE_PROHIBITED_TERMS = PROHIBITED_LANGUAGE_TERMS;

    const floatBuffer = new Float32Array(2048);
    let availableMics = [];
    let currentDeviceId = '';
    let isRefreshingMics = false;

    let activeSlot = null;
    let isRecording = false;
    let micStream = null;
    let audioCtx = null;
    let analyser = null;
    let monitorLoop = null;
  let mediaRecorder = null;
  let recordedChunks = [];
  let micSourceNode = null;
    let speechRecognizer = null;
    let speechPushStream = null;
    let speechTapNode = null;
    let speechTapGain = null;
    let speechSilentGain = null;
    let speechTokenInfo = { token: '', region: '', expiresAt: 0 };
    let stopRequested = false;
    let stopDelayTimer = null;
    let speaking = false;
    let metrics = null;
    let currentSummary = null;
    let recognitionActive = false;
  let currentlyPlayingSlot = null;

    const Step = {
      BASELINE: 'baseline',
      SCENARIO: 'scenario',
      EVALUATION: 'evaluation'
    };

    // Force the experience to begin on the baseline step only.
    selectStep(Step.BASELINE);

    function updateScenarioAvailability() {
      const scenario1 = slots.scenario1;
      const scenario2 = slots.scenario2;
      const scenario3 = slots.scenario3;

      if (scenario1?.recordBtn) {
        if (!isRecording || activeSlot === scenario1) {
          scenario1.recordBtn.disabled = false;
        } else if (isRecording && activeSlot !== scenario1) {
          scenario1.recordBtn.disabled = true;
        }
      }

      if (scenario2?.recordBtn) {
        const enable = !!scenario2.revealed && !!scenario1?.summary;
        if (!enable || (isRecording && activeSlot !== scenario2)) {
          scenario2.recordBtn.disabled = true;
        } else if (!isRecording) {
          scenario2.recordBtn.disabled = false;
        }
      }

      if (scenario3?.recordBtn) {
        const enable = !!scenario3.revealed && !!scenario1?.summary && !!scenario2?.summary;
        if (!enable || (isRecording && activeSlot !== scenario3)) {
          scenario3.recordBtn.disabled = true;
        } else if (!isRecording) {
          scenario3.recordBtn.disabled = false;
        }
      }
    }

    function disableOtherRecordButtons(disabled) {
      slotIds.forEach((id) => {
        const slot = slots[id];
        if (!slot) return;
        if (slot !== activeSlot) {
          if (disabled) {
            slot.recordBtn.disabled = true;
          } else if (!slot.id.startsWith('scenario')) {
            slot.recordBtn.disabled = false;
          }
          slot.stopBtn.disabled = true;
        }
      });
      if (!disabled) {
        updateScenarioAvailability();
      }
    }

    function resetSlot(slot, removingAudio) {
      if (!slot) return;
      stopSlotPlayback(slot);
      if (isRecording && activeSlot === slot) {
        stopRecording();
        return;
      }
      if (slot.audioUrl) {
        URL.revokeObjectURL(slot.audioUrl);
        slot.audioUrl = '';
      }
      if (slot.downloadLink) {
        slot.downloadLink.removeAttribute('href');
      }
      slot.blob = null;
      slot.summary = null;
      slot.transcriptSegments = [];
      slot.transcriptText = '';
      slot.recognitionDone = false;
      slot.recorderDone = false;
      slot.partialLine = null;
      if (slot.timerEl) slot.timerEl.textContent = '00:00';
      slot.statusEl.textContent = 'Idle';
  setSlotMeter(slot, 4);
      if (slot.listenBadge) slot.listenBadge.hidden = true;
      if (slot.playbackGroup) slot.playbackGroup.hidden = true;
      if (slot.playBtn) {
        slot.playBtn.disabled = true;
        updatePlayButton(slot, false);
      }
      if (slot.summaryPanel) slot.summaryPanel.hidden = true;
      if (slot.alertsList) slot.alertsList.innerHTML = '';
      if (slot.alertsPanel) slot.alertsPanel.hidden = true;
      if (slot.editorPanel) slot.editorPanel.hidden = true;
      if (slot.editorInput) slot.editorInput.value = '';
      if (slot.editBtn) slot.editBtn.textContent = 'Edit text';
      if (slot.nextBtn) {
        const nextSlot = slot.nextSlotId ? slots[slot.nextSlotId] : null;
        if (!nextSlot || !nextSlot.revealed) {
          slot.nextBtn.hidden = true;
          slot.nextBtn.disabled = true;
        }
      }
      slot.manualTranscript = false;
      slot.manualTranscriptText = '';
      slot.recordBtn.disabled = false;
      slot.stopBtn.disabled = true;
      if (slot.id && slot.id.startsWith('scenario')) {
        scenarioNextBtn?.setAttribute('hidden', '');
        if (scenarioNextBtn) {
          scenarioNextBtn.disabled = true;
        }
      }
      if (slot.transcriptBody) {
        slot.transcriptBody.innerHTML = '<div class="empty">No transcript yet.</div>';
        slot.transcriptBody.hidden = false;
      }
      if (slot.id === 'baseline') {
        baselineNextBtn.disabled = true;
      }
      if (slot.id.startsWith('scenario')) {
        scenarioNextBtn.disabled = true;
        updateScenarioAvailability();
      }
    }

    function formatTime(totalSeconds) {
      const minutes = String(Math.floor(totalSeconds / 60)).padStart(2, '0');
      const seconds = String(Math.floor(totalSeconds % 60)).padStart(2, '0');
      return `${minutes}:${seconds}`;
    }

    function setTimer(slot, startTs, currentTs) {
      if (!slot?.timerEl) return;
      if (!Number.isFinite(startTs) || startTs <= 0) {
        slot.timerEl.textContent = '00:00';
        return;
      }
      const elapsed = Math.max(0, currentTs - startTs);
      slot.timerEl.textContent = formatTime(elapsed / 1000);
    }

    function setSlotMeter(slot, percent) {
      if (!slot?.meterBar) return;
      const clamped = Math.max(4, Math.min(100, percent));
      slot.meterBar.style.width = `${clamped}%`;
    }

    function appendTranscript(slot, text, isFinal) {
      if (!slot?.transcriptBody || !text) return;
      const line = document.createElement('div');
      line.className = `line ${isFinal ? 'final' : 'partial'}`;
      const ts = document.createElement('span');
      ts.className = 'ts';
      ts.textContent = `[${new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit', second: '2-digit' })}]`;
      const body = document.createElement('span');
      body.textContent = text;
      line.appendChild(ts);
      line.appendChild(body);

      if (slot.partialLine && !isFinal) {
        slot.transcriptBody.replaceChild(line, slot.partialLine);
        slot.partialLine = line;
      } else if (isFinal && slot.partialLine) {
        slot.transcriptBody.replaceChild(line, slot.partialLine);
        slot.partialLine = null;
      } else if (!isFinal) {
        if (slot.transcriptBody.children.length === 1 && slot.transcriptBody.firstElementChild?.classList.contains('empty')) {
          slot.transcriptBody.innerHTML = '';
        }
        slot.transcriptBody.appendChild(line);
        slot.partialLine = line;
      } else {
        if (slot.transcriptBody.children.length === 1 && slot.transcriptBody.firstElementChild?.classList.contains('empty')) {
          slot.transcriptBody.innerHTML = '';
        }
        slot.transcriptBody.appendChild(line);
      }

      slot.transcriptBody.scrollTop = slot.transcriptBody.scrollHeight;
    }

    function renderTranscriptFromText(slot, text) {
      if (!slot?.transcriptBody) return;
      const normalized = text ? text.replace(/\r\n/g, '\n') : '';
      const lines = normalized
        .split('\n')
        .map((line) => line.trim())
        .filter((line) => line.length);

    slot.transcriptBody.innerHTML = '';
    slot.partialLine = null;
      if (!lines.length) {
        slot.transcriptBody.innerHTML = '<div class="empty">No transcript yet.</div>';
        return;
      }

      lines.forEach((line) => {
        const div = document.createElement('div');
        div.className = 'line final manual';
        div.textContent = line;
        slot.transcriptBody.appendChild(div);
      });
      slot.transcriptBody.scrollTop = 0;
    }

    function getTranscriptEditorValue(slot) {
      if (!slot) return '';
      if (slot.manualTranscript && slot.manualTranscriptText) {
        return slot.manualTranscriptText;
      }
      if (slot.transcriptSegments?.length) {
        return slot.transcriptSegments.join('\n');
      }
      if (slot.transcriptText) {
        return slot.transcriptText;
      }
      if (slot.transcriptBody) {
        const domText = slot.transcriptBody.textContent || '';
        return sanitizeTranscript(domText);
      }
      return '';
    }

    function toggleTranscriptEditor(slot) {
      if (!slot?.editorPanel || !slot.editBtn || !slot.editorInput) return;
      const isVisible = !slot.editorPanel.hidden;
      if (isVisible) {
        slot.editorPanel.hidden = true;
        slot.editBtn.textContent = 'Edit text';
        if (slot.transcriptBody) {
          slot.transcriptBody.hidden = false;
        }
        return;
      }

      const text = getTranscriptEditorValue(slot);
      slot.editorInput.value = text;
      slot.editorPanel.hidden = false;
      slot.editBtn.textContent = 'Close';
      if (slot.transcriptBody) {
        slot.transcriptBody.hidden = true;
      }
      slot.editorInput.focus();
    }

    function advanceToNextSlot(slot) {
      if (!slot || !slot.nextSlotId) return;
      const nextSlot = slots[slot.nextSlotId];
      if (!nextSlot) return;
      if (slot.nextBtn) {
        slot.nextBtn.hidden = true;
        slot.nextBtn.disabled = true;
      }
      // If advancing from scenario1, kick off remote evaluation but do not block the UI.
      if (slot.id === 'scenario1') {
        const transcriptText = slot.transcriptText || '';
        if (transcriptText) {
          debugLog('Remote Recording1 evaluation queued (non-blocking)');
          // Fire-and-forget; outcome is logged and used later without blocking navigation
          Promise.resolve()
            .then(() => evaluateRecording1Remotely(transcriptText))
            .catch((err) => debugLog('Remote Recording1 evaluation failed', err));
        } else {
          debugLog('Remote Recording1 evaluation skipped — empty transcript');
        }
      }
      // For scenario2, also run remote evaluation in background without blocking reveal.
      if (slot.id === 'scenario2') {
        const transcriptText = slot.transcriptText || '';
        if (transcriptText) {
          debugLog('Remote Recording2 evaluation queued (non-blocking)');
          Promise.resolve()
            .then(() => evaluateRecording2Remotely(transcriptText))
            .catch((err) => debugLog('Remote Recording2 evaluation failed', err));
        } else {
          debugLog('Remote Recording2 evaluation skipped — empty transcript');
        }
      }
      if (nextSlot.revealed) {
        return;
      }
      revealNextSlot(slot, nextSlot);
    }

    function revealNextSlot(currentSlot, nextSlot) {
      if (!nextSlot || nextSlot.revealed) return;
      nextSlot.revealed = true;
      if (nextSlot.container) {
        nextSlot.container.hidden = false;
        nextSlot.container.removeAttribute('hidden');
      }
      if (currentSlot?.container) {
        currentSlot.container.hidden = true;
        currentSlot.container.setAttribute('hidden', '');
      }
      // New slot is shown: ensure its controls are enabled
      try { window.__restoreButtons?.(); } catch {}
      updateScenarioAvailability();
      debugLog('Scenario slot unlocked', { from: currentSlot?.id, to: nextSlot.id });
      window.setTimeout(() => {
        nextSlot.container?.scrollIntoView({ behavior: 'smooth', block: 'start' });
      }, 150);
    }

    async function evaluateRecording1Remotely(transcript) {
      try {
        const requestBody = JSON.stringify({ Recording: transcript });
        const response = await fetch(REMOTE_RECORDING1_ENDPOINT, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: requestBody
        });
        if (!response.ok) {
          const text = await response.text().catch(() => '(no body)');
          throw new Error(`Remote eval responded ${response.status}: ${text}`);
        }
        const data = await response.json().catch(() => ({}));
        slots.scenario1.remoteEvaluation = data;
        debugLog('Remote Recording1 evaluation received', data);
        return data;
      } catch (err) {
        slots.scenario1.remoteEvaluationError = String(err?.message || err);
        throw err;
      }
    }

    async function evaluateRecording2Remotely(transcript) {
      try {
        const requestBody = JSON.stringify({ Recording: transcript });
        const response = await fetch(REMOTE_RECORDING2_ENDPOINT, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: requestBody
        });
        if (!response.ok) {
          const text = await response.text().catch(() => '(no body)');
          throw new Error(`Remote eval R2 responded ${response.status}: ${text}`);
        }
        const data = await response.json().catch(() => ({}));
        slots.scenario2.remoteEvaluation = data;
        debugLog('Remote Recording2 evaluation received', data);
        return data;
      } catch (err) {
        slots.scenario2.remoteEvaluationError = String(err?.message || err);
        throw err;
      }
    }

    async function evaluateRecording3Remotely(transcript) {
      try {
        const requestBody = JSON.stringify({ Recording: transcript });
        const response = await fetch(REMOTE_RECORDING3_ENDPOINT, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: requestBody
        });
        if (!response.ok) {
          const text = await response.text().catch(() => '(no body)');
          throw new Error(`Remote eval R3 responded ${response.status}: ${text}`);
        }
        const data = await response.json().catch(() => ({}));
        slots.scenario3.remoteEvaluation = data;
        debugLog('Remote Recording3 evaluation received', data);
        return data;
      } catch (err) {
        slots.scenario3.remoteEvaluationError = String(err?.message || err);
        throw err;
      }
    }

    function handleManualTranscriptInput(slot, value) {
      if (!slot) return;
      const raw = (value || '').replace(/\r\n/g, '\n');
      const trimmed = raw.trim();
      if (!trimmed) {
        slot.manualTranscript = false;
        slot.manualTranscriptText = '';
        if (slot.transcriptSegments?.length) {
          slot.transcriptText = sanitizeTranscript(slot.transcriptSegments.join(' '));
          renderTranscriptFromText(slot, slot.transcriptSegments.join('\n'));
        } else {
          slot.transcriptText = '';
          renderTranscriptFromText(slot, '');
        }
        if (slot.id === 'baseline') {
          renderBaselineCompliance(slot);
        }
        return;
      }

      slot.manualTranscript = true;
      slot.manualTranscriptText = raw;
      slot.transcriptText = sanitizeTranscript(raw);
      renderTranscriptFromText(slot, raw);
      if (slot.id === 'baseline') {
        renderBaselineCompliance(slot);
      }
    }

    async function refreshMicrophones(preferredDeviceId = '') {
      if (!navigator.mediaDevices?.enumerateDevices || !micSelect) return;
      if (isRefreshingMics) return;
      isRefreshingMics = true;
      try {
        const devices = await navigator.mediaDevices.enumerateDevices();
        const mics = devices.filter((device) => device.kind === 'audioinput' && device.deviceId !== 'default' && device.deviceId !== 'communications');
        availableMics = mics;
        const selectionTarget = preferredDeviceId || currentDeviceId || micSelect.value || '';

        micSelect.innerHTML = '';
        const defaultOption = document.createElement('option');
        defaultOption.value = '';
        defaultOption.textContent = 'System default input';
        micSelect.appendChild(defaultOption);

        mics.forEach((mic, index) => {
          const option = document.createElement('option');
          option.value = mic.deviceId;
          option.textContent = mic.label || `Microphone ${index + 1}`;
          micSelect.appendChild(option);
        });

        if (selectionTarget && mics.some((mic) => mic.deviceId === selectionTarget)) {
          micSelect.value = selectionTarget;
          currentDeviceId = selectionTarget;
        } else if (!selectionTarget) {
          micSelect.value = '';
          currentDeviceId = '';
        } else if (mics.length) {
          micSelect.value = mics[0].deviceId;
          currentDeviceId = micSelect.value;
        } else {
          micSelect.value = '';
          currentDeviceId = '';
        }

        micSelect.disabled = mics.length === 0;
      } catch (err) {
        console.warn('Unable to refresh microphones', err);
      } finally {
        isRefreshingMics = false;
      }
    }

    async function openMicrophone() {
      if (!navigator.mediaDevices) throw new Error('MediaDevices unavailable');
      const selectedMicId = micSelect?.value || currentDeviceId || '';
      const audioConstraints = {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
      };
      if (selectedMicId) {
        audioConstraints.deviceId = { exact: selectedMicId };
      }
      const stream = await navigator.mediaDevices.getUserMedia({ audio: audioConstraints });
      return stream;
    }

    function initMetrics() {
      metrics = {
        sessionActive: true,
        startTime: 0,
        lastUpdate: 0,
        endTime: 0,
        words: 0,
        fillerCounts: new Map(),
        totalSpeechMs: 0,
        lastSpeechStart: 0,
        lastSpeechDetectedAt: 0,
        lastSilenceStart: 0,
        longestPause: 0,
        sumRms: 0,
        sampleCount: 0,
        sumPitch: 0,
        pitchCount: 0,
        minPitch: Infinity,
        maxPitch: 0
      };
      speaking = false;
      currentSummary = null;
    }

    function finalizeMetrics() {
      if (!metrics) return null;
      const now = metrics.lastSpeechDetectedAt || performance.now();
      if (speaking && metrics.lastSpeechStart) {
        metrics.totalSpeechMs += now - metrics.lastSpeechStart;
        speaking = false;
      }
      metrics.endTime = now;
      metrics.sessionActive = false;

      const elapsedMs = Math.max(now - metrics.startTime, 1);
      const speechMs = metrics.totalSpeechMs;
      const speechRatio = Math.min(100, (speechMs / elapsedMs) * 100);
      const speechMinutes = speechMs > 0 ? speechMs / 60000 : 0;
      const wpm = speechMinutes > 0 ? metrics.words / speechMinutes : 0;
      const avgRms = metrics.sampleCount ? metrics.sumRms / metrics.sampleCount : 0;
      const avgDb = avgRms > 0 ? 20 * Math.log10(avgRms) : -Infinity;
      const fillerTotal = Array.from(metrics.fillerCounts.values()).reduce((acc, val) => acc + val, 0);
      const fillerRate = metrics.words ? fillerTotal / metrics.words : 0;
      const pitchAvg = metrics.pitchCount ? metrics.sumPitch / metrics.pitchCount : 0;
      const minPitch = metrics.minPitch === Infinity ? 0 : metrics.minPitch;
      const pitchRange = metrics.pitchCount ? metrics.maxPitch - minPitch : 0;
      const summary = {
        durationSeconds: elapsedMs / 1000,
        speechRatio,
        wpm,
        avgDb: isFinite(avgDb) ? avgDb : -Infinity,
        fillerCount: fillerTotal,
        fillerRate,
        words: metrics.words,
        pitchAvg,
        pitchRange,
        longestPause: metrics.longestPause / 1000
      };
      currentSummary = summary;
      return summary;
    }

    function estimatePitch(buffer, sampleRate) {
      if (!buffer || buffer.length === 0) return null;
      const size = buffer.length;
      let bestOffset = -1;
      let bestCorrelation = 0;
      let rms = 0;
      for (let i = 0; i < size; i++) rms += buffer[i] * buffer[i];
      rms = Math.sqrt(rms / size);
      if (rms < 0.01) return null;
      let lastCorrelation = 1;
      for (let offset = 32; offset < 512; offset++) {
        let correlation = 0;
        for (let i = 0; i < size - offset; i++) {
          correlation += buffer[i] * buffer[i + offset];
        }
        correlation = correlation / (size - offset);
        if (correlation > 0.9 && correlation > lastCorrelation) {
          bestCorrelation = correlation;
          bestOffset = offset;
        } else if (bestCorrelation >= 0.9 && correlation < lastCorrelation) {
          break;
        }
        lastCorrelation = correlation;
      }
      if (bestCorrelation < 0.9 || bestOffset === -1) return null;
      const pitch = sampleRate / bestOffset;
      if (pitch < 50 || pitch > 500) return null;
      return pitch;
    }

    function monitorAudio(slot) {
      if (!analyser || !metrics || !slot) return;
      analyser.getFloatTimeDomainData(floatBuffer);
      let sum = 0;
      for (let i = 0; i < floatBuffer.length; i++) {
        const value = floatBuffer[i];
        sum += value * value;
      }
      const rms = Math.sqrt(sum / floatBuffer.length);
      const db = rms > 0 ? 20 * Math.log10(rms) : -Infinity;
      const clamped = Math.max(0, Math.min(1, rms * 8));
      const meterWidth = Math.max(4, clamped * 100);
      if (levelBar) {
        levelBar.style.width = `${meterWidth}%`;
      }
      setSlotMeter(slot, meterWidth);

      const now = performance.now();
      setTimer(slot, metrics.startTime, now);

      const speechThreshold = 0.02;
      const isSpeech = rms > speechThreshold;
      if (isSpeech) {
        metrics.sumRms += rms;
        metrics.sampleCount += 1;
        if (!speaking) {
          speaking = true;
          metrics.lastSpeechStart = now;
          if (metrics.lastSilenceStart) {
            const pause = now - metrics.lastSilenceStart;
            if (pause > metrics.longestPause) {
              metrics.longestPause = pause;
            }
            metrics.lastSilenceStart = 0;
          }
        }
        metrics.lastSpeechDetectedAt = now;
      } else if (speaking && now - metrics.lastSpeechDetectedAt > 180) {
        speaking = false;
        metrics.totalSpeechMs += now - metrics.lastSpeechStart;
        metrics.lastSilenceStart = now;
      }

      if (audioCtx) {
        const pitch = estimatePitch(floatBuffer, audioCtx.sampleRate);
        if (pitch) {
          metrics.sumPitch += pitch;
          metrics.pitchCount += 1;
          metrics.minPitch = Math.min(metrics.minPitch, pitch);
          metrics.maxPitch = Math.max(metrics.maxPitch, pitch);
        }
      }

      monitorLoop = requestAnimationFrame(() => monitorAudio(slot));
    }

    function countFillers(text) {
      const lower = text.toLowerCase();
      fillers.forEach((token) => {
        const regex = new RegExp(`\b${token.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')}\b`, 'g');
        const matches = lower.match(regex);
        if (matches && matches.length) {
          const prev = metrics.fillerCounts.get(token) || 0;
          metrics.fillerCounts.set(token, prev + matches.length);
        }
      });
    }

    async function beginRecording(slot) {
      debugLog('beginRecording invoked', { slot: slot?.id });
      // Ensure settings preview is not holding the microphone
      try { stopSettingsLevelPreview(); } catch {}
      if (typeof window.SpeechSDK === 'undefined') {
        alert('Azure Speech SDK is unavailable. Refresh the page and try again.');
        debugLog('Azure Speech SDK missing during beginRecording');
        return;
      }
      if (isRecording) {
        alert('A recording is already running. Please stop it before starting another.');
        debugLog('beginRecording blocked because another slot is active', { activeSlot: activeSlot?.id });
        return;
      }
      resetSlot(slot, false);
      activeSlot = slot;
      stopRequested = false;
      isRecording = true;
      slot.recordBtn.disabled = true;
      slot.stopBtn.disabled = false;
      slot.statusEl.textContent = 'Preparing microphone…';
      disableOtherRecordButtons(true);
      debugLog('Recording preparation in progress', {
        slot: slot.id,
        selectedMic: micSelect?.value || currentDeviceId || 'default'
      });

      let micPromise = null;
      try {
        if (micStream) {
          micStream.getTracks().forEach((track) => track.stop());
          micStream = null;
        }
        micPromise = openMicrophone();
        debugLog('Requested microphone access', { slot: slot.id });
      } catch (err) {
        console.error('Microphone error', err);
        slot.statusEl.textContent = 'Microphone unavailable';
        slot.recordBtn.disabled = false;
        slot.stopBtn.disabled = true;
        disableOtherRecordButtons(false);
        isRecording = false;
        activeSlot = null;
        debugLog('Microphone access failed immediately', err);
        return;
      }

      slot.recognitionDone = false;

      try {
        micStream = await micPromise;
        const activeTrack = micStream.getAudioTracks()[0];
        const settings = activeTrack?.getSettings ? activeTrack.getSettings() : {};
        const rawDeviceId = settings.deviceId || currentDeviceId || '';
        const appliedDeviceId = rawDeviceId === 'default' || rawDeviceId === 'communications' ? '' : rawDeviceId;
        await refreshMicrophones(appliedDeviceId);
        if (appliedDeviceId) {
          micSelect.value = appliedDeviceId;
          currentDeviceId = appliedDeviceId;
        }
        const trackLabel = activeTrack?.label || 'unknown';
        debugLog('Microphone stream ready', { slot: slot.id, deviceId: appliedDeviceId || 'default', label: trackLabel });
      } catch (err) {
        console.error('Microphone error', err);
        slot.statusEl.textContent = err?.name === 'OverconstrainedError' ? 'Selected mic unavailable' : 'Microphone denied';
        slot.recordBtn.disabled = false;
        slot.stopBtn.disabled = true;
        disableOtherRecordButtons(false);
        stopAzureRecognition();
        isRecording = false;
        activeSlot = null;
        debugLog('Microphone promise rejected', err);
        return;
      }

      try {
        initMetrics();
        const sourceNode = await initAudioChain(slot, micStream);
        await startAzureRecognition(slot, audioCtx, sourceNode);
        startMediaRecorder(slot, micStream);
        await playStartTone(audioCtx);
        if (metrics) {
          const recordingStart = performance.now();
          metrics.startTime = recordingStart;
          metrics.lastUpdate = recordingStart;
        }
        slot.statusEl.textContent = 'Recording…';
        if (slot.listenBadge) slot.listenBadge.hidden = false;
        slot.container.classList.add('is-recording');
        debugLog('Recording started', { slot: slot.id });
      } catch (err) {
        console.error('Recording could not start', err);
        slot.statusEl.textContent = 'Unable to start recording';
        slot.recordBtn.disabled = false;
        slot.stopBtn.disabled = true;
        disableOtherRecordButtons(false);
        stopAzureRecognition();
        if (micStream) {
          try { micStream.getTracks().forEach((track) => track.stop()); } catch {}
          micStream = null;
        }
        isRecording = false;
        activeSlot = null;
        debugLog('Recording setup failed', err);
      }
    }

    async function initAudioChain(slot, stream) {
      const AudioContextRef = window.AudioContext || window.webkitAudioContext;
      audioCtx = new AudioContextRef({ latencyHint: 'interactive' });
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = floatBuffer.length * 2;
      micSourceNode = audioCtx.createMediaStreamSource(stream);
      micSourceNode.connect(analyser);
      monitorLoop = requestAnimationFrame(() => monitorAudio(slot));
      return micSourceNode;
    }

    function playStartTone(context) {
      if (!context) return Promise.resolve();
      return new Promise((resolve) => {
        let settled = false;
        const finish = () => {
          if (settled) return;
          settled = true;
          resolve();
        };
        try {
          const oscillator = context.createOscillator();
          const gain = context.createGain();
          const now = context.currentTime;
          const duration = 0.2;
          const fallback = setTimeout(finish, duration * 1000 + 100);

          oscillator.type = 'sine';
          oscillator.frequency.setValueAtTime(880, now);
          gain.gain.setValueAtTime(0.0001, now);
          gain.gain.linearRampToValueAtTime(0.25, now + 0.02);
          gain.gain.exponentialRampToValueAtTime(0.0001, now + duration);
          oscillator.connect(gain);
          gain.connect(context.destination);
          oscillator.start(now);
          oscillator.stop(now + duration);
          oscillator.onended = () => {
            try { oscillator.disconnect(); } catch {}
            try { gain.disconnect(); } catch {}
            clearTimeout(fallback);
            finish();
          };
        } catch (err) {
          debugLog('Start tone failed', err instanceof Error ? err.message : err);
          finish();
        }
      });
    }

    function startMediaRecorder(slot, stream) {
      debugLog('MediaRecorder starting', { slot: slot.id });
      recordedChunks = [];
      mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
      mediaRecorder.ondataavailable = (event) => {
        if (event.data && event.data.size) {
          recordedChunks.push(event.data);
        }
      };
      mediaRecorder.onstop = () => {
        debugLog('MediaRecorder stopped', { slot: slot.id, chunks: recordedChunks.length });
        const blob = new Blob(recordedChunks, { type: 'audio/webm' });
        slot.blob = blob;
        if (slot.audioUrl) {
          URL.revokeObjectURL(slot.audioUrl);
        }
        slot.audioUrl = URL.createObjectURL(blob);
        if (slot.downloadLink) {
          slot.downloadLink.href = slot.audioUrl;
          slot.downloadLink.download = `${slot.id}-${Date.now()}.webm`;
        }
        if (slot.playbackGroup) slot.playbackGroup.hidden = false;
        if (slot.playBtn) {
          slot.playBtn.disabled = false;
          updatePlayButton(slot, false);
        }
        slot.recorderDone = true;
        finalizeSlotRecording(slot);
      };
      mediaRecorder.start();
      debugLog('MediaRecorder started', { slot: slot.id });
    }

    async function fetchAzureSpeechToken() {
      const now = Date.now();
      if (speechTokenInfo.token && speechTokenInfo.region && speechTokenInfo.expiresAt - 60000 > now) {
        return speechTokenInfo;
      }
      const response = await fetch('/api/speech/token', { method: 'POST' });
      if (!response.ok) {
        const text = await response.text().catch(() => '');
        throw new Error(`Token request failed (${response.status}) ${text}`.trim());
      }
      const payload = await response.json().catch(() => ({}));
      const token = payload.token || payload.accessToken || payload.authToken;
      const region = payload.region || payload.serviceRegion;
      if (!token || !region) {
        throw new Error('Speech token response missing token or region.');
      }
      const expiresIn = typeof payload.expiresIn === 'number' ? payload.expiresIn : 540;
      speechTokenInfo = {
        token,
        region,
        expiresAt: now + Math.max(300, expiresIn) * 1000,
      };
      debugLog('Fetched Azure speech token', { region, expiresIn });
      return speechTokenInfo;
    }

    function attachAzureTap(audioContext, sourceNode) {
      if (!audioContext || !sourceNode) return;
      detachAzureTap();
      speechTapGain = audioContext.createGain();
      speechTapGain.gain.value = 1;
      sourceNode.connect(speechTapGain);

      speechTapNode = audioContext.createScriptProcessor(4096, 1, 1);
      speechTapGain.connect(speechTapNode);

      speechSilentGain = audioContext.createGain();
      speechSilentGain.gain.value = 0;
      speechTapNode.connect(speechSilentGain);
      speechSilentGain.connect(audioContext.destination);

      speechTapNode.onaudioprocess = (event) => {
        if (!speechPushStream) return;
        const input = event.inputBuffer.getChannelData(0);
        const pcm = downsampleTo16BitPCM(input, event.inputBuffer.sampleRate, 16000);
        if (!pcm) return;
        try {
          speechPushStream.write(pcm);
        } catch (err) {
          debugLog('Azure speech push failed', err instanceof Error ? err.message : err);
        }
      };
    }

    function detachAzureTap() {
      if (speechTapNode) {
        try { speechTapNode.disconnect(); } catch {}
        speechTapNode.onaudioprocess = null;
        speechTapNode = null;
      }
      if (speechTapGain) {
        try { speechTapGain.disconnect(); } catch {}
        speechTapGain = null;
      }
      if (speechSilentGain) {
        try { speechSilentGain.disconnect(); } catch {}
        speechSilentGain = null;
      }
    }

    async function startAzureRecognition(slot, audioContext, sourceNode) {
      if (!window.SpeechSDK) {
        throw new Error('Azure Speech SDK not available');
      }
      const SpeechSDK = window.SpeechSDK;
      const { token, region } = await fetchAzureSpeechToken();
      const language = languageEl?.value || 'en-US';

      const format = SpeechSDK.AudioStreamFormat.getWaveFormatPCM(16000, 16, 1);
      speechPushStream = SpeechSDK.AudioInputStream.createPushStream(format);
      const audioConfig = SpeechSDK.AudioConfig.fromStreamInput(speechPushStream);
      const speechConfig = SpeechSDK.SpeechConfig.fromAuthorizationToken(token, region);
      speechConfig.speechRecognitionLanguage = language;

      speechRecognizer = new SpeechSDK.SpeechRecognizer(speechConfig, audioConfig);
      attachAzureTap(audioContext, sourceNode);

      speechRecognizer.recognizing = (_sender, event) => {
        if (!event?.result?.text) return;
        const partial = event.result.text.trim();
        if (!partial) return;
        appendTranscript(slot, partial, false);
      };

      speechRecognizer.recognized = (_sender, event) => {
        if (!event?.result) return;
        if (event.result.reason === SpeechSDK.ResultReason.RecognizedSpeech) {
          const transcript = event.result.text?.trim();
          if (!transcript) return;
          metrics.words += transcript.split(/\s+/).filter(Boolean).length;
          countFillers(transcript);
          slot.transcriptSegments.push(transcript);
          appendTranscript(slot, transcript, true);
          slot.partialLine = null;
          debugLog('Azure speech final segment', {
            slot: slot.id,
            transcript: transcript.length > 160 ? `${transcript.slice(0, 160)}…` : transcript
          });
        } else if (event.result.reason === SpeechSDK.ResultReason.NoMatch) {
          const details = event.result.noMatchDetails;
          const reasonEnum = details?.reason;
          const reasonLabel = (() => {
            switch (reasonEnum) {
              case SpeechSDK.NoMatchReason.InitialSilenceTimeout:
                return 'initial silence timeout';
              case SpeechSDK.NoMatchReason.InitialBabbleTimeout:
                return 'initial babble timeout';
              case SpeechSDK.NoMatchReason.KeywordNotRecognized:
                return 'keyword not recognized';
              case SpeechSDK.NoMatchReason.NotRecognized:
                return 'speech not recognized';
              case SpeechSDK.NoMatchReason.EndOfDictation:
                return 'end of dictation';
              default:
                return 'unknown';
            }
          })();
          if (reasonEnum === SpeechSDK.NoMatchReason.EndOfDictation || stopRequested) {
            return;
          }
          debugLog('Azure speech no match', { slot: slot.id, reason: reasonLabel });
        }
      };

      speechRecognizer.canceled = (_sender, event) => {
        const reason = event?.reason;
        const details = event?.errorDetails || reason || 'unknown';
        debugLog('Azure speech cancelled', { slot: slot.id, details });
        if (reason === SpeechSDK.CancellationReason.Error) {
          slot.statusEl.textContent = 'Speech service error';
        }
      };

      speechRecognizer.sessionStarted = () => {
        recognitionActive = true;
        debugLog('Azure speech session started', { slot: slot.id });
      };

      speechRecognizer.sessionStopped = () => {
        recognitionActive = false;
        debugLog('Azure speech session stopped', { slot: slot.id });
        if (!slot.recognitionDone) {
          slot.recognitionDone = true;
          finalizeSlotIfReady(slot);
        }
      };

      return new Promise((resolve, reject) => {
        speechRecognizer.startContinuousRecognitionAsync(
          () => {
            debugLog('Azure speech recognizer started', { slot: slot.id, language, region });
            resolve();
          },
          (error) => {
            const message = error instanceof Error ? error.message : String(error || 'Unknown error');
            debugLog('Azure speech recognizer start failed', message);
            slot.statusEl.textContent = 'Speech service unavailable';
            slot.recognitionDone = true;
            finalizeSlotIfReady(slot);
            stopAzureRecognition();
            reject(new Error(message));
          }
        );
      });
    }

    function stopAzureRecognition() {
      const recognizer = speechRecognizer;
      speechRecognizer = null;
      if (speechPushStream) {
        try { speechPushStream.close(); } catch {}
        speechPushStream = null;
      }
      detachAzureTap();
      if (!recognizer) {
        const slot = activeSlot;
        if (slot && !slot.recognitionDone) {
          slot.recognitionDone = true;
          finalizeSlotIfReady(slot);
        }
        return;
      }
      try {
        recognizer.stopContinuousRecognitionAsync(
          () => {
            debugLog('Azure speech recognizer stopped');
            try { recognizer.close?.(); } catch {}
            const slot = activeSlot;
            if (slot && !slot.recognitionDone) {
              slot.recognitionDone = true;
              finalizeSlotIfReady(slot);
            }
          },
          (error) => {
            debugLog('Azure speech recognizer stop failed', error instanceof Error ? error.message : error);
            try { recognizer.close?.(); } catch {}
            const slot = activeSlot;
            if (slot && !slot.recognitionDone) {
              slot.recognitionDone = true;
              finalizeSlotIfReady(slot);
            }
          }
        );
      } catch (err) {
        debugLog('Azure speech recognizer stop threw', err instanceof Error ? err.message : err);
        try { recognizer.close?.(); } catch {}
        const slot = activeSlot;
        if (slot && !slot.recognitionDone) {
          slot.recognitionDone = true;
          finalizeSlotIfReady(slot);
        }
      }
    }

    function downsampleTo16BitPCM(buffer, inputSampleRate, outputSampleRate) {
      if (!buffer || !buffer.length) return null;
      const ratio = inputSampleRate / outputSampleRate;
      if (ratio <= 1) {
        outputSampleRate = inputSampleRate;
      }
      const newLength = Math.floor(buffer.length / Math.max(1, ratio));
      const pcmBuffer = new ArrayBuffer(newLength * 2);
      const view = new DataView(pcmBuffer);
      let offsetResult = 0;
      let offsetBuffer = 0;
      while (offsetResult < newLength) {
        const nextOffsetBuffer = Math.min(buffer.length, Math.round((offsetResult + 1) * ratio));
        let sum = 0;
        let count = 0;
        for (let i = offsetBuffer; i < nextOffsetBuffer; i += 1) {
          sum += buffer[i];
          count += 1;
        }
        const sample = count > 0 ? sum / count : 0;
        const clamped = Math.max(-1, Math.min(1, sample));
        view.setInt16(offsetResult * 2, clamped < 0 ? clamped * 0x8000 : clamped * 0x7fff, true);
        offsetResult += 1;
        offsetBuffer = nextOffsetBuffer;
      }
      return pcmBuffer;
    }

    function scheduleStopRecording(slot) {
      if (!isRecording || !activeSlot || slot !== activeSlot) return;
      if (stopDelayTimer) return;
      slot.stopBtn.disabled = true;
      slot.statusEl.textContent = 'Finishing…';
      if (slot.listenBadge) slot.listenBadge.hidden = true;
      debugLog('Stop requested', { slot: slot.id });
      stopDelayTimer = setTimeout(() => {
        stopDelayTimer = null;
        stopRecording();
      }, 2000);
    }

    function stopRecording() {
      if (!isRecording || !activeSlot) return;
      debugLog('stopRecording invoked', { slot: activeSlot.id });
      if (stopDelayTimer) {
        clearTimeout(stopDelayTimer);
        stopDelayTimer = null;
      }
    stopRequested = true;
    recognitionActive = false;
    activeSlot.statusEl.textContent = 'Finishing…';
    if (activeSlot.listenBadge) activeSlot.listenBadge.hidden = true;
    stopAzureRecognition();
      try { mediaRecorder?.stop(); } catch (err) { console.warn('MediaRecorder stop failed', err); }
      if (monitorLoop) {
        cancelAnimationFrame(monitorLoop);
        monitorLoop = null;
      }
      if (analyser) {
        try { analyser.disconnect(); } catch (err) {}
        analyser = null;
      }
      if (audioCtx) {
        try { audioCtx.close(); } catch (err) {}
        audioCtx = null;
      }
      if (micStream) {
        micStream.getTracks().forEach((track) => track.stop());
        micStream = null;
      }
      micSourceNode = null;
      if (levelBar) {
        levelBar.style.width = '4%';
      }
      setSlotMeter(activeSlot, 4);
      finalizeMetrics();
      debugLog('stopRecording cleanup complete', { slot: activeSlot.id });
      // If settings modal is open, resume live level preview
      if (settingsVisible) {
        try { startSettingsLevelPreview(); } catch {}
      }
    }

    function finalizeSlotIfReady(slot) {
      if (!slot || !currentSummary) return;
      if (!slot.recorderDone || !slot.recognitionDone) return;
      completeSlotRecording(slot);
    }

    function completeSlotRecording(slot) {
  const summary = currentSummary || finalizeMetrics();
  slot.summary = summary;
  const joinedTranscript = slot.transcriptSegments.join(' ');
  const bodyText = slot.transcriptBody ? slot.transcriptBody.textContent || '' : '';
  slot.transcriptText = sanitizeTranscript(joinedTranscript) || sanitizeTranscript(bodyText);
      debugLog('Slot recording completed', {
        slot: slot.id,
        hasSummary: Boolean(summary),
        transcriptChars: slot.transcriptText.length
      });
      slot.statusEl.textContent = 'Recording saved';
      slot.recordBtn.disabled = false;
      slot.stopBtn.disabled = true;
      if (slot.listenBadge) slot.listenBadge.hidden = true;
      disableOtherRecordButtons(false);
      slot.container.classList.remove('is-recording');
      isRecording = false;
      activeSlot = null;
      currentSummary = null;
      stopRequested = false;

      if (slot.nextBtn) {
        const nextSlot = slot.nextSlotId ? slots[slot.nextSlotId] : null;
        if (nextSlot && !nextSlot.revealed) {
          slot.nextBtn.hidden = false;
          slot.nextBtn.disabled = false;
          slot.nextBtn.removeAttribute('hidden');
        }
      }

      if (slot.summaryPanel && summary) {
        const { tempo, ratio, loudness, filler, pause } = slot.summaryFields;
        if (tempo) tempo.textContent = `${summary.wpm.toFixed(1)} wpm`;
        if (ratio) ratio.textContent = `${summary.speechRatio.toFixed(0)}%`;
        if (loudness) loudness.textContent = isFinite(summary.avgDb) ? `${summary.avgDb.toFixed(1)} dB` : '– dB';
        if (filler) filler.textContent = `${summary.fillerCount}`;
        if (pause) pause.textContent = `${summary.longestPause.toFixed(1)}s`;
      }

      if (slot.id === 'baseline') {
        baselineNextBtn.disabled = false;
        updateScenarioAvailability();
        renderBaselineCompliance(slot);
        setSettingsVisible(false);
      }
      if (slot.id.startsWith('scenario')) {
        updateScenarioAvailability();
        const allDone = scenarioOrder.every((sid) => slots[sid]?.summary);
        scenarioNextBtn.disabled = !allDone;
        if (allDone) {
          scenarioNextBtn.removeAttribute('hidden');
        } else {
          scenarioNextBtn.setAttribute('hidden', '');
        }
      }
      setTimer(slot, summary ? metrics?.startTime || performance.now() : performance.now(), metrics?.endTime || performance.now());
    }

    function updatePlayButton(slot, playing) {
      if (!slot?.playBtn) return;
  slot.playBtn.textContent = playing ? 'Stop Playing' : 'Play Recording';
      slot.playBtn.setAttribute('aria-pressed', playing ? 'true' : 'false');
      slot.playBtn.classList.toggle('is-playing', Boolean(playing));
    }

  function stopSlotPlayback(slot) {
      if (!slot) return;
      const audio = slot.playbackAudio;
      if (audio) {
        if (slot.playbackEndedHandler) {
          audio.removeEventListener('ended', slot.playbackEndedHandler);
        }
        if (slot.playbackErrorHandler) {
          audio.removeEventListener('error', slot.playbackErrorHandler);
        }
        try {
          audio.pause();
          audio.currentTime = 0;
        } catch (err) {
          console.warn('Failed to stop playback cleanly', err);
        }
      }
      slot.playbackAudio = null;
      slot.playbackEndedHandler = null;
      slot.playbackErrorHandler = null;
      slot.isPlaying = false;
      updatePlayButton(slot, false);
      if (currentlyPlayingSlot === slot) {
        currentlyPlayingSlot = null;
      }
    }

    function playSlot(slot) {
      if (!slot?.audioUrl) return;
      if (slot.isPlaying) {
  stopSlotPlayback(slot);
        return;
      }
      if (currentlyPlayingSlot && currentlyPlayingSlot !== slot) {
  stopSlotPlayback(currentlyPlayingSlot);
      }
      const audio = new Audio(slot.audioUrl);
      const handleEnded = () => {
  stopSlotPlayback(slot);
      };
      const handleError = (event) => {
        console.warn('Playback failed', event);
        stopSlotPlayback(slot);
        if (slot?.statusEl) {
          slot.statusEl.textContent = 'Playback unavailable';
        }
      };
      audio.addEventListener('ended', handleEnded);
      audio.addEventListener('error', handleError);
      slot.playbackAudio = audio;
      slot.playbackEndedHandler = handleEnded;
      slot.playbackErrorHandler = handleError;
      slot.isPlaying = true;
      currentlyPlayingSlot = slot;
      updatePlayButton(slot, true);
      audio.play().catch((err) => {
        console.warn('Playback start failed', err);
        stopSlotPlayback(slot);
        if (slot?.statusEl) {
          slot.statusEl.textContent = 'Playback failed to start';
        }
      });
    }

    function selectStep(step) {
      baselineStepEl.hidden = step !== Step.BASELINE;
      scenarioStepEl.hidden = step !== Step.SCENARIO;
      evaluationStepEl.hidden = step !== Step.EVALUATION;
    }

    baselineNextBtn.addEventListener('click', () => {
      infoCardEl?.setAttribute('hidden', '');
      setSettingsVisible(false);
      selectStep(Step.SCENARIO);
      // Ensure controls on the newly shown step are enabled
      try { window.__restoreButtons?.(); } catch {}
      window.scrollTo({ top: 0, behavior: 'smooth' });
    });

    scenarioNextBtn.addEventListener('click', async () => {
      scenarioNextBtn.disabled = true;
      const isAdmin = window.location.hash === '#/admin';
      selectStep(Step.EVALUATION);
      // Ensure controls on the newly shown step are enabled
      try { window.__restoreButtons?.(); } catch {}
      window.scrollTo({ top: 0, behavior: 'smooth' });
      if (!isAdmin) {
        if (evaluationStepEl) {
          evaluationStepEl.innerHTML = '<div class="evaluation-complete"><p><strong>LLND Speaking Section Complete</strong></p></div>';
        } else if (evaluationSummaryEl) {
          evaluationSummaryEl.innerHTML = '<p><strong>LLND Speaking Section Complete</strong></p>';
        }
      } else if (evaluationSummaryEl) {
        evaluationSummaryEl.innerHTML = '<p><strong>Finalising evaluation…</strong> Please wait while we prepare your report.</p>';
      }
      try {
        // Ensure remote evaluation for Recording 3 completes before building final HTML
        const r3Transcript = slots.scenario3?.transcriptText || '';
        if (r3Transcript && !slots.scenario3.remoteEvaluation && !slots.scenario3.remoteEvaluationError) {
          debugLog('Remote Recording3 evaluation starting (awaited)');
          try {
            await evaluateRecording3Remotely(r3Transcript);
            debugLog('Remote Recording3 evaluation completed');
          } catch (remErr) {
            debugLog('Remote Recording3 evaluation failed', remErr);
          }
        }
        const evaluationPackage = runEvaluation();
        if (!evaluationPackage) {
          scenarioNextBtn.disabled = false;
          return;
        }
        await finaliseAssessment(evaluationPackage);
      } catch (err) {
        debugLog('Evaluation finalisation failed', err);
        if (evaluationSummaryEl) {
          const message = err?.message ? escapeHtml(String(err.message)) : 'An unexpected error occurred while finalising the assessment.';
          evaluationSummaryEl.innerHTML = `
            <div class="evaluation-block">
              <h3>Automatic delivery failed</h3>
              <p>${message}</p>
              <p>Please retry by pressing “Next” again after resolving the issue or use the manual send buttons.</p>
            </div>
          `;
        }
        scenarioNextBtn.disabled = false;
      }
    });

    const NUMBER_WORD_ONES = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine'];
    const NUMBER_WORD_TEENS = ['ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen'];
    const NUMBER_WORD_TENS = ['', '', 'twenty', 'thirty', 'forty', 'fifty', 'sixty', 'seventy', 'eighty', 'ninety'];
    const NUMBER_WORD_SCALES = ['trillion', 'billion', 'million', 'thousand'];
    const NUMBER_WORD_SCALE_VALUES = [1_000_000_000_000, 1_000_000_000, 1_000_000, 1_000];

    function numberLessThanThousandToWords(num) {
      const parts = [];
      const hundreds = Math.floor(num / 100);
      const remainder = num % 100;
      if (hundreds) {
        parts.push(`${NUMBER_WORD_ONES[hundreds]} hundred`);
      }
      if (remainder) {
        if (remainder < 10) {
          parts.push(NUMBER_WORD_ONES[remainder]);
        } else if (remainder < 20) {
          parts.push(NUMBER_WORD_TEENS[remainder - 10]);
        } else {
          const tens = Math.floor(remainder / 10);
          const ones = remainder % 10;
          parts.push(ones ? `${NUMBER_WORD_TENS[tens]}-${NUMBER_WORD_ONES[ones]}` : NUMBER_WORD_TENS[tens]);
        }
      }
      return parts.join(' ').trim();
    }

    function numberToWords(value) {
      if (!Number.isFinite(value)) return String(value);
      if (value === 0) return 'zero';
      const negative = value < 0;
      let remaining = Math.abs(value);
      const parts = [];

      NUMBER_WORD_SCALE_VALUES.forEach((scaleValue, index) => {
        if (remaining >= scaleValue) {
          const scaleCount = Math.floor(remaining / scaleValue);
          parts.push(`${numberLessThanThousandToWords(scaleCount)} ${NUMBER_WORD_SCALES[index]}`.trim());
          remaining %= scaleValue;
        }
      });

      if (remaining) {
        parts.push(numberLessThanThousandToWords(remaining));
      }

      const joined = parts.join(' ').replace(/\s+/g, ' ').trim();
      return negative ? `minus ${joined}` : joined;
    }

    function normalizeNumberToken(originalToken, replacement) {
      if (!originalToken || !replacement) return replacement;
      if (/^[A-Z]+$/.test(originalToken)) {
        return replacement.toUpperCase();
      }
      if (/^[A-Z]/.test(originalToken)) {
        return replacement.charAt(0).toUpperCase() + replacement.slice(1);
      }
      return replacement;
    }

    function describeDecimalPart(decimalString) {
      return decimalString
        .split('')
        .map((digit) => NUMBER_WORD_ONES[Number(digit)] ?? digit)
        .join(' ');
    }

    function convertNumbersToWords(text) {
      if (!text) return '';
      const numberPattern = /(^|[^A-Za-z0-9])([+-]?\d[\d,]*(?:\.\d+)?)(?=$|[^A-Za-z0-9])/g;
      return text.replace(numberPattern, (match, prefix, numericPart) => {
        const normalised = numericPart.replace(/,/g, '');
        if (!/^[-+]?\d*(?:\.\d+)?$/.test(normalised)) {
          return match;
        }
        const value = Number(normalised);
        if (!Number.isFinite(value)) {
          return match;
        }
        let replacement = '';
        if (Number.isInteger(value)) {
          replacement = numberToWords(value);
        } else {
          const [intPartRaw, decimalPartRaw] = normalised.split('.');
          const intPart = intPartRaw && intPartRaw !== '+' && intPartRaw !== '-' ? Number(intPartRaw) : 0;
          const intWords = numberToWords(intPart);
          const decimalWords = describeDecimalPart(decimalPartRaw || '0');
          const isNegative = normalised.trim().startsWith('-');
          const prefixWord = isNegative && intPart === 0 ? 'minus ' : '';
          replacement = `${prefixWord}${intWords} point ${decimalWords}`.replace(/\s+/g, ' ').trim();
        }
        replacement = normalizeNumberToken(numericPart, replacement);
        return `${prefix}${replacement}`;
      });
    }

    function sanitizeTranscript(rawText) {
      if (!rawText) return '';
      const cleaned = rawText
        .replace(/no transcript yet\.?/gi, '')
        .replace(/\[[0-9]{1,2}:[0-9]{2}:[0-9]{2}\s?(?:am|pm)?\]/gi, '')
        .replace(/\s+/g, ' ')
        .trim();
      return convertNumbersToWords(cleaned);
    }

    function getSlotTranscript(slot) {
      if (!slot) return '';
      if (slot.transcriptText) {
        return sanitizeTranscript(slot.transcriptText);
      }
      const domText = slot.transcriptBody ? slot.transcriptBody.textContent || '' : '';
      return sanitizeTranscript(domText);
    }

    function evaluateBaselineCompliance(summary, transcript) {
      const findings = { errors: [], warnings: [] };
      if (summary && isFinite(summary.avgDb)) {
        if (summary.avgDb > SHOUTING_THRESHOLD_DB) {
          findings.errors.push(`Average loudness was ${summary.avgDb.toFixed(1)} dB, which is above the recommended range. Re-record at a calmer volume.`);
        }
      }

      const lowerTranscript = transcript.toLowerCase();
      const flaggedTerms = BASELINE_PROHIBITED_TERMS.filter((term) => new RegExp(`\\b${term}\\b`, 'i').test(lowerTranscript));
      if (flaggedTerms.length) {
        const unique = Array.from(new Set(flaggedTerms.map((t) => t.toLowerCase())));
        findings.errors.push(`Remove inappropriate language (${unique.join(', ')}). Re-record using professional wording.`);
      }

      return findings;
    }

    function evaluateProfessionalLanguage(transcript) {
      const original = typeof transcript === 'string' ? transcript : '';
      const trimmed = original.trim();
      if (!trimmed) {
        return { appropriate: false, message: 'No transcript captured to review language.' };
      }

      if (/\*/.test(original)) {
        return { appropriate: false, message: 'Asterisks indicate censored or inappropriate language. Replace this wording with professional language.' };
      }

      const cleaned = sanitizeTranscript(original);
      const lower = cleaned.toLowerCase();
      const issues = [];

      const flaggedTerms = PROHIBITED_LANGUAGE_TERMS.filter((term) => new RegExp(`\\b${term}\\b`, 'i').test(lower));
      if (flaggedTerms.length) {
        const unique = Array.from(new Set(flaggedTerms.map((t) => t.toLowerCase())));
        issues.push(`Detected explicit or disrespectful language (${unique.join(', ')}). This wording is not acceptable in a professional environment.`);
      }

      const casualHits = [];
      CASUAL_LANGUAGE_PATTERNS.forEach((rule) => {
        if (rule.regex.test(lower)) {
          casualHits.push(rule.label);
        }
      });
      if (casualHits.length) {
        const unique = Array.from(new Set(casualHits));
        issues.push(`Detected slang or overly casual phrasing (${unique.join(', ')}). Use neutral, workplace-appropriate language.`);
      }

      if (!issues.length) {
        return { appropriate: true, message: 'Language stayed professional throughout.' };
      }

      return { appropriate: false, message: issues.join(' ') };
    }

    function evaluateProfessionalBehaviour(transcript) {
      const source = typeof transcript === 'string' ? transcript : '';
      const trimmed = source.trim();
      if (!trimmed) {
        return { ok: false, message: 'No transcript captured to review behaviour.' };
      }

      const lower = trimmed.toLowerCase();
      const hits = [];
      for (const pattern of UNPROFESSIONAL_BEHAVIOUR_PATTERNS) {
        if (pattern.regex.test(lower)) {
          hits.push(pattern.label);
        }
      }

      if (!hits.length) {
        return { ok: true, message: 'No unprofessional behaviour detected.' };
      }

      const unique = Array.from(new Set(hits));
      return {
        ok: false,
        message: `Unprofessional behaviour detected (${unique.join(', ')}).`
      };
    }

    function renderBaselineCompliance(slot) {
      if (!slot || slot.id !== 'baseline') return;
      const transcript = getSlotTranscript(slot);
      const findings = evaluateBaselineCompliance(slot.summary, transcript);

      if (!slot.alertsPanel || !slot.alertsList) return;

      slot.alertsList.innerHTML = '';
      const { errors, warnings } = findings;
      const hasAlerts = errors.length || warnings.length;

      if (!hasAlerts) {
        slot.alertsPanel.hidden = true;
        baselineNextBtn.disabled = false;
        return;
      }

      [...errors, ...warnings].forEach((message, index) => {
        const li = document.createElement('li');
        li.textContent = message;
        li.classList.add(index < errors.length ? 'error' : 'warning');
        slot.alertsList.appendChild(li);
      });

      slot.alertsPanel.hidden = false;
      baselineNextBtn.disabled = errors.length > 0;
    }

    function evaluatePromptCoverage(transcript, keywordGroups, requiredMatches = keywordGroups.length) {
      if (!transcript || !transcript.trim()) {
        return { met: false, explanation: 'No transcript captured for this response.' };
      }

      const lower = transcript.toLowerCase();
      const matched = [];
      const missing = [];

      keywordGroups.forEach((group) => {
        const hitKeyword = group.keywords.find((keyword) => lower.includes(keyword));
        if (hitKeyword) {
          matched.push({ label: group.label, keyword: hitKeyword, required: Boolean(group.required) });
        } else {
          missing.push(group.label);
        }
      });

      const matchedLabels = new Set(matched.map((m) => m.label));
      const missingRequiredGroups = keywordGroups.filter((group) => group.required && !matchedLabels.has(group.label));
      if (missingRequiredGroups.length) {
        const metText = matched.length ? `Mentioned ${matched.map((m) => `${m.label} (“${m.keyword}”)`).join(', ')}.` : '';
        const requiredText = `Must include clear reference to ${missingRequiredGroups.map((group) => group.label).join(' and ')}.`;
        return { met: false, explanation: `${metText} ${requiredText}`.trim() };
      }

      if (matched.length >= requiredMatches) {
        const detail = matched.map((m) => `${m.label} (“${m.keyword}”)`).join(', ');
        return { met: true, explanation: `Addressed ${detail}.` };
      }

      const metLabels = matched.map((m) => m.label);
      const metText = metLabels.length ? `Mentioned ${metLabels.join(' and ')}.` : '';
      const missingText = `Add clearer reference to ${missing.join(' and ')}.`;
      return { met: false, explanation: `${metText} ${missingText}`.trim() };
    }

    const SIMILARITY_STOPWORDS = new Set([
      'a', 'an', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'could', 'for', 'from', 'had', 'has', 'have', 'he', 'her', 'hers',
      'him', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'it', 'its', 'may', 'me', 'might', 'my', 'now', 'of', 'on', 'or', 'our',
      'ours', 'she', 'should', 'so', 'than', 'that', 'the', 'their', 'theirs', 'them', 'there', 'these', 'they', 'this', 'those',
      'to', 'too', 'up', 'us', 'was', 'we', 'were', 'what', 'when', 'where', 'which', 'who', 'will', 'with', 'would', 'you', 'your',
      'yours'
    ]);

    const SIMILARITY_SYNONYM_GROUPS = [
      ['client', 'clients', 'customer', 'customers', 'company', 'companies', 'organisation', 'organization', 'business', 'borrower', 'borrowers'],
      ['complaint', 'complaints', 'complain', 'complained', 'complaining', 'escalation', 'escalations', 'issue', 'issues', 'problem', 'problems', 'reputation', 'reputational', 'damage', 'risk', 'risks'],
      ['busy', 'overloaded', 'swamped', 'flatout', 'flat-out', 'occupied', 'underwater', 'tied', 'tiedup', 'tied-up'],
      ['deadline', 'deadlines', 'due', 'duedate', 'due-date', 'overdue', 'lateness'],
      ['settle', 'settles', 'settled', 'settling', 'pay', 'pays', 'payment', 'payments', 'repay', 'repays', 'repayment', 'repayments', 'finalise', 'finalize', 'complete'],
      ['finance', 'financial', 'loan', 'loans', 'funding', 'approval', 'approvals'],
      ['support', 'supports', 'supporting', 'help', 'helps', 'helping', 'assist', 'assists', 'assisting', 'partner', 'partnering', 'backing'],
      ['check', 'checks', 'checking', 'follow', 'followup', 'follow-up', 'touch', 'touchbase', 'meeting', 'meetings', 'meet', 'meets'],
      ['plan', 'plans', 'planning', 'strategy', 'strategies', 'schedule', 'schedules', 'calendar', 'calendars', 'reminder', 'reminders', 'roadmap'],
      ['prevent', 'prevents', 'preventing', 'avoid', 'avoids', 'avoiding', 'ensure', 'ensures', 'ensuring'],
      ['future', 'futures', 'next', 'forward', 'forwards', 'upcoming']
    ];

    const SIMILARITY_SYNONYM_LOOKUP = (() => {
      const lookup = Object.create(null);
      SIMILARITY_SYNONYM_GROUPS.forEach((group) => {
        const canonical = group[0];
        group.forEach((term) => {
          const key = term.replace(/[^a-z0-9]/g, '');
          if (key) {
            lookup[key] = canonical;
          }
        });
      });
      return lookup;
    })();

    function normaliseToken(token) {
      if (!token) return '';
      const compact = token.replace(/[^a-z0-9]/g, '');
      if (!compact) return '';
      const synonym = SIMILARITY_SYNONYM_LOOKUP[compact];
      return synonym || token;
    }

    function tokenizeForSimilarity(text) {
      if (!text) return [];
      return text
        .toLowerCase()
        .replace(/[^a-z0-9\s']/g, ' ')
        .split(/\s+/)
        .map((token) => token.trim())
        .filter((token) => token && token.length > 1 && !SIMILARITY_STOPWORDS.has(token))
        .map((token) => normaliseToken(token))
        .filter(Boolean);
    }
    function buildFrequencyMap(tokens) {
      return tokens.reduce((map, token) => {
        const next = map;
        next[token] = (next[token] || 0) + 1;
        return next;
      }, Object.create(null));
    }

    function calculateCosineSimilarity(textA, textB) {
      const tokensA = tokenizeForSimilarity(textA);
      const tokensB = tokenizeForSimilarity(textB);
      if (!tokensA.length || !tokensB.length) {
        return 0;
      }
      const freqA = buildFrequencyMap(tokensA);
      const freqB = buildFrequencyMap(tokensB);
      const sharedTokens = new Set([...Object.keys(freqA), ...Object.keys(freqB)]);
      let dotProduct = 0;
      let magnitudeA = 0;
      let magnitudeB = 0;

      sharedTokens.forEach((token) => {
        const valueA = freqA[token] || 0;
        const valueB = freqB[token] || 0;
        dotProduct += valueA * valueB;
      });

      Object.values(freqA).forEach((value) => {
        magnitudeA += value * value;
      });
      Object.values(freqB).forEach((value) => {
        magnitudeB += value * value;
      });

      if (!magnitudeA || !magnitudeB) {
        return 0;
      }

      return dotProduct / (Math.sqrt(magnitudeA) * Math.sqrt(magnitudeB));
    }

    function calculateReferenceCoverage(referenceText, candidateText) {
      const referenceTokens = new Set(tokenizeForSimilarity(referenceText));
      const candidateTokens = new Set(tokenizeForSimilarity(candidateText));
      if (!referenceTokens.size || !candidateTokens.size) {
        return 0;
      }
      let hits = 0;
      referenceTokens.forEach((token) => {
        if (candidateTokens.has(token)) {
          hits += 1;
        }
      });
      return hits / referenceTokens.size;
    }

    function formatKeywordGroups(groups) {
      if (!Array.isArray(groups)) {
        return '';
      }
      return groups
        .map((group) => {
          const keywords = (group.keywords || [])
            .map((keyword) => `<code>${escapeHtml(keyword)}</code>`)
            .join(', ');
          return `<li><strong>${escapeHtml(group.label || 'Cue')}:</strong> ${keywords}</li>`;
        })
        .join('');
    }

    function evaluatePreferredExampleGist(transcript, config = {}) {
      const cleanedTranscript = sanitizeTranscript(transcript || '');
      if (!cleanedTranscript) {
        return {
          met: false,
          status: 'Outcome mismatch',
          explanation: 'No transcript captured to compare with the preferred example. Unable to confirm if the same outcome would be achieved.',
          similarity: 0,
          similarityThreshold: config.similarityThreshold ?? 0.5,
          coverage: 0,
          similarityScoreUsed: 0,
          findings: [],
          matchedExpectations: 0,
          totalExpectations: config.expectations?.length || 0,
          achievesOutcome: false,
          missingExpectations: []
        };
      }

      const exampleText = sanitizeTranscript(config.exampleText || '');
      const similarity = calculateCosineSimilarity(cleanedTranscript, exampleText);
      const coverage = calculateReferenceCoverage(exampleText, cleanedTranscript);
      const similarityScoreUsed = Math.max(similarity, coverage);
      const threshold = config.similarityThreshold ?? 0.5;
      const lowerTranscript = cleanedTranscript.toLowerCase();

      const findings = (config.expectations || []).map((expectation) => {
        const phrases = expectation.phrases || [];
        const phraseHit = phrases.find((phrase) => lowerTranscript.includes(phrase));
        const components = expectation.components || [];
        const componentMatches = components.map((group) => {
          const match = group.find((term) => lowerTranscript.includes(term));
          return { terms: group, match };
        });
        const componentsMet = !components.length || componentMatches.every((item) => Boolean(item.match));
        const met = Boolean(phraseHit) || componentsMet;
        const matchedTerms = [];
        if (phraseHit) {
          matchedTerms.push(phraseHit);
        } else {
          componentMatches.forEach((item) => {
            if (item.match) {
              matchedTerms.push(item.match);
            }
          });
        }
        return {
          description: expectation.description,
          met,
          matchedTerms,
          critical: Boolean(expectation.critical)
        };
      });

      const matchedExpectations = findings.filter((finding) => finding.met).length;
      const totalExpectations = findings.length;
      const minExpectations = config.minExpectations ?? totalExpectations;
      const criticalMiss = findings.some((finding) => finding.critical && !finding.met);
      const expectationPass = (totalExpectations === 0 || matchedExpectations >= minExpectations) && !criticalMiss;
      const similarityPass = similarityScoreUsed >= threshold;
      const missingExpectations = findings.filter((finding) => !finding.met).map((finding) => finding.description);
      const achievesOutcome = expectationPass && similarityPass;

      const similarityText = `Similarity ${(similarity * 100).toFixed(0)}% · Coverage ${(coverage * 100).toFixed(0)}% (uses ${(similarityScoreUsed * 100).toFixed(0)}% vs ${(threshold * 100).toFixed(0)}% required)`;
      const expectationText = totalExpectations
        ? `${matchedExpectations}/${totalExpectations} outcome elements detected${criticalMiss ? ', but a critical element is missing' : ''}`
        : 'No outcome elements configured.';
      const baseExplanation = achievesOutcome
        ? 'Message is likely to achieve the same outcome as the preferred example. '
        : 'Message is unlikely to achieve the same outcome as the preferred example. ';
      const missingText = !achievesOutcome && missingExpectations.length
        ? `Missing elements: ${missingExpectations.join(', ')}. `
        : '';
      const explanation = `${baseExplanation}${similarityText}; ${expectationText}. ${missingText}`.trim();
      const status = achievesOutcome ? 'Likely same outcome' : 'Outcome mismatch';

      return {
        met: achievesOutcome,
        status,
        explanation,
        similarity,
        similarityThreshold: threshold,
        coverage,
        similarityScoreUsed,
        findings,
        matchedExpectations,
        totalExpectations,
        achievesOutcome,
        missingExpectations
      };
    }

    function formatPreferredExampleFindings(findings) {
      if (!Array.isArray(findings) || !findings.length) {
        return '';
      }
      return findings
        .map((finding) => {
          const statusLabel = finding.met ? 'Met' : 'Missing';
          const matched = finding.matchedTerms?.length
            ? ` — matched ${finding.matchedTerms.map((term) => `&ldquo;${escapeHtml(term)}&rdquo;`).join(', ')}`
            : '';
          const criticalNote = finding.critical ? ' (critical)' : '';
          return `<li><strong>${statusLabel}${criticalNote}:</strong> ${finding.description}${matched}</li>`;
        })
        .join('');
    }

    function escapeHtml(value) {
      if (value === null || value === undefined) return '';
      return String(value)
        .replace(/&/g, '&amp;')
        .replace(/</g, '&lt;')
        .replace(/>/g, '&gt;')
        .replace(/"/g, '&quot;')
        .replace(/'/g, '&#39;');
    }

    function assessProfessionalTone(summary, baselineSummary) {
      if (!summary || !baselineSummary) {
        return { professional: false, explanation: 'Audio metrics unavailable for comparison.' };
      }

      const observations = [];
      let concerns = 0;

      const tempoDelta = summary.wpm - baselineSummary.wpm;
      if (!summary.words || summary.words < 5) {
        observations.push('Very short response detected; add more detail to coach effectively.');
        concerns += 1;
      } else if (Math.abs(tempoDelta) <= 25) {
        observations.push('Tempo stayed close to baseline.');
      } else if (Math.abs(tempoDelta) <= 40) {
        observations.push('Tempo shifted noticeably but the overall message remained clear.');
      } else if (tempoDelta > 40) {
        observations.push('Tempo became much faster than baseline; breathe and slow slightly.');
        concerns += 1;
      } else {
        observations.push('Tempo slowed significantly; keep a little more energy in the delivery.');
        concerns += 1;
      }

      const fillerDelta = summary.fillerRate - baselineSummary.fillerRate;
      if (!isFinite(summary.fillerRate) || summary.fillerRate <= 0.06 || fillerDelta <= 0.04) {
        observations.push('Filler words remained well controlled.');
      } else if (summary.fillerRate <= 0.1) {
        observations.push('Filler usage rose slightly; pause briefly instead of using “um/uh”.');
      } else {
        observations.push('Frequent filler words reduced clarity. Practise deliberate pauses.');
        concerns += 1;
      }

      const loudnessDelta = summary.avgDb - baselineSummary.avgDb;
      if (!isFinite(summary.avgDb) || !isFinite(baselineSummary.avgDb)) {
        observations.push('Loudness comparison unavailable.');
      } else if (Math.abs(loudnessDelta) <= 7) {
        observations.push('Volume stayed consistent with baseline.');
      } else if (Math.abs(loudnessDelta) <= 12) {
        observations.push('Volume shifted a little from baseline; adjust slightly next time.');
      } else if (loudnessDelta < -12) {
        observations.push('Volume dipped well below baseline; speak a touch firmer when correcting issues.');
        concerns += 1;
      } else {
        observations.push('Volume rose well above baseline; ensure firmness doesn’t become confrontational.');
        concerns += 1;
      }

      const professional = concerns <= 2;
      return { professional, explanation: observations.join(' ') };
    }

    function summariseOverallTone(baselineSummary, scenarioSummaries) {
      if (!baselineSummary || scenarioSummaries.some((s) => !s)) {
        return {
          heading: 'Overall tone: Not enough data',
          detail: 'Record the baseline plus all three scenario recordings to calculate the combined tone rating.'
        };
      }

      const average = scenarioSummaries.reduce((acc, summary) => ({
        wpm: acc.wpm + summary.wpm,
        fillerRate: acc.fillerRate + summary.fillerRate,
        avgDb: acc.avgDb + summary.avgDb
      }), { wpm: 0, fillerRate: 0, avgDb: 0 });

      average.wpm /= scenarioSummaries.length;
      average.fillerRate /= scenarioSummaries.length;
      average.avgDb /= scenarioSummaries.length;

      const tempoDelta = average.wpm - baselineSummary.wpm;
      const fillerDelta = average.fillerRate - baselineSummary.fillerRate;
      const loudnessDelta = average.avgDb - baselineSummary.avgDb;

      let concerns = 0;
      const notes = [];

      if (Math.abs(tempoDelta) <= 25) {
        notes.push('tempo stayed close to the calm baseline');
      } else if (Math.abs(tempoDelta) <= 40) {
        notes.push('tempo shifted slightly faster/slower than baseline');
      } else {
        concerns += 1;
        notes.push('tempo moved well away from the baseline pace');
      }

      if (!isFinite(fillerDelta) || average.fillerRate <= 0.06 || fillerDelta <= 0.04) {
        notes.push('filler words remained controlled');
      } else if (average.fillerRate <= 0.1) {
        notes.push('filler words increased a little');
      } else {
        concerns += 1;
        notes.push('frequent fillers affected clarity');
      }

      if (!isFinite(loudnessDelta) || Math.abs(loudnessDelta) <= 7) {
        notes.push('volume matched the baseline');
      } else if (Math.abs(loudnessDelta) <= 12) {
        notes.push('volume moved slightly away from baseline');
      } else {
        concerns += 1;
        notes.push('volume shifted a long way from the baseline level');
      }

      let heading = 'Overall tone: Calm and professional';
      if (concerns >= 3) {
        heading = 'Overall tone: Needs attention';
      } else if (concerns >= 1) {
        heading = 'Overall tone: Mostly professional with minor issues';
      }

      return {
        heading,
        detail: notes.join('; ') + '. '
      };
    }

    function buildEvaluationEmailHtml(summaryMarkup, options = {}) {
      const studentName = typeof options.studentName === 'string' ? options.studentName.trim() : '';
      const contactId = typeof options.contactId === 'string' ? options.contactId.trim() : String(options.contactId ?? '').trim();
      const headingParts = [];
      if (studentName && studentName.toLowerCase() !== 'xxxx') {
        headingParts.push(studentName);
      }
      if (contactId && contactId.toLowerCase() !== 'xxxx') {
        headingParts.push(contactId);
      }
      const headingLabel = headingParts.length
        ? `Vocal Test Results - ${headingParts.join(' — ')}`
        : 'Vocal Test Results';
      const baseStyles = [
        'body { font-family: "Inter", -apple-system, "Segoe UI", sans-serif; color: #0c2740; background: #f6fbff; margin: 0; padding: 24px; }',
        'h1 { margin: 0 0 24px; font-size: 24px; letter-spacing: 0.04em; text-transform: uppercase; color: #0b4a7a; }',
        'h3 { margin: 0 0 12px; font-size: 18px; color: #0b4a7a; }',
        'p { margin: 0 0 12px; line-height: 1.6; }',
        '.subtle { color: #7d8b95; font-size: 13px; }',
        '.evaluation-block { border-bottom: 1px solid #d6ecff; padding: 16px 0; }',
        '.evaluation-block:last-of-type { border-bottom: none; }',
        '.evaluation-transcript { background: #eaf5ff; border: 1px solid #d6ecff; padding: 12px 14px; border-radius: 10px; font-family: "JetBrains Mono", monospace; font-size: 13px; white-space: pre-wrap; }',
        '.keywords-list { margin: 8px 0 0; padding-left: 20px; color: #7d8b95; }',
        '.keywords-list code { background: #fff5df; border: 1px solid rgba(210,166,58,0.35); border-radius: 6px; padding: 2px 6px; font-family: "JetBrains Mono", monospace; }',
        '.evaluation-expected-behaviour { margin-top: 24px; padding: 18px; border-radius: 12px; border: 1px solid #d6ecff; background: #ffffff; box-shadow: 0 4px 12px rgba(13,30,41,0.06); }',
        '.evaluation-expected-behaviour ul { margin: 12px 0 0; padding-left: 20px; }',
        '.evaluation-expected-behaviour li { margin: 4px 0; }',
        '.tag { display: inline-flex; align-items: center; padding: 3px 8px; border-radius: 999px; font-size: 11px; letter-spacing: 0.04em; text-transform: uppercase; color: #d2a63a; background: rgba(241,164,58,0.16); border: 1px solid rgba(241,164,58,0.32); }'
      ].join('\n');

      return [
        '<!doctype html>',
        '<html lang="en">',
        '<head>',
        '<meta charset="utf-8" />',
        '<title>Assessment Summary</title>',
        '<style>',
        baseStyles,
        '</style>',
        '</head>',
        '<body>',
        `<h1>${escapeHtml(headingLabel)}</h1>`,
        summaryMarkup || '<p>No evaluation summary available.</p>',
        '</body>',
        '</html>'
      ].join('\n');
    }

    function runEvaluation() {
      const baselineSummary = slots.baseline.summary;
      const scenarioSummaries = [slots.scenario1.summary, slots.scenario2.summary, slots.scenario3.summary];
      const transcripts = [getSlotTranscript(slots.scenario1), getSlotTranscript(slots.scenario2), getSlotTranscript(slots.scenario3)];

      if (!baselineSummary || scenarioSummaries.some((summary) => !summary)) {
        if (evaluationSummaryEl) {
          evaluationSummaryEl.innerHTML = '<p><strong>Insufficient data</strong></p><p>Record the baseline plus all three recordings to generate an evaluation.</p>';
        }
        setAssessmentResult('Not met');
        refreshDownloadList();
        return null;
      }

      const configs = [
          {
            title: 'Recording 1 — Impact on the client',
            preferred: '“Hi Sam, because you missed the deadlines the client will not be able to settle their finance on time.”',
            summary: scenarioSummaries[0],
            transcript: transcripts[0],
            keywords: [
              { label: 'Client reference', keywords: ['client', 'clients', 'client\'s', 'customer', 'customer\'s'], required: true },
              { label: 'Client consequence', keywords: ['penalty', 'penalties', 'fee', 'fees', 'complaint', 'complaints', 'delay', 'delays', 'late', 'settle', 'settlement', 'finance', 'impact', 'affected', 'pay', 'payment', 'payments', 'paying', 'missed payment', 'missed payments'], required: true }
            ],
            requiredMatches: 2,
            preferredAiConfig: {
              exampleText: 'Hi Sam, because you missed the deadlines the client will not be able to settle their finance on time.',
              similarityThreshold: 0.45,
              minExpectations: 2,
              expectations: [
                {
                  description: 'Greets Sam directly and acknowledges the missed deadlines.',
                  components: [
                    ['hi sam', 'hello sam', 'hey sam', 'sam'],
                    ['missed the deadline', 'missed the deadlines', 'missed deadline', 'missed deadlines', 'late paperwork', 'late submission', 'late lodgement', 'late lodgment', 'late deadline', 'late deadlines', 'overdue deadline', 'overdue deadlines', 'deadline', 'deadlines', 'deadline dates', 'due date', 'due dates', 'past due']
                  ]
                },
                {
                  description: 'Explains the client cannot settle on time (or will face late-settlement penalties) because of the missed deadline.',
                  phrases: [
                    'client will not be able to settle their finance on time',
                    'client cannot settle their finance on time',
                    'client will not be able to settle finance on time',
                    'client cannot settle finance on time',
                    'client will suffer penalties for late settlement',
                    'client will incur penalties for late settlement',
                    'client will now suffer penalties for late settlement',
                    'client will now incur penalties for late settlement',
                    'client will suffer a late settlement penalty',
                    'client will incur a late settlement penalty'
                  ],
                  components: [
                    ['client', 'client\'s', 'customer', 'customer\'s', 'borrower'],
                    [
                      'cannot settle', 'will not settle', 'unable to settle', 'settle', 'settlement', 'settling', 'complete', 'finalise', 'finalize',
                      'pay', 'payment', 'payments', 'make their payments', 'repay', 'repayment',
                      'penalty', 'penalties', 'late settlement', 'late settlement penalty', 'late settlement penalties', 'late payment', 'late payments',
                      'late fee', 'late fees', 'late charge', 'late charges', 'suffer penalties', 'incur penalties', 'face penalties'
                    ],
                    [
                      'on time', 'in time', 'by the deadline', 'by deadline', 'by the due date', 'on schedule',
                      'for late settlement', 'for a late settlement', 'late settlement', 'late to settle', 'miss settlement', 'miss the settlement deadline',
                      'late payment', 'late payments', 'penalty for late settlement', 'penalties for late settlement', 'late settlement penalty'
                    ]
                  ],
                  critical: true
                },
                {
                  description: 'Links Sam’s missed deadline to the client consequence using cause-and-effect language.',
                  components: [
                    ['because', 'since', 'as', 'due to'],
                    ['missed', 'late', 'delayed', 'deadline', 'deadlines', 'due date', 'due dates', 'submission'],
                    ['client', 'customer']
                  ]
                }
              ]
            }
          },
          {
            title: 'Recording 2 — Impact on the company',
            preferred: '“I understand you were busy with other tasks, but the client may now lodge a complaint.”',
            summary: scenarioSummaries[1],
            transcript: transcripts[1],
            keywords: [
              { label: 'Business or team reference', keywords: ['business', 'company', 'team', 'office', 'organisation', 'organization', 'broking', 'us', 'arora', 'arora finance solutions', 'arora financial solutions'], required: true },
              { label: 'Operational consequence', keywords: ['penalty', 'penalties', 'complaint', 'complaints', 'reputation', 'risk', 'trust', 'workload', 'extra work', 'lost time', 'cost', 'costs'], required: true },
              { label: 'Link to client impact', keywords: ['client', 'customer', 'service', 'settlement', 'complaint', 'complaints', 'formal complaint', 'formal complaints', 'reputation', 'reputational'], required: true }
            ],
            requiredMatches: 3,
            preferredAiConfig: {
              exampleText: 'I understand you were busy with other tasks, but the client may now lodge a complaint.',
              similarityThreshold: 0.4,
              minExpectations: 2,
              expectations: [
                {
                  description: 'Acknowledges Sam was busy while maintaining empathy and accountability.',
                  components: [
                    ['i understand', 'i appreciate', 'i recognise', 'i recognize', 'i know', 'i realise', 'i realize', 'i can see', 'i get'],
                    ['busy', 'other tasks', 'flat out', 'tied up', 'swamped', 'under the pump', 'caught up', 'with other priorities', 'stretched', 'juggling', 'back to back', 'back-to-back', 'snowed under']
                  ]
                },
                {
                  description: 'Warns that the client may lodge a complaint.',
                  phrases: [
                    'client may lodge a complaint',
                    'client may file a complaint',
                    'client may raise a complaint',
                    'client may make a complaint',
                    'client may complain',
                    'client may escalate a complaint',
                    'client may raise an escalation'
                  ],
                  components: [
                    ['client', 'customer', 'company', 'business', 'organisation', 'organization', 'firm', 'borrower', 'stakeholder'],
                    ['complaint', 'complaints', 'formal complaint', 'formal complaints', 'raise a complaint', 'lodge a complaint', 'file a complaint', 'escalation', 'escalate', 'escalated', 'reputation risk', 'reputational damage', 'complain', 'negative review']
                  ],
                  critical: true
                },
                {
                  description: 'Connects Sam’s workload issue with the potential complaint.',
                  components: [
                    ['but', 'however', 'yet', 'though', 'still', 'even so', 'nevertheless'],
                    ['complaint', 'complaints', 'formal complaint', 'escalation', 'issue', 'problem', 'reputational', 'reputation', 'damage', 'risk', 'penalty', 'penalties', 'escalate', 'escalation'],
                    ['busy', 'other tasks', 'workload', 'overloaded', 'swamped', 'tied up', 'flat out', 'under the pump', 'juggling']
                  ]
                }
              ]
            }
          },
          {
            title: 'Recording 3 — Prevention strategy',
            preferred: '“To avoid this happening again you should...” and “I will check in with you...”',
            summary: scenarioSummaries[2],
            transcript: transcripts[2],
            keywords: [
              { label: 'Future prevention', keywords: ['prevent', 'avoid', 'next time', 'future', "won't happen", 'again', 'ensure', 'in the future', 'in future', 'going forward', 'going forwards', 'to avoid future problems', 'avoid future problems', 'avoid future issues', 'avoid future delays'], required: true },
              { label: 'Collaborative support', keywords: ['work with you', 'work together', 'work alongside you', 'support you', 'support from me', 'help you', 'assist you', 'partner with you', 'check in with you', 'follow up with you', 'meet with you', 'meet with me', 'meeting with you', 'meeting with me', 'book a meeting', 'book a weekly meeting', 'schedule a meeting', 'weekly meeting', 'weekly meetings', 'regular meeting', 'regular meetings', 'check with you', 'check with me'], required: true },
              { label: 'Strategy or action', keywords: ['strategy', 'plan', 'reminder', 'reminders', 'calendar', 'schedule', 'prioritise', 'prioritize', 'priority', 'ask for help', 'ask for support', 'check-in', 'support', 'delegate', 'follow up', 'weekly update', 'update', 'set reminders', 'task list'], required: true }
            ],
            requiredMatches: 3,
            preferredAiConfig: {
              exampleText: 'To avoid this happening again you should... I will check in with you...',
              similarityThreshold: 0.45,
              minExpectations: 2,
              expectations: [
                {
                  description: 'States how to avoid the issue happening again with clear future language ("to avoid", "next time").',
                  components: [
                    ['to avoid', 'to prevent', 'in future', 'in the future', 'next time', 'going forward', "so this doesn't happen again", "so it doesn't happen again", "so that this doesn't happen again", "so we don't repeat this", 'so we avoid this', "so it won't happen again"],
                    ['happening again', 'again', 'repeat', 'future issues', 'future problem', 'future problems', 'future delays', 'same issue', 'same problem', 'same situation', 'same mistake', 'repeat this', 'repeat it']
                  ],
                  critical: true
                },
                {
                  description: 'Directs Sam with “you should/need to…” guidance for the fix.',
                  components: [
                    ['you should', 'you need to', 'you must', 'i need you to', "let's make sure you", 'i want you to', "let's get you to", "it's important you", 'its important you', 'you could', 'i encourage you to'],
                    ['plan', 'prioritise', 'prioritize', 'use reminders', 'set reminders', 'ask for help', 'calendar', 'schedule', 'task list', 'book a meeting', 'schedule a meeting', 'weekly meeting', 'meeting with me', 'meeting with you', 'organise a check-in', 'organize a check-in', 'set up reminders', 'calendar reminder', 'calendar block', 'shared task list', 'checklist', 'weekly check-in', 'progress update', 'status update']
                  ]
                },
                {
                  description: 'Commits to checking in or following up personally.',
                  phrases: ['i will check in with you', 'i will check with you', 'i will check with you against the project plan', 'i will check with you weekly', 'i will follow up with you', 'i will touch base with you', 'i will keep in touch with you', 'i will stay in touch with you', 'i will catch up with you'],
                  components: [
                    ['check in with you', 'check-in with you', 'follow up with you', 'touch base with you', 'check on you', 'touch base', 'check with you', 'check with me', 'meet with you', 'meet with me', 'weekly meeting', 'touch base weekly', 'catch up with you', 'catch up weekly', 'follow up weekly', 'stay in touch', 'keep in touch']
                  ],
                  critical: true
                }
              ]
            }
          }
        ];

          const outcomes = configs.map((config, index) => {
          // Use local tone only; all other criteria come from Remote Evaluation feedback
          let coverage = { met: false, explanation: 'Awaiting remote evaluation' };
          const tone = assessProfessionalTone(config.summary, baselineSummary);
          let language = { appropriate: false, message: 'Awaiting remote evaluation' };
          let behaviour = { ok: false, message: 'Awaiting remote evaluation' };
          let preferredExampleAi = { met: false, status: 'Awaiting remote evaluation', explanation: 'Awaiting remote evaluation', findings: [] };

          // Remote override for Recording 1 (index 0) – use remote service output for all but tone.
          if (index === 0 && slots.scenario1?.remoteEvaluation) {
            const remote = slots.scenario1.remoteEvaluation;
            const parseStatusLine = (value, defaultLabel) => {
              if (typeof value !== 'string') return { status: defaultLabel, explanation: '' };
              const parts = value.split('—');
              const status = parts[0].trim();
              const explanation = parts.slice(1).join('—').trim();
              return { status, explanation };
            };
            const qc = parseStatusLine(remote.questionCriteria, 'Met');
            const pl = parseStatusLine(remote.professionalLanguage, 'Met');
            const pb = parseStatusLine(remote.professionalBehaviour, 'Met');
            const gist = parseStatusLine(remote.aiGist, 'Likely same outcome');
            coverage = { met: qc.status.toLowerCase() === 'met', explanation: qc.explanation || remote.questionCriteria || '' };
            language = { appropriate: pl.status.toLowerCase() === 'met', message: pl.explanation || remote.professionalLanguage || '' };
            behaviour = { ok: pb.status.toLowerCase() === 'met', message: pb.explanation || remote.professionalBehaviour || '' };
            preferredExampleAi = {
              met: gist.status.toLowerCase().startsWith('likely'),
              status: gist.status,
              explanation: gist.explanation || remote.aiGist || '',
              findings: []
            };
            debugLog('Recording1 using remote evaluation override', remote);
          }
          // Remote override for Recording 2 (index 1)
          if (index === 1 && slots.scenario2?.remoteEvaluation) {
            const remote = slots.scenario2.remoteEvaluation;
            const parseStatusLine = (value, defaultLabel) => {
              if (typeof value !== 'string') return { status: defaultLabel, explanation: '' };
              const parts = value.split('—');
              const status = parts[0].trim();
              const explanation = parts.slice(1).join('—').trim();
              return { status, explanation };
            };
            const qc = parseStatusLine(remote.questionCriteria, 'Met');
            const pl = parseStatusLine(remote.professionalLanguage, 'Met');
            const pb = parseStatusLine(remote.professionalBehaviour, 'Met');
            const gist = parseStatusLine(remote.aiGist, 'Likely same outcome');
            coverage = { met: qc.status.toLowerCase() === 'met', explanation: qc.explanation || remote.questionCriteria || '' };
            language = { appropriate: pl.status.toLowerCase() === 'met', message: pl.explanation || remote.professionalLanguage || '' };
            behaviour = { ok: pb.status.toLowerCase() === 'met', message: pb.explanation || remote.professionalBehaviour || '' };
            preferredExampleAi = {
              met: gist.status.toLowerCase().startsWith('likely'),
              status: gist.status,
              explanation: gist.explanation || remote.aiGist || '',
              findings: []
            };
            debugLog('Recording2 using remote evaluation override', remote);
          }
          // Remote override for Recording 3 (index 2)
          if (index === 2 && slots.scenario3?.remoteEvaluation) {
            const remote = slots.scenario3.remoteEvaluation;
            const parseStatusLine = (value, defaultLabel) => {
              if (typeof value !== 'string') return { status: defaultLabel, explanation: '' };
              const parts = value.split('—');
              const status = parts[0].trim();
              const explanation = parts.slice(1).join('—').trim();
              return { status, explanation };
            };
            const qc = parseStatusLine(remote.questionCriteria, 'Met');
            const pl = parseStatusLine(remote.professionalLanguage, 'Met');
            const pb = parseStatusLine(remote.professionalBehaviour, 'Met');
            const gist = parseStatusLine(remote.aiGist, 'Likely same outcome');
            coverage = { met: qc.status.toLowerCase() === 'met', explanation: qc.explanation || remote.questionCriteria || '' };
            language = { appropriate: pl.status.toLowerCase() === 'met', message: pl.explanation || remote.professionalLanguage || '' };
            behaviour = { ok: pb.status.toLowerCase() === 'met', message: pb.explanation || remote.professionalBehaviour || '' };
            preferredExampleAi = {
              met: gist.status.toLowerCase().startsWith('likely'),
              status: gist.status,
              explanation: gist.explanation || remote.aiGist || '',
              findings: []
            };
            debugLog('Recording3 using remote evaluation override', remote);
          }

          const questionMet = coverage.met;
          const toneMet = tone.professional;
          const languageMet = language.appropriate;
          const behaviourMet = behaviour.ok;
          // If remote evaluation is present for this recording, use it as the defining
          // pass/fail and treat local tone as advisory notes only.
          const hasRemoteOverride = (index === 0 && !!slots.scenario1?.remoteEvaluation)
            || (index === 1 && !!slots.scenario2?.remoteEvaluation)
            || (index === 2 && !!slots.scenario3?.remoteEvaluation);
          const combinedMet = hasRemoteOverride
            ? (questionMet && languageMet && behaviourMet && preferredExampleAi.met)
            : (questionMet && toneMet && languageMet && behaviourMet && preferredExampleAi.met);
          const questionStatus = questionMet ? 'Met' : 'Unmet';
          const toneStatus = toneMet ? 'Met' : 'Unmet';
          const languageStatus = languageMet ? 'Met' : 'Unmet';
          const behaviourStatus = behaviourMet ? 'Met' : 'Unmet';
          const missingPieces = [];
            if (!questionMet) missingPieces.push('Question Criteria');
            // When remote override applies, tone is recorded as notes only (not defining)
            if (!hasRemoteOverride && !toneMet) missingPieces.push('Professional Tone');
            if (!languageMet) missingPieces.push('Professional Language');
            if (!behaviourMet) missingPieces.push('Professional Behaviour');
            if (!preferredExampleAi.met) missingPieces.push('Preferred Example Outcome');
          const combinedStatus = combinedMet ? 'Met' : 'Unmet';
          const combinedMessage = combinedMet
            ? 'All question, tone, language, behaviour, and preferred-example outcome requirements were satisfied.'
            : `Unmet because ${missingPieces.join(', ')} require attention.`;
          const preferredExampleStatus = preferredExampleAi.status;

          const blockHtml = `
            <div class="evaluation-block">
              <h3>${config.title}</h3>
              <p><strong>Question Criteria:</strong> ${questionStatus} — ${coverage.explanation}</p>
              <p><strong>Professional Tone:</strong> ${toneStatus} — ${tone.explanation}</p>
              <p><strong>Professional Language:</strong> ${languageStatus} — ${language.message}</p>
              <p><strong>Professional Behaviour:</strong> ${behaviourStatus} — ${behaviour.message}</p>
              <p><strong>AI Gist:</strong> ${preferredExampleStatus} — ${preferredExampleAi.explanation}</p>
              <p><strong>Combined Criteria:</strong> ${combinedStatus} — ${combinedMessage}</p>
              <p><strong>Preferred example:</strong> ${config.preferred}</p>
              <div>
                <strong>What you said:</strong>
                <div class="evaluation-transcript">${escapeHtml(config.transcript || 'No transcript captured.')}</div>
              </div>
              <div>
                <strong>Acceptable cues:</strong>
                <ul class="keywords-list">${formatKeywordGroups(config.keywords)}</ul>
              </div>
            </div>
          `;

          return {
            html: blockHtml,
            combinedMet,
            title: config.title,
            missingPieces,
            transcript: transcripts[index],
            metrics: {
              question: { status: questionStatus, explanation: coverage.explanation },
              tone: { status: toneStatus, explanation: tone.explanation },
              language: { status: languageStatus, explanation: language.message },
              behaviour: { status: behaviourStatus, explanation: behaviour.message },
              combined: { status: combinedStatus, explanation: combinedMessage }
            },
            preferredExample: config.preferred,
            acceptableCues: config.keywords,
            keywordMatches: coverage,
            aiPreferredExample: preferredExampleAi
          };
        });

      const rows = outcomes.map((outcome) => outcome.html).join('');
      const toneSummary = summariseOverallTone(baselineSummary, scenarioSummaries);
      const averageScenarioTempo = scenarioSummaries.reduce((acc, s) => acc + s.wpm, 0) / scenarioSummaries.length;
      const allCombinedMet = outcomes.every((outcome) => outcome.combinedMet);
      const overallStatus = allCombinedMet ? 'Met' : 'Not met';
      const failingDetails = outcomes
        .filter((outcome) => !outcome.combinedMet)
        .map((outcome) => {
          const details = outcome.missingPieces.join(', ');
          return details ? `${outcome.title} (${details})` : outcome.title;
        });

      let finalSummaryText;
      if (allCombinedMet) {
        finalSummaryText = `Overall result: ${overallStatus}. All responses satisfied the question, professional tone, professional language, and professional behaviour requirements. The student has met the assessment criteria.`;
      } else {
        const behaviourIssues = outcomes
          .filter((outcome) => !outcome.combinedMet)
          .some((outcome) => outcome.missingPieces.includes('Professional Behaviour'));
        const toneOrLanguageIssues = outcomes
          .filter((outcome) => !outcome.combinedMet)
          .some((outcome) => outcome.missingPieces.some((piece) => piece === 'Professional Tone' || piece === 'Professional Language'));
        if (behaviourIssues) {
          finalSummaryText = `Overall result: ${overallStatus}. Unprofessional behaviour was detected in ${failingDetails.join('; ')}. The student has not met the assessment criteria.`;
        } else if (toneOrLanguageIssues) {
          finalSummaryText = `Overall result: ${overallStatus}. Professional tone and/or language requirements were missed in ${failingDetails.join('; ')}. The student has not met the assessment criteria.`;
        } else {
          finalSummaryText = `Overall result: ${overallStatus}. Question Criteria were not fully met in ${failingDetails.join('; ')}. The student has not met the assessment criteria.`;
        }
      }

      const expectedBehaviourItems = [
        'Begins conversation politely and clearly.',
        'Introduces the purpose (discussing missed deadlines).',
        'Maintains a calm, professional tone.',
        'Clearly explains how Sam’s missed deadlines have affected the client.',
        'Uses factual and professional language.',
        'Demonstrates empathy for both client and Sam.',
        'Discusses broader organisational consequences (reputation, complaints, trust).',
        'Maintains professional, solution-focused language.',
        'Summarises the agreed outcome or expectation.',
        'Closes with a polite and supportive tone.'
      ];

      const expectedBehaviourHtml = `
          <div class="evaluation-expected-behaviour">
            <h3>Expected Candidate Behaviour</h3>
            <ul>
              ${expectedBehaviourItems.map((item) => `<li><strong>Confirmed:</strong> ${item}</li>`).join('')}
            </ul>
          </div>
        `;

      const evaluationSummaryMarkup = `
          <p><strong>Overall Summary:</strong> ${finalSummaryText}</p>
          ${rows}
          <p><strong>${toneSummary.heading}</strong> ${toneSummary.detail}</p>
          <p class="subtle">Baseline tempo: ${baselineSummary.wpm.toFixed(1)} wpm · Average scenario tempo: ${averageScenarioTempo.toFixed(1)} wpm</p>
          ${expectedBehaviourHtml}
        `;

      const scenarioDetails = outcomes.map((outcome, idx) => ({
        sequence: idx + 1,
        title: outcome.title,
        combinedMet: outcome.combinedMet,
        missingCriteria: outcome.missingPieces,
        transcript: outcome.transcript,
        metrics: outcome.metrics,
        preferredExample: outcome.preferredExample,
        acceptableCues: outcome.acceptableCues,
        keywordMatches: outcome.keywordMatches,
        aiPreferredExample: outcome.aiPreferredExample
      }));

      const { contactIdText, studentName, studentEmail } = getStudentContext();
      const evaluationEmailHtml = buildEvaluationEmailHtml(evaluationSummaryMarkup, {
        studentName,
        contactId: contactIdText
      });
      const tempDiv = document.createElement('div');
      tempDiv.innerHTML = evaluationSummaryMarkup;
      const evaluationText = tempDiv.textContent || '';

      const assessmentDetails = {
        baseline: baselineSummary,
        scenarios: scenarioSummaries,
        scenarioDetails,
        finalSummaryText,
        toneSummary,
        failingDetails,
        averageScenarioTempo,
        expectedBehaviourItems,
        studentName,
        contactId: contactIdText,
        studentEmail,
        evaluationHtml: evaluationSummaryMarkup,
        evaluationEmailHtml,
        evaluationText
      };

      refreshDownloadList();

      return {
        overallStatus,
        assessmentDetails,
        evaluationSummaryMarkup,
        outcomes
      };
    }

    function refreshDownloadList() {
      downloadListEl.innerHTML = '';
      slotIds.forEach((id) => {
        const slot = slots[id];
        if (!slot?.audioUrl) return;
        const li = document.createElement('li');
        const link = document.createElement('a');
        link.href = slot.audioUrl;
        link.download = `${id}.webm`;
        link.textContent = `Download ${slot.label}`;
        li.appendChild(link);
        downloadListEl.appendChild(li);
      });
    }

    async function finaliseAssessment(evaluationPackage) {
      if (!evaluationPackage) {
        throw new Error('No evaluation data available to finalise.');
      }
      if (!sendAssessmentHtmlBtn || !saveAssessmentAudioBtn) {
        throw new Error('Automatic delivery controls are unavailable.');
      }
      if (autoDeliveryInFlight) {
        debugLog('Finalisation skipped — delivery already in progress');
        return;
      }
      autoDeliveryInFlight = true;
      const payloadForDelivery = {
        overall: evaluationPackage.overallStatus,
        timestamp: Date.now(),
        details: { ...evaluationPackage.assessmentDetails }
      };
      try {
        await deliverAssessmentHtml(sendAssessmentHtmlBtn, payloadForDelivery);
        await deliverAssessmentAudio(saveAssessmentAudioBtn, payloadForDelivery);
        const isAdminView = window.location.hash === '#/admin';
        if (isAdminView) {
          if (evaluationSummaryEl) {
            evaluationSummaryEl.innerHTML = evaluationPackage.evaluationSummaryMarkup;
          }
        } else {
          // Non-admin: collapse evaluation screen to single completion message.
          if (evaluationStepEl) {
            evaluationStepEl.innerHTML = '<div class="evaluation-complete"><p><strong>LLND Speaking Section Complete</strong></p></div>';
          } else if (evaluationSummaryEl) {
            evaluationSummaryEl.innerHTML = '<p><strong>LLND Speaking Section Complete</strong></p>';
          }
        }
        setAssessmentResult(payloadForDelivery.overall, payloadForDelivery.details);
        if (isAdminView) {
          // Downloads only relevant for admin view.
          refreshDownloadList();
        } else if (downloadListEl) {
          downloadListEl.innerHTML = '';
        }
      } finally {
        autoDeliveryInFlight = false;
      }
    }

    micSelect?.addEventListener('change', (event) => {
      currentDeviceId = event.target?.value || '';
      // If the settings modal is open and not recording, restart preview on the new device
      if (settingsVisible && !isRecording) {
        startSettingsLevelPreview();
      }
    });

    if (navigator.mediaDevices) {
      const handleDeviceChange = () => {
        refreshMicrophones().catch(() => {});
      };
      if (typeof navigator.mediaDevices.addEventListener === 'function') {
        navigator.mediaDevices.addEventListener('devicechange', handleDeviceChange);
      } else {
        navigator.mediaDevices.ondevicechange = handleDeviceChange;
      }
    }

    refreshMicrophones().catch(() => {});
    updateScenarioAvailability();
  </script>
  <script>
    const postVocalStatus = () => {
      const result = window.VocalAssessmentResult ?? 'In progress';
      window.parent?.postMessage(
        {
          type: 'vocal-status',
          status: result,
          detail: result
        },
        '*'
      );
    };

    window.addEventListener('message', (event) => {
      const data = event?.data;
      if (!data || typeof data !== 'object') {
        return;
      }
      if (data.type === 'vocal-student-context') {
        const incomingName = typeof data.studentName === 'string' && data.studentName.trim() ? data.studentName.trim() : DEFAULT_STUDENT_NAME;
        const rawContact = data.contactId ?? data.contactID ?? data.ContactId ?? data.ContactID;
        let resolvedContact = '';
        if (typeof rawContact === 'number' && Number.isFinite(rawContact)) {
          resolvedContact = String(rawContact);
        } else if (typeof rawContact === 'string' && rawContact.trim()) {
          resolvedContact = rawContact.trim();
        }
        if (!resolvedContact) {
          resolvedContact = DEFAULT_CONTACT_ID;
        }
        const incomingEmail = typeof data.studentEmail === 'string' && data.studentEmail.trim() ? data.studentEmail.trim() : undefined;
        const nextInfo = {
          ...(typeof window.VocalStudentInfo === 'object' && window.VocalStudentInfo ? window.VocalStudentInfo : {}),
          studentName: incomingName,
          contactId: resolvedContact
        };
        if (incomingEmail) {
          nextInfo.studentEmail = incomingEmail;
        }
        window.VocalStudentInfo = nextInfo;
        window.VocalAssessmentContactId = resolvedContact;
        if (document.body?.dataset) {
          document.body.dataset.studentName = incomingName;
          document.body.dataset.contactId = resolvedContact;
          if (incomingEmail) {
            document.body.dataset.studentEmail = incomingEmail;
          }
        }
        updateStudentContextBanner();
        debugLog('Student context received', window.VocalStudentInfo);
        return;
      }
      if (data.type === 'request-vocal-status') {
        postVocalStatus();
      }
    });

    window.addEventListener('load', () => {
      updateStudentContextBanner();
      postVocalStatus();
    });

    window.broadcastVocalAssessmentResult = (nextResult) => {
      window.VocalAssessmentResult = nextResult;
      postVocalStatus();
    };
  </script>
  <script>
    // Disable all buttons after clicking Next until next page/slot loads
    (function(){
      function disableAllButtons() {
        document.querySelectorAll('button').forEach(btn => {
          if (!btn.disabled) {
            btn.dataset.prevEnabled = '1';
            btn.disabled = true;
          }
        });
      }

      function restoreButtons() {
        document.querySelectorAll('button').forEach(btn => {
          if (btn.dataset.prevEnabled === '1') {
            btn.disabled = false;
            delete btn.dataset.prevEnabled;
          }
        });
      }

      // Expose a safe global to re-enable controls after step changes
      try { window.__restoreButtons = restoreButtons; } catch {}

      function observeSlotChangeAndRestore() {
        const target = document.querySelector('main') || document.body;
        const observer = new MutationObserver((mutations, obs) => {
          for (const m of mutations) {
            if (m.type === 'attributes' && m.target instanceof HTMLElement) {
              if (m.target.classList.contains('slot')) {
                // When a slot visibility changes, restore buttons once
                restoreButtons();
                obs.disconnect();
                return;
              }
            }
            if (m.type === 'childList') {
              // New slot injected or page content changed
              restoreButtons();
              obs.disconnect();
              return;
            }
          }
        });
        observer.observe(target, { attributes: true, attributeFilter: ['hidden'], subtree: true, childList: true });
      }

      document.addEventListener('click', (e) => {
        const el = e.target;
        if (el instanceof HTMLElement && el.matches('button[data-action="next-slot"], .btn-primary[data-action="next-slot"], #baselineNext, #scenarioNext')) {
          disableAllButtons();
          observeSlotChangeAndRestore();
        }
      }, true);
    })();
  </script>
</body>
</html>
